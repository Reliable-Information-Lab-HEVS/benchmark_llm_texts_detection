log_loss_steps: 200
eval_steps: 504
check_degradation: 504
Average Loss on fact answering task after 0 samples: 6.0321
Average Loss on fact answering task after 0 samples: 5.8221
Average Loss on fact answering task after 0 samples: 6.1644
Average Loss on fact answering task after 0 samples: 6.2171
Average Loss on fact answering task after 0 samples: 5.9218
----------------Epoch 1/1----------------
Epoch 1/1, Loss after 192 samples: 0.6961
Epoch 1/1, Loss after 392 samples: 0.6902
Average Loss on fact answering task after 496 samples: 6.1658
Average Loss on fact answering task after 496 samples: 6.0284
Average Loss on fact answering task after 496 samples: 6.1547
Average Loss on fact answering task after 496 samples: 6.1494
Average Loss on fact answering task after 496 samples: 6.0787
Mean accuracy: 0.6816, std: 0.0108, lower bound: 0.6587, upper bound: 0.7023 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 496 samples: 0.6820
Best model with eval accuracy 0.6820486815415822 with 496 samples seen is saved
Epoch 1/1, Loss after 592 samples: 0.6875
Epoch 1/1, Loss after 792 samples: 0.6503
Epoch 1/1, Loss after 992 samples: 0.5838
Average Loss on fact answering task after 1000 samples: 6.5452
Average Loss on fact answering task after 1000 samples: 6.6708
Average Loss on fact answering task after 1000 samples: 6.3797
Average Loss on fact answering task after 1000 samples: 6.4840
Average Loss on fact answering task after 1000 samples: 6.2836
Mean accuracy: 0.5265, std: 0.0109, lower bound: 0.5046, upper bound: 0.5477 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 1000 samples: 0.5264
Epoch 1/1, Loss after 1192 samples: 0.5271
Epoch 1/1, Loss after 1392 samples: 0.4121
Average Loss on fact answering task after 1504 samples: 6.7954
Average Loss on fact answering task after 1504 samples: 6.8055
Average Loss on fact answering task after 1504 samples: 6.8724
Average Loss on fact answering task after 1504 samples: 7.0070
Average Loss on fact answering task after 1504 samples: 6.6951
Mean accuracy: 0.8318, std: 0.0085, lower bound: 0.8154, upper bound: 0.8479 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 1504 samples: 0.8316
Best model with eval accuracy 0.8316430020283976 with 1504 samples seen is saved
Epoch 1/1, Loss after 1592 samples: 0.3237
Epoch 1/1, Loss after 1792 samples: 0.3623
Epoch 1/1, Loss after 1992 samples: 0.2846
Average Loss on fact answering task after 2008 samples: 7.3519
Average Loss on fact answering task after 2008 samples: 7.4980
Average Loss on fact answering task after 2008 samples: 7.5383
Average Loss on fact answering task after 2008 samples: 7.4174
Average Loss on fact answering task after 2008 samples: 7.5199
Mean accuracy: 0.8058, std: 0.0094, lower bound: 0.7875, upper bound: 0.8240 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 2008 samples: 0.8058
Epoch 1/1, Loss after 2192 samples: 0.4621
Epoch 1/1, Loss after 2392 samples: 0.3049
Average Loss on fact answering task after 2512 samples: 7.9284
Average Loss on fact answering task after 2512 samples: 7.9386
Average Loss on fact answering task after 2512 samples: 7.7507
Average Loss on fact answering task after 2512 samples: 7.9665
Average Loss on fact answering task after 2512 samples: 7.8331
Mean accuracy: 0.7859, std: 0.0094, lower bound: 0.7682, upper bound: 0.8043 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 2512 samples: 0.7865
Epoch 1/1, Loss after 2592 samples: 0.2178
Epoch 1/1, Loss after 2792 samples: 0.3208
Epoch 1/1, Loss after 2992 samples: 0.2782
Average Loss on fact answering task after 3016 samples: 8.0471
Average Loss on fact answering task after 3016 samples: 8.1772
Average Loss on fact answering task after 3016 samples: 8.1502
Average Loss on fact answering task after 3016 samples: 8.0870
Average Loss on fact answering task after 3016 samples: 8.0120
Mean accuracy: 0.9047, std: 0.0066, lower bound: 0.8915, upper bound: 0.9178 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 3016 samples: 0.9047
Best model with eval accuracy 0.9046653144016227 with 3016 samples seen is saved
Epoch 1/1, Loss after 3192 samples: 0.2492
Epoch 1/1, Loss after 3392 samples: 0.2805
Average Loss on fact answering task after 3520 samples: 7.6157
Average Loss on fact answering task after 3520 samples: 7.4067
Average Loss on fact answering task after 3520 samples: 7.3722
Average Loss on fact answering task after 3520 samples: 7.4404
Average Loss on fact answering task after 3520 samples: 7.2911
Mean accuracy: 0.9107, std: 0.0066, lower bound: 0.8976, upper bound: 0.9234 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 3520 samples: 0.9108
Best model with eval accuracy 0.9107505070993914 with 3520 samples seen is saved
Epoch 1/1, Loss after 3592 samples: 0.3280
Epoch 1/1, Loss after 3792 samples: 0.2356
Epoch 1/1, Loss after 3992 samples: 0.2283
Average Loss on fact answering task after 4024 samples: 7.9211
Average Loss on fact answering task after 4024 samples: 7.5116
Average Loss on fact answering task after 4024 samples: 7.5757
Average Loss on fact answering task after 4024 samples: 7.5779
Average Loss on fact answering task after 4024 samples: 7.6091
Mean accuracy: 0.9146, std: 0.0065, lower bound: 0.9021, upper bound: 0.9270 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 4024 samples: 0.9148
Best model with eval accuracy 0.9148073022312373 with 4024 samples seen is saved
Epoch 1/1, Loss after 4192 samples: 0.3966
Epoch 1/1, Loss after 4392 samples: 0.3214
Average Loss on fact answering task after 4528 samples: 7.5689
Average Loss on fact answering task after 4528 samples: 7.4561
Average Loss on fact answering task after 4528 samples: 7.5707
Average Loss on fact answering task after 4528 samples: 7.4483
Average Loss on fact answering task after 4528 samples: 7.5666
Mean accuracy: 0.8969, std: 0.0067, lower bound: 0.8839, upper bound: 0.9097 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 4528 samples: 0.8971
Epoch 1/1, Loss after 4592 samples: 0.1712
Epoch 1/1, Loss after 4792 samples: 0.1656
Epoch 1/1, Loss after 4992 samples: 0.2268
Average Loss on fact answering task after 5032 samples: 7.2054
Average Loss on fact answering task after 5032 samples: 7.1980
Average Loss on fact answering task after 5032 samples: 7.4593
Average Loss on fact answering task after 5032 samples: 7.3374
Average Loss on fact answering task after 5032 samples: 7.3458
Mean accuracy: 0.9284, std: 0.0059, lower bound: 0.9173, upper bound: 0.9397 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 5032 samples: 0.9285
Best model with eval accuracy 0.928498985801217 with 5032 samples seen is saved
Epoch 1/1, Loss after 5192 samples: 0.1658
Epoch 1/1, Loss after 5392 samples: 0.2077
Average Loss on fact answering task after 5536 samples: 7.6014
Average Loss on fact answering task after 5536 samples: 7.4651
Average Loss on fact answering task after 5536 samples: 7.3523
Average Loss on fact answering task after 5536 samples: 7.3267
Average Loss on fact answering task after 5536 samples: 7.3123
Mean accuracy: 0.9101, std: 0.0068, lower bound: 0.8966, upper bound: 0.9234 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 5536 samples: 0.9102
Epoch 1/1, Loss after 5592 samples: 0.2512
Epoch 1/1, Loss after 5792 samples: 0.2246
Epoch 1/1, Loss after 5992 samples: 0.2226
Average Loss on fact answering task after 6040 samples: 7.7059
Average Loss on fact answering task after 6040 samples: 7.8319
Average Loss on fact answering task after 6040 samples: 7.9572
Average Loss on fact answering task after 6040 samples: 7.6509
Average Loss on fact answering task after 6040 samples: 7.8650
Mean accuracy: 0.8567, std: 0.0079, lower bound: 0.8403, upper bound: 0.8712 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 6040 samples: 0.8565
Epoch 1/1, Loss after 6192 samples: 0.2675
Epoch 1/1, Loss after 6392 samples: 0.1961
Average Loss on fact answering task after 6544 samples: 7.5674
Average Loss on fact answering task after 6544 samples: 7.5471
Average Loss on fact answering task after 6544 samples: 7.3756
Average Loss on fact answering task after 6544 samples: 7.6508
Average Loss on fact answering task after 6544 samples: 7.5390
Mean accuracy: 0.8746, std: 0.0075, lower bound: 0.8590, upper bound: 0.8890 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 6544 samples: 0.8742
Epoch 1/1, Loss after 6592 samples: 0.2552
Epoch 1/1, Loss after 6792 samples: 0.1521
Epoch 1/1, Loss after 6992 samples: 0.1796
Average Loss on fact answering task after 7048 samples: 7.5806
Average Loss on fact answering task after 7048 samples: 7.4345
Average Loss on fact answering task after 7048 samples: 7.4284
Average Loss on fact answering task after 7048 samples: 7.4226
Average Loss on fact answering task after 7048 samples: 7.5222
Mean accuracy: 0.9187, std: 0.0060, lower bound: 0.9072, upper bound: 0.9305 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 7048 samples: 0.9184
Epoch 1/1, Loss after 7192 samples: 0.1996
Epoch 1/1, Loss after 7392 samples: 0.1681
Average Loss on fact answering task after 7552 samples: 7.7866
Average Loss on fact answering task after 7552 samples: 7.8925
Average Loss on fact answering task after 7552 samples: 7.8948
Average Loss on fact answering task after 7552 samples: 7.6387
Average Loss on fact answering task after 7552 samples: 7.8800
Mean accuracy: 0.8998, std: 0.0068, lower bound: 0.8869, upper bound: 0.9133 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 7552 samples: 0.8996
Epoch 1/1, Loss after 7592 samples: 0.1884
Epoch 1/1, Loss after 7792 samples: 0.1782
Epoch 1/1, Loss after 7992 samples: 0.1977
Average Loss on fact answering task after 8056 samples: 7.8384
Average Loss on fact answering task after 8056 samples: 7.8240
Average Loss on fact answering task after 8056 samples: 7.9107
Average Loss on fact answering task after 8056 samples: 7.7373
Average Loss on fact answering task after 8056 samples: 7.7099
Mean accuracy: 0.9197, std: 0.0061, lower bound: 0.9072, upper bound: 0.9315 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 8056 samples: 0.9199
Epoch 1/1, Loss after 8192 samples: 0.1182
Epoch 1/1, Loss after 8392 samples: 0.1749
Average Loss on fact answering task after 8560 samples: 7.8952
Average Loss on fact answering task after 8560 samples: 7.9675
Average Loss on fact answering task after 8560 samples: 7.9453
Average Loss on fact answering task after 8560 samples: 7.7846
Average Loss on fact answering task after 8560 samples: 7.9653
Mean accuracy: 0.9065, std: 0.0068, lower bound: 0.8925, upper bound: 0.9199 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 8560 samples: 0.9067
Epoch 1/1, Loss after 8592 samples: 0.1521
Epoch 1/1, Loss after 8792 samples: 0.1616
Epoch 1/1, Loss after 8992 samples: 0.1191
Average Loss on fact answering task after 9064 samples: 7.8301
Average Loss on fact answering task after 9064 samples: 7.5965
Average Loss on fact answering task after 9064 samples: 7.7347
Average Loss on fact answering task after 9064 samples: 7.9203
Average Loss on fact answering task after 9064 samples: 7.6529
Mean accuracy: 0.9033, std: 0.0065, lower bound: 0.8905, upper bound: 0.9153 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 9064 samples: 0.9037
Epoch 1/1, Loss after 9192 samples: 0.1558
Epoch 1/1, Loss after 9392 samples: 0.1790
Average Loss on fact answering task after 9568 samples: 7.6070
Average Loss on fact answering task after 9568 samples: 7.4523
Average Loss on fact answering task after 9568 samples: 7.5063
Average Loss on fact answering task after 9568 samples: 7.4461
Average Loss on fact answering task after 9568 samples: 7.4082
Mean accuracy: 0.8995, std: 0.0068, lower bound: 0.8859, upper bound: 0.9133 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 9568 samples: 0.8996
Epoch 1/1, Loss after 9592 samples: 0.1728
Epoch 1/1, Loss after 9792 samples: 0.1663
Epoch 1/1, Loss after 9992 samples: 0.1662
Average Loss on fact answering task after 10072 samples: 7.4233
Average Loss on fact answering task after 10072 samples: 7.6107
Average Loss on fact answering task after 10072 samples: 7.4360
Average Loss on fact answering task after 10072 samples: 7.5313
Average Loss on fact answering task after 10072 samples: 7.2283
Mean accuracy: 0.9335, std: 0.0059, lower bound: 0.9219, upper bound: 0.9447 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 10072 samples: 0.9336
Best model with eval accuracy 0.9335699797160243 with 10072 samples seen is saved
Epoch 1/1, Loss after 10192 samples: 0.1854
Epoch 1/1, Loss after 10392 samples: 0.1435
Average Loss on fact answering task after 10576 samples: 7.6498
Average Loss on fact answering task after 10576 samples: 7.3378
Average Loss on fact answering task after 10576 samples: 7.5132
Average Loss on fact answering task after 10576 samples: 7.7657
Average Loss on fact answering task after 10576 samples: 7.5932
Mean accuracy: 0.9298, std: 0.0057, lower bound: 0.9189, upper bound: 0.9407 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 10576 samples: 0.9300
Epoch 1/1, Loss after 10592 samples: 0.1634
Epoch 1/1, Loss after 10792 samples: 0.1347
Epoch 1/1, Loss after 10992 samples: 0.1127
Average Loss on fact answering task after 11080 samples: 7.5780
Average Loss on fact answering task after 11080 samples: 7.6042
Average Loss on fact answering task after 11080 samples: 7.6639
Average Loss on fact answering task after 11080 samples: 7.3266
Average Loss on fact answering task after 11080 samples: 7.5384
Mean accuracy: 0.9337, std: 0.0055, lower bound: 0.9229, upper bound: 0.9442 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 11080 samples: 0.9336
Epoch 1/1, Loss after 11192 samples: 0.1090
Epoch 1/1, Loss after 11392 samples: 0.1408
Average Loss on fact answering task after 11584 samples: 7.4185
Average Loss on fact answering task after 11584 samples: 7.6198
Average Loss on fact answering task after 11584 samples: 7.5509
Average Loss on fact answering task after 11584 samples: 7.5628
Average Loss on fact answering task after 11584 samples: 7.7788
Mean accuracy: 0.9487, std: 0.0048, lower bound: 0.9391, upper bound: 0.9579 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 11584 samples: 0.9488
Best model with eval accuracy 0.9487829614604463 with 11584 samples seen is saved
Epoch 1/1, Loss after 11592 samples: 0.1133
Epoch 1/1, Loss after 11792 samples: 0.1534
Epoch 1/1, Loss after 11992 samples: 0.1527
Average Loss on fact answering task after 12088 samples: 7.6313
Average Loss on fact answering task after 12088 samples: 7.7095
Average Loss on fact answering task after 12088 samples: 7.6376
Average Loss on fact answering task after 12088 samples: 7.5200
Average Loss on fact answering task after 12088 samples: 7.6452
Mean accuracy: 0.9419, std: 0.0054, lower bound: 0.9310, upper bound: 0.9518 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 12088 samples: 0.9422
Epoch 1/1, Loss after 12192 samples: 0.1617
Epoch 1/1, Loss after 12392 samples: 0.1492
Epoch 1/1, Loss after 12592 samples: 0.0934
Average Loss on fact answering task after 12592 samples: 7.6590
Average Loss on fact answering task after 12592 samples: 7.3800
Average Loss on fact answering task after 12592 samples: 7.5295
Average Loss on fact answering task after 12592 samples: 7.7530
Average Loss on fact answering task after 12592 samples: 7.6792
Mean accuracy: 0.8720, std: 0.0076, lower bound: 0.8570, upper bound: 0.8869 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 12592 samples: 0.8717
Epoch 1/1, Loss after 12792 samples: 0.1894
Epoch 1/1, Loss after 12992 samples: 0.1439
Average Loss on fact answering task after 13096 samples: 7.4297
Average Loss on fact answering task after 13096 samples: 7.5283
Average Loss on fact answering task after 13096 samples: 7.4151
Average Loss on fact answering task after 13096 samples: 7.5170
Average Loss on fact answering task after 13096 samples: 7.8397
Mean accuracy: 0.9193, std: 0.0064, lower bound: 0.9072, upper bound: 0.9321 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 13096 samples: 0.9194
Epoch 1/1, Loss after 13192 samples: 0.0833
Epoch 1/1, Loss after 13392 samples: 0.1355
Epoch 1/1, Loss after 13592 samples: 0.0940
Average Loss on fact answering task after 13600 samples: 7.8725
Average Loss on fact answering task after 13600 samples: 7.9506
Average Loss on fact answering task after 13600 samples: 7.5926
Average Loss on fact answering task after 13600 samples: 7.7001
Average Loss on fact answering task after 13600 samples: 7.6657
Mean accuracy: 0.9154, std: 0.0060, lower bound: 0.9036, upper bound: 0.9270 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 13600 samples: 0.9153
Epoch 1/1, Loss after 13792 samples: 0.1560
Epoch 1/1, Loss after 13992 samples: 0.1320
Average Loss on fact answering task after 14104 samples: 7.7707
Average Loss on fact answering task after 14104 samples: 7.7153
Average Loss on fact answering task after 14104 samples: 7.6527
Average Loss on fact answering task after 14104 samples: 7.7800
Average Loss on fact answering task after 14104 samples: 7.5741
Mean accuracy: 0.9302, std: 0.0057, lower bound: 0.9184, upper bound: 0.9412 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 14104 samples: 0.9300
Epoch 1/1, Loss after 14192 samples: 0.1652
Epoch 1/1, Loss after 14392 samples: 0.1402
Epoch 1/1, Loss after 14592 samples: 0.1055
Average Loss on fact answering task after 14608 samples: 7.7528
Average Loss on fact answering task after 14608 samples: 7.7334
Average Loss on fact answering task after 14608 samples: 7.7508
Average Loss on fact answering task after 14608 samples: 7.7621
Average Loss on fact answering task after 14608 samples: 7.5118
Mean accuracy: 0.9381, std: 0.0059, lower bound: 0.9265, upper bound: 0.9493 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 14608 samples: 0.9381
Epoch 1/1, Loss after 14792 samples: 0.1644
Epoch 1/1, Loss after 14992 samples: 0.1138
Average Loss on fact answering task after 15112 samples: 7.4378
Average Loss on fact answering task after 15112 samples: 7.7767
Average Loss on fact answering task after 15112 samples: 7.5318
Average Loss on fact answering task after 15112 samples: 7.6434
Average Loss on fact answering task after 15112 samples: 7.7027
Mean accuracy: 0.9215, std: 0.0061, lower bound: 0.9092, upper bound: 0.9331 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 15112 samples: 0.9214
Epoch 1/1, Loss after 15192 samples: 0.1324
Epoch 1/1, Loss after 15392 samples: 0.1234
Epoch 1/1, Loss after 15592 samples: 0.1226
Average Loss on fact answering task after 15616 samples: 7.7213
Average Loss on fact answering task after 15616 samples: 7.8566
Average Loss on fact answering task after 15616 samples: 7.8061
Average Loss on fact answering task after 15616 samples: 7.6863
Average Loss on fact answering task after 15616 samples: 7.5223
Mean accuracy: 0.9134, std: 0.0066, lower bound: 0.9006, upper bound: 0.9260 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 15616 samples: 0.9138
Training signal is False, stopping training
Training finished
Best model: {'eval_acc': 0.9487829614604463, 'nb_samples': 11584}
Training loss logs: [{'samples': 192, 'loss': 0.69607666015625}, {'samples': 392, 'loss': 0.6901513671875}, {'samples': 592, 'loss': 0.68751220703125}, {'samples': 792, 'loss': 0.650281982421875}, {'samples': 992, 'loss': 0.58377685546875}, {'samples': 1192, 'loss': 0.5270517349243165}, {'samples': 1392, 'loss': 0.4121199035644531}, {'samples': 1592, 'loss': 0.3237478446960449}, {'samples': 1792, 'loss': 0.3622766709327698}, {'samples': 1992, 'loss': 0.28462648391723633}, {'samples': 2192, 'loss': 0.46205878257751465}, {'samples': 2392, 'loss': 0.3049456214904785}, {'samples': 2592, 'loss': 0.21780382871627807}, {'samples': 2792, 'loss': 0.3208333683013916}, {'samples': 2992, 'loss': 0.2782395648956299}, {'samples': 3192, 'loss': 0.24917978048324585}, {'samples': 3392, 'loss': 0.2804997968673706}, {'samples': 3592, 'loss': 0.327956907749176}, {'samples': 3792, 'loss': 0.23563751459121704}, {'samples': 3992, 'loss': 0.22834824562072753}, {'samples': 4192, 'loss': 0.396558895111084}, {'samples': 4392, 'loss': 0.3214025187492371}, {'samples': 4592, 'loss': 0.17124777793884277}, {'samples': 4792, 'loss': 0.16560678720474242}, {'samples': 4992, 'loss': 0.2268004059791565}, {'samples': 5192, 'loss': 0.1657634496688843}, {'samples': 5392, 'loss': 0.20766263127326964}, {'samples': 5592, 'loss': 0.2511528277397156}, {'samples': 5792, 'loss': 0.2246366000175476}, {'samples': 5992, 'loss': 0.2225702691078186}, {'samples': 6192, 'loss': 0.2675100266933441}, {'samples': 6392, 'loss': 0.19605665922164917}, {'samples': 6592, 'loss': 0.25516664862632754}, {'samples': 6792, 'loss': 0.1521427857875824}, {'samples': 6992, 'loss': 0.17961270809173585}, {'samples': 7192, 'loss': 0.19955217003822326}, {'samples': 7392, 'loss': 0.1681029224395752}, {'samples': 7592, 'loss': 0.18839139938354493}, {'samples': 7792, 'loss': 0.17817267417907715}, {'samples': 7992, 'loss': 0.1976757514476776}, {'samples': 8192, 'loss': 0.11821120738983154}, {'samples': 8392, 'loss': 0.17489962935447692}, {'samples': 8592, 'loss': 0.15208834052085876}, {'samples': 8792, 'loss': 0.16160499095916747}, {'samples': 8992, 'loss': 0.11914533138275146}, {'samples': 9192, 'loss': 0.15576555132865905}, {'samples': 9392, 'loss': 0.17904795408248902}, {'samples': 9592, 'loss': 0.1727585506439209}, {'samples': 9792, 'loss': 0.16626072645187379}, {'samples': 9992, 'loss': 0.16623758435249328}, {'samples': 10192, 'loss': 0.1853501856327057}, {'samples': 10392, 'loss': 0.1434640669822693}, {'samples': 10592, 'loss': 0.1634056043624878}, {'samples': 10792, 'loss': 0.13467582702636718}, {'samples': 10992, 'loss': 0.1126978850364685}, {'samples': 11192, 'loss': 0.10899518251419067}, {'samples': 11392, 'loss': 0.14075928270816804}, {'samples': 11592, 'loss': 0.11328979015350342}, {'samples': 11792, 'loss': 0.15342432677745818}, {'samples': 11992, 'loss': 0.15268004536628724}, {'samples': 12192, 'loss': 0.1617234480381012}, {'samples': 12392, 'loss': 0.14919209361076355}, {'samples': 12592, 'loss': 0.093397616147995}, {'samples': 12792, 'loss': 0.18938440084457397}, {'samples': 12992, 'loss': 0.14393184185028077}, {'samples': 13192, 'loss': 0.08332505643367767}, {'samples': 13392, 'loss': 0.1355063408613205}, {'samples': 13592, 'loss': 0.09402824640274048}, {'samples': 13792, 'loss': 0.15598482191562651}, {'samples': 13992, 'loss': 0.13202665448188783}, {'samples': 14192, 'loss': 0.1651831352710724}, {'samples': 14392, 'loss': 0.14015021026134492}, {'samples': 14592, 'loss': 0.10553366303443909}, {'samples': 14792, 'loss': 0.1643610966205597}, {'samples': 14992, 'loss': 0.11382662475109101}, {'samples': 15192, 'loss': 0.1324350678920746}, {'samples': 15392, 'loss': 0.12344937205314636}, {'samples': 15592, 'loss': 0.12258045852184296}]
Evaluation accuracy logs: [{'samples': 496, 'accuracy': 0.6816054766734281, 'std': 0.01082153100288413, 'lower_bound': 0.6587094320486815, 'upper_bound': 0.7023326572008114}, {'samples': 1000, 'accuracy': 0.5265212981744422, 'std': 0.010935889664555378, 'lower_bound': 0.5045638945233266, 'upper_bound': 0.5476673427991886}, {'samples': 1504, 'accuracy': 0.8318174442190668, 'std': 0.008505005686325317, 'lower_bound': 0.8154031440162272, 'upper_bound': 0.847882860040568}, {'samples': 2008, 'accuracy': 0.8058093306288032, 'std': 0.009406206610571136, 'lower_bound': 0.787525354969574, 'upper_bound': 0.8240365111561866}, {'samples': 2512, 'accuracy': 0.7858869168356998, 'std': 0.009359901484099173, 'lower_bound': 0.7682429006085192, 'upper_bound': 0.8042596348884381}, {'samples': 3016, 'accuracy': 0.9047089249492901, 'std': 0.006598230357109377, 'lower_bound': 0.8914807302231237, 'upper_bound': 0.9178498985801217}, {'samples': 3520, 'accuracy': 0.9106678498985802, 'std': 0.006568306164905415, 'lower_bound': 0.8975659229208925, 'upper_bound': 0.9234279918864098}, {'samples': 4024, 'accuracy': 0.9145953346855985, 'std': 0.00645024198816689, 'lower_bound': 0.902129817444219, 'upper_bound': 0.9269776876267748}, {'samples': 4528, 'accuracy': 0.8968950304259634, 'std': 0.0067332922054506444, 'lower_bound': 0.8838742393509128, 'upper_bound': 0.90973630831643}, {'samples': 5032, 'accuracy': 0.9283686612576065, 'std': 0.005888359679678091, 'lower_bound': 0.9173427991886409, 'upper_bound': 0.9396551724137931}, {'samples': 5536, 'accuracy': 0.9101140973630831, 'std': 0.006759350994313869, 'lower_bound': 0.896551724137931, 'upper_bound': 0.9234279918864098}, {'samples': 6040, 'accuracy': 0.8566632860040567, 'std': 0.007927220593337257, 'lower_bound': 0.84026369168357, 'upper_bound': 0.8712094320486816}, {'samples': 6544, 'accuracy': 0.8745552738336715, 'std': 0.00748748815783484, 'lower_bound': 0.859026369168357, 'upper_bound': 0.8889579107505071}, {'samples': 7048, 'accuracy': 0.9187119675456389, 'std': 0.005980247870200154, 'lower_bound': 0.9072008113590264, 'upper_bound': 0.930540060851927}, {'samples': 7552, 'accuracy': 0.899843813387424, 'std': 0.006825262735906896, 'lower_bound': 0.8869041582150101, 'upper_bound': 0.9132860040567952}, {'samples': 8056, 'accuracy': 0.919684584178499, 'std': 0.006116679777695222, 'lower_bound': 0.9072008113590264, 'upper_bound': 0.9315415821501014}, {'samples': 8560, 'accuracy': 0.9064538539553753, 'std': 0.006815183227189891, 'lower_bound': 0.8924949290060852, 'upper_bound': 0.9198782961460447}, {'samples': 9064, 'accuracy': 0.9032738336713996, 'std': 0.006527227358937034, 'lower_bound': 0.8904665314401623, 'upper_bound': 0.9153270791075051}, {'samples': 9568, 'accuracy': 0.8995466531440162, 'std': 0.006779999726435095, 'lower_bound': 0.8858899594320486, 'upper_bound': 0.9132860040567952}, {'samples': 10072, 'accuracy': 0.9335456389452332, 'std': 0.00588662885788013, 'lower_bound': 0.9219066937119675, 'upper_bound': 0.9447261663286004}, {'samples': 10576, 'accuracy': 0.9297662271805274, 'std': 0.00572892154795484, 'lower_bound': 0.9188640973630832, 'upper_bound': 0.9406693711967545}, {'samples': 11080, 'accuracy': 0.9336744421906694, 'std': 0.005522998335050615, 'lower_bound': 0.922920892494929, 'upper_bound': 0.9442317444219067}, {'samples': 11584, 'accuracy': 0.9486866125760649, 'std': 0.004844747545156108, 'lower_bound': 0.9391480730223124, 'upper_bound': 0.9579107505070994}, {'samples': 12088, 'accuracy': 0.9418539553752535, 'std': 0.005353372741200828, 'lower_bound': 0.9310218052738336, 'upper_bound': 0.9518382352941177}, {'samples': 12592, 'accuracy': 0.8719802231237322, 'std': 0.007604597042808095, 'lower_bound': 0.8569979716024341, 'upper_bound': 0.8869295131845842}, {'samples': 13096, 'accuracy': 0.9193149087221095, 'std': 0.006415853064386667, 'lower_bound': 0.9072008113590264, 'upper_bound': 0.9320613590263692}, {'samples': 13600, 'accuracy': 0.9154269776876267, 'std': 0.005992891855062559, 'lower_bound': 0.9036384381338742, 'upper_bound': 0.9269776876267748}, {'samples': 14104, 'accuracy': 0.9302261663286003, 'std': 0.005694777282440345, 'lower_bound': 0.9183569979716024, 'upper_bound': 0.9411764705882353}, {'samples': 14608, 'accuracy': 0.9380780933062881, 'std': 0.00592516724677978, 'lower_bound': 0.9264579107505071, 'upper_bound': 0.949302738336714}, {'samples': 15112, 'accuracy': 0.9214974645030426, 'std': 0.006059991574680618, 'lower_bound': 0.9092292089249493, 'upper_bound': 0.9330628803245437}, {'samples': 15616, 'accuracy': 0.913357505070994, 'std': 0.006580913862191252, 'lower_bound': 0.9006085192697769, 'upper_bound': 0.9259761663286005}]
