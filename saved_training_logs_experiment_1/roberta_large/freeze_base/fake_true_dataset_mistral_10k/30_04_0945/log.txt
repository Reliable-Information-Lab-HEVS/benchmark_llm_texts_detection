log_loss_steps: 256
eval_steps: 512
check_degradation: 512
Average Loss on fact answering task after 0 samples: 5.0322
Average Loss on fact answering task after 0 samples: 5.3341
Average Loss on fact answering task after 0 samples: 5.3146
Average Loss on fact answering task after 0 samples: 5.2945
Average Loss on fact answering task after 0 samples: 5.2691
----------------Epoch 1/1----------------
Epoch 1/1, Loss after 192 samples: 0.7084
Epoch 1/1, Loss after 448 samples: 0.7045
Average Loss on fact answering task after 448 samples: 5.2867
Average Loss on fact answering task after 448 samples: 5.1131
Average Loss on fact answering task after 448 samples: 5.1505
Average Loss on fact answering task after 448 samples: 5.2840
Average Loss on fact answering task after 448 samples: 5.2752
Mean accuracy: 0.5005, std: 0.0112, lower bound: 0.4792, upper bound: 0.5233 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 448 samples: 0.5005
Best model with eval accuracy 0.5005070993914807 with 448 samples seen is saved
Epoch 1/1, Loss after 704 samples: 0.6919
Epoch 1/1, Loss after 960 samples: 0.6622
Average Loss on fact answering task after 960 samples: 5.1631
Average Loss on fact answering task after 960 samples: 5.3394
Average Loss on fact answering task after 960 samples: 5.1008
Average Loss on fact answering task after 960 samples: 5.4427
Average Loss on fact answering task after 960 samples: 5.2349
Mean accuracy: 0.6154, std: 0.0108, lower bound: 0.5938, upper bound: 0.6369 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 960 samples: 0.6151
Best model with eval accuracy 0.6151115618661258 with 960 samples seen is saved
Epoch 1/1, Loss after 1216 samples: 0.6232
Epoch 1/1, Loss after 1472 samples: 0.6123
Average Loss on fact answering task after 1472 samples: 5.4168
Average Loss on fact answering task after 1472 samples: 5.0697
Average Loss on fact answering task after 1472 samples: 5.3991
Average Loss on fact answering task after 1472 samples: 5.4420
Average Loss on fact answering task after 1472 samples: 4.9979
Mean accuracy: 0.6818, std: 0.0106, lower bound: 0.6613, upper bound: 0.7028 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 1472 samples: 0.6815
Best model with eval accuracy 0.6815415821501014 with 1472 samples seen is saved
Epoch 1/1, Loss after 1728 samples: 0.6079
Epoch 1/1, Loss after 1984 samples: 0.5853
Average Loss on fact answering task after 1984 samples: 5.1735
Average Loss on fact answering task after 1984 samples: 5.1941
Average Loss on fact answering task after 1984 samples: 5.2942
Average Loss on fact answering task after 1984 samples: 5.2846
Average Loss on fact answering task after 1984 samples: 5.1804
Mean accuracy: 0.6523, std: 0.0105, lower bound: 0.6298, upper bound: 0.6724 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 1984 samples: 0.6521
Epoch 1/1, Loss after 2240 samples: 0.5361
Epoch 1/1, Loss after 2496 samples: 0.5253
Average Loss on fact answering task after 2496 samples: 5.1996
Average Loss on fact answering task after 2496 samples: 5.3000
Average Loss on fact answering task after 2496 samples: 5.2095
Average Loss on fact answering task after 2496 samples: 5.1869
Average Loss on fact answering task after 2496 samples: 5.2639
Mean accuracy: 0.7555, std: 0.0097, lower bound: 0.7363, upper bound: 0.7743 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 2496 samples: 0.7556
Best model with eval accuracy 0.755578093306288 with 2496 samples seen is saved
Epoch 1/1, Loss after 2752 samples: 0.4819
Epoch 1/1, Loss after 3008 samples: 0.5287
Average Loss on fact answering task after 3008 samples: 5.2757
Average Loss on fact answering task after 3008 samples: 5.3381
Average Loss on fact answering task after 3008 samples: 5.1891
Average Loss on fact answering task after 3008 samples: 5.1901
Average Loss on fact answering task after 3008 samples: 5.1631
Mean accuracy: 0.7672, std: 0.0094, lower bound: 0.7490, upper bound: 0.7870 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 3008 samples: 0.7672
Best model with eval accuracy 0.7672413793103449 with 3008 samples seen is saved
Epoch 1/1, Loss after 3264 samples: 0.5526
Epoch 1/1, Loss after 3520 samples: 0.5314
Average Loss on fact answering task after 3520 samples: 5.2613
Average Loss on fact answering task after 3520 samples: 5.1835
Average Loss on fact answering task after 3520 samples: 5.2102
Average Loss on fact answering task after 3520 samples: 5.3644
Average Loss on fact answering task after 3520 samples: 5.1479
Mean accuracy: 0.7503, std: 0.0098, lower bound: 0.7312, upper bound: 0.7698 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 3520 samples: 0.7500
Epoch 1/1, Loss after 3776 samples: 0.5350
Epoch 1/1, Loss after 4032 samples: 0.5208
Average Loss on fact answering task after 4032 samples: 5.2135
Average Loss on fact answering task after 4032 samples: 5.3669
Average Loss on fact answering task after 4032 samples: 5.2528
Average Loss on fact answering task after 4032 samples: 5.1437
Average Loss on fact answering task after 4032 samples: 5.3757
Mean accuracy: 0.7526, std: 0.0096, lower bound: 0.7343, upper bound: 0.7728 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 4032 samples: 0.7525
Epoch 1/1, Loss after 4288 samples: 0.5474
Epoch 1/1, Loss after 4544 samples: 0.5153
Average Loss on fact answering task after 4544 samples: 5.1849
Average Loss on fact answering task after 4544 samples: 5.1630
Average Loss on fact answering task after 4544 samples: 5.1788
Average Loss on fact answering task after 4544 samples: 5.3966
Average Loss on fact answering task after 4544 samples: 5.1753
Mean accuracy: 0.7891, std: 0.0094, lower bound: 0.7713, upper bound: 0.8083 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 4544 samples: 0.7890
Best model with eval accuracy 0.7890466531440162 with 4544 samples seen is saved
Epoch 1/1, Loss after 4800 samples: 0.4703
Epoch 1/1, Loss after 5056 samples: 0.4555
Average Loss on fact answering task after 5056 samples: 5.0233
Average Loss on fact answering task after 5056 samples: 5.1038
Average Loss on fact answering task after 5056 samples: 5.4905
Average Loss on fact answering task after 5056 samples: 5.3047
Average Loss on fact answering task after 5056 samples: 5.3547
Mean accuracy: 0.7953, std: 0.0090, lower bound: 0.7779, upper bound: 0.8119 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 5056 samples: 0.7951
Best model with eval accuracy 0.795131845841785 with 5056 samples seen is saved
Epoch 1/1, Loss after 5312 samples: 0.4713
Epoch 1/1, Loss after 5568 samples: 0.4582
Average Loss on fact answering task after 5568 samples: 5.1739
Average Loss on fact answering task after 5568 samples: 5.4011
Average Loss on fact answering task after 5568 samples: 5.2057
Average Loss on fact answering task after 5568 samples: 5.0961
Average Loss on fact answering task after 5568 samples: 5.0856
Mean accuracy: 0.8047, std: 0.0089, lower bound: 0.7870, upper bound: 0.8225 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 5568 samples: 0.8048
Best model with eval accuracy 0.8047667342799188 with 5568 samples seen is saved
Epoch 1/1, Loss after 5824 samples: 0.4966
Epoch 1/1, Loss after 6080 samples: 0.5239
Average Loss on fact answering task after 6080 samples: 5.2675
Average Loss on fact answering task after 6080 samples: 5.4459
Average Loss on fact answering task after 6080 samples: 5.2267
Average Loss on fact answering task after 6080 samples: 5.3750
Average Loss on fact answering task after 6080 samples: 5.2854
Mean accuracy: 0.7987, std: 0.0093, lower bound: 0.7794, upper bound: 0.8154 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 6080 samples: 0.7987
Epoch 1/1, Loss after 6336 samples: 0.5042
Epoch 1/1, Loss after 6592 samples: 0.4839
Average Loss on fact answering task after 6592 samples: 5.2998
Average Loss on fact answering task after 6592 samples: 5.2552
Average Loss on fact answering task after 6592 samples: 5.1824
Average Loss on fact answering task after 6592 samples: 5.2298
Average Loss on fact answering task after 6592 samples: 5.2839
Mean accuracy: 0.7747, std: 0.0092, lower bound: 0.7566, upper bound: 0.7931 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 6592 samples: 0.7743
Epoch 1/1, Loss after 6848 samples: 0.5100
Epoch 1/1, Loss after 7104 samples: 0.4678
Average Loss on fact answering task after 7104 samples: 5.1510
Average Loss on fact answering task after 7104 samples: 5.3240
Average Loss on fact answering task after 7104 samples: 5.4852
Average Loss on fact answering task after 7104 samples: 5.1645
Average Loss on fact answering task after 7104 samples: 5.2435
Mean accuracy: 0.7632, std: 0.0095, lower bound: 0.7454, upper bound: 0.7819 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 7104 samples: 0.7632
Epoch 1/1, Loss after 7360 samples: 0.4895
Epoch 1/1, Loss after 7616 samples: 0.4932
Average Loss on fact answering task after 7616 samples: 5.1652
Average Loss on fact answering task after 7616 samples: 5.1859
Average Loss on fact answering task after 7616 samples: 5.1392
Average Loss on fact answering task after 7616 samples: 5.3088
Average Loss on fact answering task after 7616 samples: 5.3131
Mean accuracy: 0.8069, std: 0.0092, lower bound: 0.7896, upper bound: 0.8240 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 7616 samples: 0.8068
Best model with eval accuracy 0.8067951318458418 with 7616 samples seen is saved
Epoch 1/1, Loss after 7872 samples: 0.4942
Epoch 1/1, Loss after 8128 samples: 0.4807
Average Loss on fact answering task after 8128 samples: 5.0746
Average Loss on fact answering task after 8128 samples: 5.3808
Average Loss on fact answering task after 8128 samples: 5.2114
Average Loss on fact answering task after 8128 samples: 5.3887
Average Loss on fact answering task after 8128 samples: 5.2520
Mean accuracy: 0.8178, std: 0.0089, lower bound: 0.8007, upper bound: 0.8347 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 8128 samples: 0.8180
Best model with eval accuracy 0.8179513184584178 with 8128 samples seen is saved
Epoch 1/1, Loss after 8384 samples: 0.5278
Epoch 1/1, Loss after 8640 samples: 0.5009
Average Loss on fact answering task after 8640 samples: 5.2790
Average Loss on fact answering task after 8640 samples: 5.4013
Average Loss on fact answering task after 8640 samples: 5.3155
Average Loss on fact answering task after 8640 samples: 5.1051
Average Loss on fact answering task after 8640 samples: 5.2331
Mean accuracy: 0.8013, std: 0.0090, lower bound: 0.7835, upper bound: 0.8185 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 8640 samples: 0.8012
Epoch 1/1, Loss after 8896 samples: 0.4718
Epoch 1/1, Loss after 9152 samples: 0.4779
Average Loss on fact answering task after 9152 samples: 5.1251
Average Loss on fact answering task after 9152 samples: 5.3400
Average Loss on fact answering task after 9152 samples: 5.1628
Average Loss on fact answering task after 9152 samples: 5.3809
Average Loss on fact answering task after 9152 samples: 5.4934
Mean accuracy: 0.8013, std: 0.0092, lower bound: 0.7835, upper bound: 0.8195 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 9152 samples: 0.8012
Epoch 1/1, Loss after 9408 samples: 0.4591
Epoch 1/1, Loss after 9664 samples: 0.4923
Average Loss on fact answering task after 9664 samples: 5.1058
Average Loss on fact answering task after 9664 samples: 5.0420
Average Loss on fact answering task after 9664 samples: 5.2285
Average Loss on fact answering task after 9664 samples: 5.3763
Average Loss on fact answering task after 9664 samples: 5.0239
Mean accuracy: 0.7878, std: 0.0094, lower bound: 0.7698, upper bound: 0.8068 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 9664 samples: 0.7880
Epoch 1/1, Loss after 9920 samples: 0.4680
Epoch 1/1, Loss after 10176 samples: 0.4831
Average Loss on fact answering task after 10176 samples: 5.1065
Average Loss on fact answering task after 10176 samples: 5.0539
Average Loss on fact answering task after 10176 samples: 5.0357
Average Loss on fact answering task after 10176 samples: 5.1278
Average Loss on fact answering task after 10176 samples: 5.4313
Mean accuracy: 0.7772, std: 0.0094, lower bound: 0.7591, upper bound: 0.7951 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 10176 samples: 0.7774
Epoch 1/1, Loss after 10432 samples: 0.5446
Epoch 1/1, Loss after 10688 samples: 0.5602
Average Loss on fact answering task after 10688 samples: 5.2559
Average Loss on fact answering task after 10688 samples: 5.2139
Average Loss on fact answering task after 10688 samples: 5.0958
Average Loss on fact answering task after 10688 samples: 5.3970
Average Loss on fact answering task after 10688 samples: 5.2518
Mean accuracy: 0.7686, std: 0.0092, lower bound: 0.7495, upper bound: 0.7855 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 10688 samples: 0.7688
Epoch 1/1, Loss after 10944 samples: 0.5422
Epoch 1/1, Loss after 11200 samples: 0.4742
Average Loss on fact answering task after 11200 samples: 5.3021
Average Loss on fact answering task after 11200 samples: 5.1296
Average Loss on fact answering task after 11200 samples: 5.1352
Average Loss on fact answering task after 11200 samples: 5.3756
Average Loss on fact answering task after 11200 samples: 5.3403
Mean accuracy: 0.8197, std: 0.0088, lower bound: 0.8027, upper bound: 0.8367 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 11200 samples: 0.8195
Best model with eval accuracy 0.8194726166328601 with 11200 samples seen is saved
Epoch 1/1, Loss after 11456 samples: 0.5394
Epoch 1/1, Loss after 11712 samples: 0.5313
Average Loss on fact answering task after 11712 samples: 5.2199
Average Loss on fact answering task after 11712 samples: 5.2392
Average Loss on fact answering task after 11712 samples: 5.0769
Average Loss on fact answering task after 11712 samples: 5.1068
Average Loss on fact answering task after 11712 samples: 5.1611
Mean accuracy: 0.7050, std: 0.0103, lower bound: 0.6846, upper bound: 0.7246 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 11712 samples: 0.7049
Epoch 1/1, Loss after 11968 samples: 0.4619
Epoch 1/1, Loss after 12224 samples: 0.5059
Average Loss on fact answering task after 12224 samples: 5.3497
Average Loss on fact answering task after 12224 samples: 5.1819
Average Loss on fact answering task after 12224 samples: 5.3638
Average Loss on fact answering task after 12224 samples: 5.1882
Average Loss on fact answering task after 12224 samples: 5.1032
Mean accuracy: 0.8263, std: 0.0084, lower bound: 0.8098, upper bound: 0.8418 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 12224 samples: 0.8266
Best model with eval accuracy 0.8265720081135902 with 12224 samples seen is saved
Epoch 1/1, Loss after 12480 samples: 0.4141
Epoch 1/1, Loss after 12736 samples: 0.4757
Average Loss on fact answering task after 12736 samples: 5.1190
Average Loss on fact answering task after 12736 samples: 5.4138
Average Loss on fact answering task after 12736 samples: 5.2477
Average Loss on fact answering task after 12736 samples: 5.2809
Average Loss on fact answering task after 12736 samples: 5.2812
Mean accuracy: 0.8296, std: 0.0087, lower bound: 0.8124, upper bound: 0.8474 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 12736 samples: 0.8301
Best model with eval accuracy 0.8301217038539553 with 12736 samples seen is saved
Epoch 1/1, Loss after 12992 samples: 0.4444
Epoch 1/1, Loss after 13248 samples: 0.4658
Average Loss on fact answering task after 13248 samples: 5.2315
Average Loss on fact answering task after 13248 samples: 5.3102
Average Loss on fact answering task after 13248 samples: 5.3837
Average Loss on fact answering task after 13248 samples: 5.4566
Average Loss on fact answering task after 13248 samples: 5.0086
Mean accuracy: 0.8257, std: 0.0086, lower bound: 0.8088, upper bound: 0.8428 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 13248 samples: 0.8256
Epoch 1/1, Loss after 13504 samples: 0.4418
Epoch 1/1, Loss after 13760 samples: 0.4801
Average Loss on fact answering task after 13760 samples: 5.3460
Average Loss on fact answering task after 13760 samples: 5.1212
Average Loss on fact answering task after 13760 samples: 5.2553
Average Loss on fact answering task after 13760 samples: 5.2356
Average Loss on fact answering task after 13760 samples: 5.2432
Mean accuracy: 0.8191, std: 0.0086, lower bound: 0.8022, upper bound: 0.8352 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 13760 samples: 0.8190
Epoch 1/1, Loss after 14016 samples: 0.4374
Epoch 1/1, Loss after 14272 samples: 0.5051
Average Loss on fact answering task after 14272 samples: 5.0082
Average Loss on fact answering task after 14272 samples: 5.2796
Average Loss on fact answering task after 14272 samples: 5.4532
Average Loss on fact answering task after 14272 samples: 5.2147
Average Loss on fact answering task after 14272 samples: 5.4550
Mean accuracy: 0.8209, std: 0.0084, lower bound: 0.8048, upper bound: 0.8377 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 14272 samples: 0.8210
Epoch 1/1, Loss after 14528 samples: 0.4068
Epoch 1/1, Loss after 14784 samples: 0.4765
Average Loss on fact answering task after 14784 samples: 5.2942
Average Loss on fact answering task after 14784 samples: 5.0612
Average Loss on fact answering task after 14784 samples: 5.1376
Average Loss on fact answering task after 14784 samples: 5.2660
Average Loss on fact answering task after 14784 samples: 5.2377
Mean accuracy: 0.8147, std: 0.0086, lower bound: 0.7982, upper bound: 0.8311 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 14784 samples: 0.8144
Epoch 1/1, Loss after 15040 samples: 0.4875
Epoch 1/1, Loss after 15296 samples: 0.5025
Average Loss on fact answering task after 15296 samples: 5.2754
Average Loss on fact answering task after 15296 samples: 5.1380
Average Loss on fact answering task after 15296 samples: 5.2143
Average Loss on fact answering task after 15296 samples: 5.1250
Average Loss on fact answering task after 15296 samples: 5.3232
Mean accuracy: 0.8179, std: 0.0084, lower bound: 0.8017, upper bound: 0.8342 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 15296 samples: 0.8180
Epoch 1/1, Loss after 15552 samples: 0.4632
Training signal is False, stopping training
Training finished
Best model: {'eval_acc': 0.8301217038539553, 'nb_samples': 12736}
Training loss logs: [{'samples': 192, 'loss': 0.7084360122680664}, {'samples': 448, 'loss': 0.7045068740844727}, {'samples': 704, 'loss': 0.6919255256652832}, {'samples': 960, 'loss': 0.6621785163879395}, {'samples': 1216, 'loss': 0.6232020854949951}, {'samples': 1472, 'loss': 0.6122514009475708}, {'samples': 1728, 'loss': 0.6079004406929016}, {'samples': 1984, 'loss': 0.5852564573287964}, {'samples': 2240, 'loss': 0.5360824465751648}, {'samples': 2496, 'loss': 0.525330513715744}, {'samples': 2752, 'loss': 0.48190903663635254}, {'samples': 3008, 'loss': 0.5287220180034637}, {'samples': 3264, 'loss': 0.5526171326637268}, {'samples': 3520, 'loss': 0.5314289778470993}, {'samples': 3776, 'loss': 0.5349955260753632}, {'samples': 4032, 'loss': 0.520796574652195}, {'samples': 4288, 'loss': 0.547355055809021}, {'samples': 4544, 'loss': 0.5152964890003204}, {'samples': 4800, 'loss': 0.47031576931476593}, {'samples': 5056, 'loss': 0.45554186403751373}, {'samples': 5312, 'loss': 0.4712860509753227}, {'samples': 5568, 'loss': 0.4582061916589737}, {'samples': 5824, 'loss': 0.4965988025069237}, {'samples': 6080, 'loss': 0.5238942131400108}, {'samples': 6336, 'loss': 0.504159227013588}, {'samples': 6592, 'loss': 0.48392540216445923}, {'samples': 6848, 'loss': 0.5100227445363998}, {'samples': 7104, 'loss': 0.4677913933992386}, {'samples': 7360, 'loss': 0.4894835203886032}, {'samples': 7616, 'loss': 0.49321676045656204}, {'samples': 7872, 'loss': 0.4941943734884262}, {'samples': 8128, 'loss': 0.4806691184639931}, {'samples': 8384, 'loss': 0.5278433784842491}, {'samples': 8640, 'loss': 0.5008820593357086}, {'samples': 8896, 'loss': 0.4718218967318535}, {'samples': 9152, 'loss': 0.4778892919421196}, {'samples': 9408, 'loss': 0.45905981957912445}, {'samples': 9664, 'loss': 0.4922575205564499}, {'samples': 9920, 'loss': 0.46799495816230774}, {'samples': 10176, 'loss': 0.4830635190010071}, {'samples': 10432, 'loss': 0.5445816069841385}, {'samples': 10688, 'loss': 0.5602361857891083}, {'samples': 10944, 'loss': 0.5422458201646805}, {'samples': 11200, 'loss': 0.47416774183511734}, {'samples': 11456, 'loss': 0.5393748879432678}, {'samples': 11712, 'loss': 0.5313149392604828}, {'samples': 11968, 'loss': 0.461882583796978}, {'samples': 12224, 'loss': 0.5059148222208023}, {'samples': 12480, 'loss': 0.4141215607523918}, {'samples': 12736, 'loss': 0.4756822735071182}, {'samples': 12992, 'loss': 0.4444483369588852}, {'samples': 13248, 'loss': 0.46575067937374115}, {'samples': 13504, 'loss': 0.44178464263677597}, {'samples': 13760, 'loss': 0.4800914600491524}, {'samples': 14016, 'loss': 0.4373924061655998}, {'samples': 14272, 'loss': 0.5051280707120895}, {'samples': 14528, 'loss': 0.4068225622177124}, {'samples': 14784, 'loss': 0.47646409273147583}, {'samples': 15040, 'loss': 0.487467922270298}, {'samples': 15296, 'loss': 0.5025001540780067}, {'samples': 15552, 'loss': 0.46320048719644547}]
Evaluation accuracy logs: [{'samples': 448, 'accuracy': 0.5004584178498985, 'std': 0.011199560529729116, 'lower_bound': 0.47919624746450307, 'upper_bound': 0.5233265720081136}, {'samples': 960, 'accuracy': 0.615371196754564, 'std': 0.01083577611810276, 'lower_bound': 0.593800709939148, 'upper_bound': 0.6369168356997972}, {'samples': 1472, 'accuracy': 0.6817936105476673, 'std': 0.01060235557921914, 'lower_bound': 0.6612576064908722, 'upper_bound': 0.7028397565922921}, {'samples': 1984, 'accuracy': 0.6522560851926978, 'std': 0.010541485245079685, 'lower_bound': 0.6298174442190669, 'upper_bound': 0.6724137931034483}, {'samples': 2496, 'accuracy': 0.7554822515212982, 'std': 0.009691215714922988, 'lower_bound': 0.7363083164300203, 'upper_bound': 0.7743407707910751}, {'samples': 3008, 'accuracy': 0.7672408722109533, 'std': 0.00943323455161577, 'lower_bound': 0.7489858012170385, 'upper_bound': 0.7870182555780934}, {'samples': 3520, 'accuracy': 0.750253042596349, 'std': 0.009755754105658926, 'lower_bound': 0.731224645030426, 'upper_bound': 0.7697895537525355}, {'samples': 4032, 'accuracy': 0.7526262677484787, 'std': 0.009626276697444473, 'lower_bound': 0.7342799188640974, 'upper_bound': 0.7728194726166329}, {'samples': 4544, 'accuracy': 0.7891080121703853, 'std': 0.009441863295906737, 'lower_bound': 0.7712981744421906, 'upper_bound': 0.808329107505071}, {'samples': 5056, 'accuracy': 0.7953184584178499, 'std': 0.008955216977414564, 'lower_bound': 0.7778904665314401, 'upper_bound': 0.8118661257606491}, {'samples': 5568, 'accuracy': 0.8046541582150102, 'std': 0.008858065759957472, 'lower_bound': 0.7870182555780934, 'upper_bound': 0.8225152129817445}, {'samples': 6080, 'accuracy': 0.7986952332657201, 'std': 0.00932216785832262, 'lower_bound': 0.7794117647058824, 'upper_bound': 0.8154158215010142}, {'samples': 6592, 'accuracy': 0.7746754563894523, 'std': 0.009163727986502961, 'lower_bound': 0.7565922920892495, 'upper_bound': 0.7931034482758621}, {'samples': 7104, 'accuracy': 0.7631866125760648, 'std': 0.009533306502442041, 'lower_bound': 0.7454361054766734, 'upper_bound': 0.781947261663286}, {'samples': 7616, 'accuracy': 0.8069295131845843, 'std': 0.009171250696102043, 'lower_bound': 0.789553752535497, 'upper_bound': 0.8240491886409737}, {'samples': 8128, 'accuracy': 0.8177728194726166, 'std': 0.008904412569705731, 'lower_bound': 0.8006972616632859, 'upper_bound': 0.834685598377282}, {'samples': 8640, 'accuracy': 0.8013362068965517, 'std': 0.009035363920387344, 'lower_bound': 0.7834558823529412, 'upper_bound': 0.8184710953346856}, {'samples': 9152, 'accuracy': 0.8013326572008114, 'std': 0.009229264872888396, 'lower_bound': 0.7834685598377282, 'upper_bound': 0.8194726166328601}, {'samples': 9664, 'accuracy': 0.7877530425963489, 'std': 0.009421865740843798, 'lower_bound': 0.7697768762677485, 'upper_bound': 0.8067951318458418}, {'samples': 10176, 'accuracy': 0.7771916835699797, 'std': 0.009444052156137132, 'lower_bound': 0.7591151115618661, 'upper_bound': 0.795144523326572}, {'samples': 10688, 'accuracy': 0.7685791075050711, 'std': 0.009213633905640613, 'lower_bound': 0.7494802231237322, 'upper_bound': 0.7854969574036511}, {'samples': 11200, 'accuracy': 0.8197028397565923, 'std': 0.00877639312127702, 'lower_bound': 0.802738336713996, 'upper_bound': 0.8367139959432048}, {'samples': 11712, 'accuracy': 0.7049741379310345, 'std': 0.010270926311514135, 'lower_bound': 0.6845715010141987, 'upper_bound': 0.7246450304259635}, {'samples': 12224, 'accuracy': 0.8263473630831643, 'std': 0.008433457009008962, 'lower_bound': 0.8098250507099392, 'upper_bound': 0.8417976673427993}, {'samples': 12736, 'accuracy': 0.8296014198782962, 'std': 0.00871685009360102, 'lower_bound': 0.8123732251521298, 'upper_bound': 0.8473630831643002}, {'samples': 13248, 'accuracy': 0.8256825557809332, 'std': 0.008637191639182867, 'lower_bound': 0.8088235294117647, 'upper_bound': 0.8428118661257606}, {'samples': 13760, 'accuracy': 0.8190786004056795, 'std': 0.008567988159318076, 'lower_bound': 0.8022312373225152, 'upper_bound': 0.8351926977687627}, {'samples': 14272, 'accuracy': 0.820933569979716, 'std': 0.008375016868241813, 'lower_bound': 0.8047667342799188, 'upper_bound': 0.8377281947261663}, {'samples': 14784, 'accuracy': 0.8146906693711968, 'std': 0.008592680605271017, 'lower_bound': 0.7981744421906694, 'upper_bound': 0.8311485801217039}, {'samples': 15296, 'accuracy': 0.8178686612576064, 'std': 0.00836527164278356, 'lower_bound': 0.8017241379310345, 'upper_bound': 0.8341784989858012}]
