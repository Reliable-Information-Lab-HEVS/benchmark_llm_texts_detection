log_loss_steps: 200
eval_steps: 500
check_degradation: 500
Average Loss on fact answering task after 0 samples: 5.1026
Average Loss on fact answering task after 0 samples: 5.2151
Average Loss on fact answering task after 0 samples: 5.2252
Average Loss on fact answering task after 0 samples: 5.0505
Average Loss on fact answering task after 0 samples: 5.2988
----------------Epoch 1/1----------------
Epoch 1/1, Loss after 196 samples: 0.6961
Epoch 1/1, Loss after 396 samples: 0.6736
Average Loss on fact answering task after 496 samples: 5.2663
Average Loss on fact answering task after 496 samples: 5.4595
Average Loss on fact answering task after 496 samples: 5.3418
Average Loss on fact answering task after 496 samples: 5.4779
Average Loss on fact answering task after 496 samples: 5.3573
Mean accuracy: 0.7372, std: 0.0102, lower bound: 0.7185, upper bound: 0.7576 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 496 samples: 0.7373
Best model with eval accuracy 0.7373225152129818 with 496 samples seen is saved
Epoch 1/1, Loss after 596 samples: 0.6300
Epoch 1/1, Loss after 796 samples: 0.5487
Epoch 1/1, Loss after 996 samples: 0.5229
Average Loss on fact answering task after 996 samples: 5.3809
Average Loss on fact answering task after 996 samples: 5.4262
Average Loss on fact answering task after 996 samples: 5.2255
Average Loss on fact answering task after 996 samples: 5.3779
Average Loss on fact answering task after 996 samples: 5.3556
Mean accuracy: 0.8623, std: 0.0077, lower bound: 0.8468, upper bound: 0.8773 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 996 samples: 0.8621
Best model with eval accuracy 0.8620689655172413 with 996 samples seen is saved
Epoch 1/1, Loss after 1196 samples: 0.3938
Epoch 1/1, Loss after 1396 samples: 0.3806
Average Loss on fact answering task after 1496 samples: 6.0875
Average Loss on fact answering task after 1496 samples: 6.0248
Average Loss on fact answering task after 1496 samples: 5.9638
Average Loss on fact answering task after 1496 samples: 6.1422
Average Loss on fact answering task after 1496 samples: 6.0301
Mean accuracy: 0.9075, std: 0.0065, lower bound: 0.8940, upper bound: 0.9204 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 1496 samples: 0.9072
Best model with eval accuracy 0.9072008113590264 with 1496 samples seen is saved
Epoch 1/1, Loss after 1596 samples: 0.2999
Epoch 1/1, Loss after 1796 samples: 0.3287
Epoch 1/1, Loss after 1996 samples: 0.2659
Average Loss on fact answering task after 1996 samples: 7.6747
Average Loss on fact answering task after 1996 samples: 7.7010
Average Loss on fact answering task after 1996 samples: 7.4749
Average Loss on fact answering task after 1996 samples: 7.7102
Average Loss on fact answering task after 1996 samples: 7.6709
Mean accuracy: 0.8954, std: 0.0071, lower bound: 0.8808, upper bound: 0.9087 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 1996 samples: 0.8955
Epoch 1/1, Loss after 2196 samples: 0.2611
Epoch 1/1, Loss after 2396 samples: 0.3189
Average Loss on fact answering task after 2496 samples: 7.2528
Average Loss on fact answering task after 2496 samples: 7.6104
Average Loss on fact answering task after 2496 samples: 7.0824
Average Loss on fact answering task after 2496 samples: 7.1414
Average Loss on fact answering task after 2496 samples: 7.5553
Mean accuracy: 0.8748, std: 0.0076, lower bound: 0.8600, upper bound: 0.8900 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 2496 samples: 0.8747
Epoch 1/1, Loss after 2596 samples: 0.2210
Epoch 1/1, Loss after 2796 samples: 0.1800
Epoch 1/1, Loss after 2996 samples: 0.3457
Average Loss on fact answering task after 2996 samples: 7.8849
Average Loss on fact answering task after 2996 samples: 7.7499
Average Loss on fact answering task after 2996 samples: 7.8677
Average Loss on fact answering task after 2996 samples: 7.7199
Average Loss on fact answering task after 2996 samples: 7.6193
Mean accuracy: 0.9307, std: 0.0060, lower bound: 0.9194, upper bound: 0.9427 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 2996 samples: 0.9305
Best model with eval accuracy 0.9305273833671399 with 2996 samples seen is saved
Epoch 1/1, Loss after 3196 samples: 0.2337
Epoch 1/1, Loss after 3396 samples: 0.2187
Average Loss on fact answering task after 3496 samples: 7.9319
Average Loss on fact answering task after 3496 samples: 7.6336
Average Loss on fact answering task after 3496 samples: 7.5806
Average Loss on fact answering task after 3496 samples: 7.6812
Average Loss on fact answering task after 3496 samples: 7.4842
Mean accuracy: 0.8799, std: 0.0073, lower bound: 0.8656, upper bound: 0.8940 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 3496 samples: 0.8803
Epoch 1/1, Loss after 3596 samples: 0.2189
Epoch 1/1, Loss after 3796 samples: 0.2421
Epoch 1/1, Loss after 3996 samples: 0.1815
Average Loss on fact answering task after 3996 samples: 7.2419
Average Loss on fact answering task after 3996 samples: 7.2408
Average Loss on fact answering task after 3996 samples: 7.3796
Average Loss on fact answering task after 3996 samples: 7.2074
Average Loss on fact answering task after 3996 samples: 7.2910
Mean accuracy: 0.8197, std: 0.0086, lower bound: 0.8027, upper bound: 0.8367 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 3996 samples: 0.8195
Epoch 1/1, Loss after 4196 samples: 0.2272
Epoch 1/1, Loss after 4396 samples: 0.2284
Average Loss on fact answering task after 4496 samples: 7.3431
Average Loss on fact answering task after 4496 samples: 7.1866
Average Loss on fact answering task after 4496 samples: 7.2727
Average Loss on fact answering task after 4496 samples: 7.1516
Average Loss on fact answering task after 4496 samples: 7.2804
Mean accuracy: 0.9286, std: 0.0057, lower bound: 0.9173, upper bound: 0.9402 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 4496 samples: 0.9280
Epoch 1/1, Loss after 4596 samples: 0.2349
Epoch 1/1, Loss after 4796 samples: 0.1740
Epoch 1/1, Loss after 4996 samples: 0.2438
Average Loss on fact answering task after 4996 samples: 6.8787
Average Loss on fact answering task after 4996 samples: 6.7686
Average Loss on fact answering task after 4996 samples: 6.7880
Average Loss on fact answering task after 4996 samples: 6.8680
Average Loss on fact answering task after 4996 samples: 6.9820
Mean accuracy: 0.9118, std: 0.0062, lower bound: 0.8996, upper bound: 0.9234 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 4996 samples: 0.9118
Epoch 1/1, Loss after 5196 samples: 0.1288
Epoch 1/1, Loss after 5396 samples: 0.1933
Average Loss on fact answering task after 5496 samples: 7.1541
Average Loss on fact answering task after 5496 samples: 7.3924
Average Loss on fact answering task after 5496 samples: 7.4024
Average Loss on fact answering task after 5496 samples: 7.3640
Average Loss on fact answering task after 5496 samples: 7.5825
Mean accuracy: 0.9101, std: 0.0065, lower bound: 0.8976, upper bound: 0.9234 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 5496 samples: 0.9102
Epoch 1/1, Loss after 5596 samples: 0.1821
Epoch 1/1, Loss after 5796 samples: 0.1674
Epoch 1/1, Loss after 5996 samples: 0.1883
Average Loss on fact answering task after 5996 samples: 7.2808
Average Loss on fact answering task after 5996 samples: 7.0560
Average Loss on fact answering task after 5996 samples: 7.0598
Average Loss on fact answering task after 5996 samples: 7.0456
Average Loss on fact answering task after 5996 samples: 7.1193
Mean accuracy: 0.8314, std: 0.0085, lower bound: 0.8154, upper bound: 0.8474 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 5996 samples: 0.8311
Epoch 1/1, Loss after 6196 samples: 0.2351
Epoch 1/1, Loss after 6396 samples: 0.2327
Average Loss on fact answering task after 6496 samples: 6.6979
Average Loss on fact answering task after 6496 samples: 6.8016
Average Loss on fact answering task after 6496 samples: 6.7908
Average Loss on fact answering task after 6496 samples: 6.9750
Average Loss on fact answering task after 6496 samples: 6.8055
Mean accuracy: 0.9173, std: 0.0061, lower bound: 0.9057, upper bound: 0.9290 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 6496 samples: 0.9173
Epoch 1/1, Loss after 6596 samples: 0.1605
Epoch 1/1, Loss after 6796 samples: 0.1362
Epoch 1/1, Loss after 6996 samples: 0.1173
Average Loss on fact answering task after 6996 samples: 7.1908
Average Loss on fact answering task after 6996 samples: 7.0985
Average Loss on fact answering task after 6996 samples: 7.2679
Average Loss on fact answering task after 6996 samples: 7.3378
Average Loss on fact answering task after 6996 samples: 7.0426
Mean accuracy: 0.9379, std: 0.0055, lower bound: 0.9270, upper bound: 0.9483 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 6996 samples: 0.9381
Best model with eval accuracy 0.9381338742393509 with 6996 samples seen is saved
Epoch 1/1, Loss after 7196 samples: 0.1589
Epoch 1/1, Loss after 7396 samples: 0.1581
Average Loss on fact answering task after 7496 samples: 7.7462
Average Loss on fact answering task after 7496 samples: 7.8377
Average Loss on fact answering task after 7496 samples: 7.6201
Average Loss on fact answering task after 7496 samples: 7.7187
Average Loss on fact answering task after 7496 samples: 7.5982
Mean accuracy: 0.8554, std: 0.0079, lower bound: 0.8398, upper bound: 0.8712 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 7496 samples: 0.8555
Epoch 1/1, Loss after 7596 samples: 0.2058
Epoch 1/1, Loss after 7796 samples: 0.1084
Epoch 1/1, Loss after 7996 samples: 0.1662
Average Loss on fact answering task after 7996 samples: 7.7673
Average Loss on fact answering task after 7996 samples: 7.4549
Average Loss on fact answering task after 7996 samples: 7.7626
Average Loss on fact answering task after 7996 samples: 7.7401
Average Loss on fact answering task after 7996 samples: 7.7421
Mean accuracy: 0.8848, std: 0.0073, lower bound: 0.8702, upper bound: 0.8986 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 7996 samples: 0.8844
Epoch 1/1, Loss after 8196 samples: 0.0934
Epoch 1/1, Loss after 8396 samples: 0.1240
Average Loss on fact answering task after 8496 samples: 7.9163
Average Loss on fact answering task after 8496 samples: 7.7922
Average Loss on fact answering task after 8496 samples: 8.0126
Average Loss on fact answering task after 8496 samples: 8.0945
Average Loss on fact answering task after 8496 samples: 8.0267
Mean accuracy: 0.9265, std: 0.0060, lower bound: 0.9148, upper bound: 0.9381 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 8496 samples: 0.9265
Epoch 1/1, Loss after 8596 samples: 0.0882
Epoch 1/1, Loss after 8796 samples: 0.1497
Epoch 1/1, Loss after 8996 samples: 0.1262
Average Loss on fact answering task after 8996 samples: 7.8607
Average Loss on fact answering task after 8996 samples: 7.7757
Average Loss on fact answering task after 8996 samples: 7.5761
Average Loss on fact answering task after 8996 samples: 7.5091
Average Loss on fact answering task after 8996 samples: 7.5370
Mean accuracy: 0.9163, std: 0.0061, lower bound: 0.9047, upper bound: 0.9285 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 8996 samples: 0.9163
Epoch 1/1, Loss after 9196 samples: 0.1121
Epoch 1/1, Loss after 9396 samples: 0.1301
Average Loss on fact answering task after 9496 samples: 7.6349
Average Loss on fact answering task after 9496 samples: 7.7244
Average Loss on fact answering task after 9496 samples: 7.8555
Average Loss on fact answering task after 9496 samples: 7.6523
Average Loss on fact answering task after 9496 samples: 7.7231
Mean accuracy: 0.8561, std: 0.0079, lower bound: 0.8403, upper bound: 0.8712 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 9496 samples: 0.8560
Epoch 1/1, Loss after 9596 samples: 0.1623
Epoch 1/1, Loss after 9796 samples: 0.1459
Epoch 1/1, Loss after 9996 samples: 0.1435
Average Loss on fact answering task after 9996 samples: 7.4534
Average Loss on fact answering task after 9996 samples: 7.1121
Average Loss on fact answering task after 9996 samples: 7.0918
Average Loss on fact answering task after 9996 samples: 7.2060
Average Loss on fact answering task after 9996 samples: 7.0646
Mean accuracy: 0.9149, std: 0.0064, lower bound: 0.9021, upper bound: 0.9275 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 9996 samples: 0.9148
Epoch 1/1, Loss after 10196 samples: 0.1340
Epoch 1/1, Loss after 10396 samples: 0.0982
Average Loss on fact answering task after 10496 samples: 7.1030
Average Loss on fact answering task after 10496 samples: 7.1265
Average Loss on fact answering task after 10496 samples: 7.0569
Average Loss on fact answering task after 10496 samples: 7.2225
Average Loss on fact answering task after 10496 samples: 7.0418
Mean accuracy: 0.8939, std: 0.0069, lower bound: 0.8803, upper bound: 0.9072 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 10496 samples: 0.8940
Epoch 1/1, Loss after 10596 samples: 0.1547
Epoch 1/1, Loss after 10796 samples: 0.1213
Epoch 1/1, Loss after 10996 samples: 0.1160
Average Loss on fact answering task after 10996 samples: 7.3523
Average Loss on fact answering task after 10996 samples: 7.2471
Average Loss on fact answering task after 10996 samples: 7.4362
Average Loss on fact answering task after 10996 samples: 7.0692
Average Loss on fact answering task after 10996 samples: 7.4026
Mean accuracy: 0.9128, std: 0.0062, lower bound: 0.9006, upper bound: 0.9249 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 10996 samples: 0.9128
Epoch 1/1, Loss after 11196 samples: 0.1030
Epoch 1/1, Loss after 11396 samples: 0.1372
Average Loss on fact answering task after 11496 samples: 7.3416
Average Loss on fact answering task after 11496 samples: 7.0815
Average Loss on fact answering task after 11496 samples: 7.2978
Average Loss on fact answering task after 11496 samples: 7.1246
Average Loss on fact answering task after 11496 samples: 6.9905
Mean accuracy: 0.9162, std: 0.0062, lower bound: 0.9037, upper bound: 0.9280 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 11496 samples: 0.9158
Epoch 1/1, Loss after 11596 samples: 0.1249
Epoch 1/1, Loss after 11796 samples: 0.0668
Epoch 1/1, Loss after 11996 samples: 0.1293
Average Loss on fact answering task after 11996 samples: 6.8341
Average Loss on fact answering task after 11996 samples: 7.1429
Average Loss on fact answering task after 11996 samples: 6.9952
Average Loss on fact answering task after 11996 samples: 7.0562
Average Loss on fact answering task after 11996 samples: 7.2819
Mean accuracy: 0.9458, std: 0.0051, lower bound: 0.9361, upper bound: 0.9559 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 11996 samples: 0.9457
Best model with eval accuracy 0.9457403651115619 with 11996 samples seen is saved
Epoch 1/1, Loss after 12196 samples: 0.0566
Epoch 1/1, Loss after 12396 samples: 0.1418
Average Loss on fact answering task after 12496 samples: 7.3031
Average Loss on fact answering task after 12496 samples: 7.1746
Average Loss on fact answering task after 12496 samples: 6.9457
Average Loss on fact answering task after 12496 samples: 7.3143
Average Loss on fact answering task after 12496 samples: 7.0871
Mean accuracy: 0.9076, std: 0.0064, lower bound: 0.8950, upper bound: 0.9199 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 12496 samples: 0.9077
Epoch 1/1, Loss after 12596 samples: 0.0584
Epoch 1/1, Loss after 12796 samples: 0.0881
Epoch 1/1, Loss after 12996 samples: 0.1450
Average Loss on fact answering task after 12996 samples: 7.1792
Average Loss on fact answering task after 12996 samples: 7.1419
Average Loss on fact answering task after 12996 samples: 7.1770
Average Loss on fact answering task after 12996 samples: 7.1423
Average Loss on fact answering task after 12996 samples: 6.9590
Mean accuracy: 0.9186, std: 0.0062, lower bound: 0.9067, upper bound: 0.9305 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 12996 samples: 0.9184
Epoch 1/1, Loss after 13196 samples: 0.0571
Epoch 1/1, Loss after 13396 samples: 0.1096
Average Loss on fact answering task after 13496 samples: 7.1192
Average Loss on fact answering task after 13496 samples: 7.3230
Average Loss on fact answering task after 13496 samples: 7.0630
Average Loss on fact answering task after 13496 samples: 7.2593
Average Loss on fact answering task after 13496 samples: 7.3649
Mean accuracy: 0.9315, std: 0.0058, lower bound: 0.9199, upper bound: 0.9432 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 13496 samples: 0.9315
Epoch 1/1, Loss after 13596 samples: 0.0712
Epoch 1/1, Loss after 13796 samples: 0.1183
Epoch 1/1, Loss after 13996 samples: 0.1040
Average Loss on fact answering task after 13996 samples: 7.2920
Average Loss on fact answering task after 13996 samples: 7.2965
Average Loss on fact answering task after 13996 samples: 7.0961
Average Loss on fact answering task after 13996 samples: 7.0242
Average Loss on fact answering task after 13996 samples: 7.1585
Mean accuracy: 0.9235, std: 0.0059, lower bound: 0.9123, upper bound: 0.9356 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 13996 samples: 0.9234
Epoch 1/1, Loss after 14196 samples: 0.1341
Epoch 1/1, Loss after 14396 samples: 0.1364
Average Loss on fact answering task after 14496 samples: 7.5141
Average Loss on fact answering task after 14496 samples: 7.1684
Average Loss on fact answering task after 14496 samples: 7.3354
Average Loss on fact answering task after 14496 samples: 7.2361
Average Loss on fact answering task after 14496 samples: 7.2725
Mean accuracy: 0.9366, std: 0.0054, lower bound: 0.9260, upper bound: 0.9463 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 14496 samples: 0.9366
Epoch 1/1, Loss after 14596 samples: 0.1206
Epoch 1/1, Loss after 14796 samples: 0.1342
Epoch 1/1, Loss after 14996 samples: 0.0845
Average Loss on fact answering task after 14996 samples: 7.0522
Average Loss on fact answering task after 14996 samples: 7.1713
Average Loss on fact answering task after 14996 samples: 7.4183
Average Loss on fact answering task after 14996 samples: 7.4256
Average Loss on fact answering task after 14996 samples: 7.3479
Mean accuracy: 0.9237, std: 0.0060, lower bound: 0.9123, upper bound: 0.9351 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 14996 samples: 0.9239
Epoch 1/1, Loss after 15196 samples: 0.0916
Epoch 1/1, Loss after 15396 samples: 0.1281
Average Loss on fact answering task after 15496 samples: 7.1330
Average Loss on fact answering task after 15496 samples: 7.4752
Average Loss on fact answering task after 15496 samples: 7.1805
Average Loss on fact answering task after 15496 samples: 7.2709
Average Loss on fact answering task after 15496 samples: 7.1453
Mean accuracy: 0.9115, std: 0.0063, lower bound: 0.8991, upper bound: 0.9234 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 15496 samples: 0.9113
Epoch 1/1, Loss after 15596 samples: 0.1222
Training signal is False, stopping training
Training finished
Best model: {'eval_acc': 0.9457403651115619, 'nb_samples': 11996}
Training loss logs: [{'samples': 196, 'loss': 0.6961279296875}, {'samples': 396, 'loss': 0.673604736328125}, {'samples': 596, 'loss': 0.629990234375}, {'samples': 796, 'loss': 0.5487075805664062}, {'samples': 996, 'loss': 0.5229343795776367}, {'samples': 1196, 'loss': 0.3937679290771484}, {'samples': 1396, 'loss': 0.38061756134033203}, {'samples': 1596, 'loss': 0.2999301052093506}, {'samples': 1796, 'loss': 0.32874666213989256}, {'samples': 1996, 'loss': 0.2659317445755005}, {'samples': 2196, 'loss': 0.261094274520874}, {'samples': 2396, 'loss': 0.31886767387390136}, {'samples': 2596, 'loss': 0.220998592376709}, {'samples': 2796, 'loss': 0.17998666763305665}, {'samples': 2996, 'loss': 0.34572559356689453}, {'samples': 3196, 'loss': 0.23374186992645263}, {'samples': 3396, 'loss': 0.21870045661926268}, {'samples': 3596, 'loss': 0.2188822841644287}, {'samples': 3796, 'loss': 0.24205488681793214}, {'samples': 3996, 'loss': 0.18154397010803222}, {'samples': 4196, 'loss': 0.2272157382965088}, {'samples': 4396, 'loss': 0.22837034225463868}, {'samples': 4596, 'loss': 0.23490365982055664}, {'samples': 4796, 'loss': 0.1740385103225708}, {'samples': 4996, 'loss': 0.24376779556274414}, {'samples': 5196, 'loss': 0.12881223678588868}, {'samples': 5396, 'loss': 0.1932520580291748}, {'samples': 5596, 'loss': 0.18209660530090332}, {'samples': 5796, 'loss': 0.16740503549575805}, {'samples': 5996, 'loss': 0.18834017753601073}, {'samples': 6196, 'loss': 0.23509302616119385}, {'samples': 6396, 'loss': 0.23274701595306396}, {'samples': 6596, 'loss': 0.16051857948303222}, {'samples': 6796, 'loss': 0.13622741222381593}, {'samples': 6996, 'loss': 0.11731508255004883}, {'samples': 7196, 'loss': 0.1588913083076477}, {'samples': 7396, 'loss': 0.1581161594390869}, {'samples': 7596, 'loss': 0.20579565525054933}, {'samples': 7796, 'loss': 0.10835691094398499}, {'samples': 7996, 'loss': 0.16617518663406372}, {'samples': 8196, 'loss': 0.0933901584148407}, {'samples': 8396, 'loss': 0.1239549970626831}, {'samples': 8596, 'loss': 0.08820437669754028}, {'samples': 8796, 'loss': 0.14972328782081604}, {'samples': 8996, 'loss': 0.12619720339775087}, {'samples': 9196, 'loss': 0.11208001971244812}, {'samples': 9396, 'loss': 0.1301147985458374}, {'samples': 9596, 'loss': 0.16227991938591002}, {'samples': 9796, 'loss': 0.1459481954574585}, {'samples': 9996, 'loss': 0.14349102973937988}, {'samples': 10196, 'loss': 0.13400523662567138}, {'samples': 10396, 'loss': 0.0981533432006836}, {'samples': 10596, 'loss': 0.15470096588134766}, {'samples': 10796, 'loss': 0.1213285481929779}, {'samples': 10996, 'loss': 0.1159958928823471}, {'samples': 11196, 'loss': 0.10303396701812745}, {'samples': 11396, 'loss': 0.1372358536720276}, {'samples': 11596, 'loss': 0.12488311409950256}, {'samples': 11796, 'loss': 0.06684965133666992}, {'samples': 11996, 'loss': 0.12926400899887086}, {'samples': 12196, 'loss': 0.05663679957389831}, {'samples': 12396, 'loss': 0.14180591464042663}, {'samples': 12596, 'loss': 0.05838258266448974}, {'samples': 12796, 'loss': 0.088091059923172}, {'samples': 12996, 'loss': 0.14497094511985778}, {'samples': 13196, 'loss': 0.057103766202926634}, {'samples': 13396, 'loss': 0.1096197521686554}, {'samples': 13596, 'loss': 0.07122334957122803}, {'samples': 13796, 'loss': 0.11826654195785523}, {'samples': 13996, 'loss': 0.10404087543487549}, {'samples': 14196, 'loss': 0.13407673954963684}, {'samples': 14396, 'loss': 0.1364245581626892}, {'samples': 14596, 'loss': 0.12062444567680358}, {'samples': 14796, 'loss': 0.13419265389442445}, {'samples': 14996, 'loss': 0.08454587936401367}, {'samples': 15196, 'loss': 0.09160913825035095}, {'samples': 15396, 'loss': 0.12807602405548096}, {'samples': 15596, 'loss': 0.12217517137527466}]
Evaluation accuracy logs: [{'samples': 496, 'accuracy': 0.7372449290060852, 'std': 0.010165029492566884, 'lower_bound': 0.7185471602434077, 'upper_bound': 0.757619168356998}, {'samples': 996, 'accuracy': 0.8622854969574036, 'std': 0.007743735987201904, 'lower_bound': 0.8468433062880324, 'upper_bound': 0.8772819472616633}, {'samples': 1496, 'accuracy': 0.9074994929006085, 'std': 0.006495982375308047, 'lower_bound': 0.8940162271805274, 'upper_bound': 0.9203853955375254}, {'samples': 1996, 'accuracy': 0.8953762677484788, 'std': 0.0070839239646397914, 'lower_bound': 0.8808316430020284, 'upper_bound': 0.9087347870182556}, {'samples': 2496, 'accuracy': 0.8747885395537526, 'std': 0.007600777282796514, 'lower_bound': 0.8600278904665314, 'upper_bound': 0.8899594320486816}, {'samples': 2996, 'accuracy': 0.930726673427992, 'std': 0.005973461889393108, 'lower_bound': 0.9193585192697769, 'upper_bound': 0.9426977687626775}, {'samples': 3496, 'accuracy': 0.8799046653144016, 'std': 0.007317470856671864, 'lower_bound': 0.8656059837728194, 'upper_bound': 0.8940162271805274}, {'samples': 3996, 'accuracy': 0.8196957403651115, 'std': 0.008587820645918585, 'lower_bound': 0.8027256592292089, 'upper_bound': 0.8367139959432048}, {'samples': 4496, 'accuracy': 0.9285522312373226, 'std': 0.005729055666493675, 'lower_bound': 0.9173427991886409, 'upper_bound': 0.9401622718052738}, {'samples': 4996, 'accuracy': 0.9118128803245436, 'std': 0.0062473734344077715, 'lower_bound': 0.8995943204868154, 'upper_bound': 0.9234406693711967}, {'samples': 5496, 'accuracy': 0.9101156186612576, 'std': 0.006544539482786302, 'lower_bound': 0.8975659229208925, 'upper_bound': 0.9234406693711967}, {'samples': 5996, 'accuracy': 0.8313737322515212, 'std': 0.008458488366213664, 'lower_bound': 0.8154158215010142, 'upper_bound': 0.8473757606490873}, {'samples': 6496, 'accuracy': 0.9172687626774848, 'std': 0.006116818678749337, 'lower_bound': 0.9056795131845842, 'upper_bound': 0.9290060851926978}, {'samples': 6996, 'accuracy': 0.9379396551724137, 'std': 0.0054826874940511645, 'lower_bound': 0.9269776876267748, 'upper_bound': 0.9482885395537526}, {'samples': 7496, 'accuracy': 0.8554492900608519, 'std': 0.007863231113227368, 'lower_bound': 0.8397565922920892, 'upper_bound': 0.8712094320486816}, {'samples': 7996, 'accuracy': 0.8847565922920891, 'std': 0.007278111223843764, 'lower_bound': 0.8701825557809331, 'upper_bound': 0.8985801217038539}, {'samples': 8496, 'accuracy': 0.9264604462474645, 'std': 0.006023896829040526, 'lower_bound': 0.9148073022312373, 'upper_bound': 0.9381338742393509}, {'samples': 8996, 'accuracy': 0.9163083164300203, 'std': 0.006075262350405992, 'lower_bound': 0.9046526369168356, 'upper_bound': 0.9285116632860041}, {'samples': 9496, 'accuracy': 0.8561125760649086, 'std': 0.00792013090021508, 'lower_bound': 0.84026369168357, 'upper_bound': 0.8711967545638946}, {'samples': 9996, 'accuracy': 0.9149325557809331, 'std': 0.006417923122256741, 'lower_bound': 0.902129817444219, 'upper_bound': 0.9274847870182555}, {'samples': 10496, 'accuracy': 0.893905172413793, 'std': 0.006888101832609273, 'lower_bound': 0.8803245436105477, 'upper_bound': 0.9072008113590264}, {'samples': 10996, 'accuracy': 0.912773326572008, 'std': 0.006160388986258405, 'lower_bound': 0.9006085192697769, 'upper_bound': 0.9249492900608519}, {'samples': 11496, 'accuracy': 0.9161861054766735, 'std': 0.00620168331542077, 'lower_bound': 0.9036511156186613, 'upper_bound': 0.9279918864097363}, {'samples': 11996, 'accuracy': 0.9457581135902636, 'std': 0.005110741159483588, 'lower_bound': 0.936105476673428, 'upper_bound': 0.9558823529411765}, {'samples': 12496, 'accuracy': 0.9075608519269777, 'std': 0.006403561083560693, 'lower_bound': 0.8950177484787017, 'upper_bound': 0.9198782961460447}, {'samples': 12996, 'accuracy': 0.9186257606490872, 'std': 0.00615776326422348, 'lower_bound': 0.9066937119675457, 'upper_bound': 0.9305273833671399}, {'samples': 13496, 'accuracy': 0.9314817444219067, 'std': 0.005765344895658805, 'lower_bound': 0.9198782961460447, 'upper_bound': 0.9432048681541582}, {'samples': 13996, 'accuracy': 0.9235329614604464, 'std': 0.005917442532096006, 'lower_bound': 0.9122718052738337, 'upper_bound': 0.9355983772819473}, {'samples': 14496, 'accuracy': 0.9366090263691683, 'std': 0.005448498043911086, 'lower_bound': 0.9259508113590263, 'upper_bound': 0.9462601419878296}, {'samples': 14996, 'accuracy': 0.9237454361054767, 'std': 0.005950593109989942, 'lower_bound': 0.9122718052738337, 'upper_bound': 0.9350912778904665}, {'samples': 15496, 'accuracy': 0.9115456389452333, 'std': 0.006266348793739647, 'lower_bound': 0.8990872210953347, 'upper_bound': 0.9234279918864098}]
