log_loss_steps: 208
eval_steps: 512
check_degradation: 512
Average Loss on fact answering task after 0 samples: 5.0881
Average Loss on fact answering task after 0 samples: 4.9522
Average Loss on fact answering task after 0 samples: 5.2724
Average Loss on fact answering task after 0 samples: 5.1603
Average Loss on fact answering task after 0 samples: 5.1582
----------------Epoch 1/1----------------
Epoch 1/1, Loss after 192 samples: 0.7259
Epoch 1/1, Loss after 400 samples: 0.7041
Average Loss on fact answering task after 496 samples: 5.1537
Average Loss on fact answering task after 496 samples: 4.9564
Average Loss on fact answering task after 496 samples: 5.2504
Average Loss on fact answering task after 496 samples: 4.9507
Average Loss on fact answering task after 496 samples: 5.2825
Mean accuracy: 0.5020, std: 0.0112, lower bound: 0.4812, upper bound: 0.5228 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 496 samples: 0.5020
Best model with eval accuracy 0.5020283975659229 with 496 samples seen is saved
Epoch 1/1, Loss after 608 samples: 0.6881
Epoch 1/1, Loss after 816 samples: 0.6841
Average Loss on fact answering task after 1008 samples: 5.0769
Average Loss on fact answering task after 1008 samples: 5.1889
Average Loss on fact answering task after 1008 samples: 5.0327
Average Loss on fact answering task after 1008 samples: 5.1009
Average Loss on fact answering task after 1008 samples: 5.2516
Mean accuracy: 0.5109, std: 0.0115, lower bound: 0.4888, upper bound: 0.5335 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 1008 samples: 0.5106
Best model with eval accuracy 0.5106490872210954 with 1008 samples seen is saved
Epoch 1/1, Loss after 1024 samples: 0.6740
Epoch 1/1, Loss after 1232 samples: 0.5345
Epoch 1/1, Loss after 1440 samples: 0.4383
Average Loss on fact answering task after 1520 samples: 5.7923
Average Loss on fact answering task after 1520 samples: 5.8852
Average Loss on fact answering task after 1520 samples: 5.6987
Average Loss on fact answering task after 1520 samples: 5.6424
Average Loss on fact answering task after 1520 samples: 5.6852
Mean accuracy: 0.8512, std: 0.0079, lower bound: 0.8347, upper bound: 0.8666 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 1520 samples: 0.8514
Best model with eval accuracy 0.8514198782961461 with 1520 samples seen is saved
Epoch 1/1, Loss after 1648 samples: 0.3474
Epoch 1/1, Loss after 1856 samples: 0.2816
Average Loss on fact answering task after 2032 samples: 6.0119
Average Loss on fact answering task after 2032 samples: 6.1491
Average Loss on fact answering task after 2032 samples: 6.1273
Average Loss on fact answering task after 2032 samples: 6.2265
Average Loss on fact answering task after 2032 samples: 5.6825
Mean accuracy: 0.8577, std: 0.0079, lower bound: 0.8428, upper bound: 0.8732 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 2032 samples: 0.8580
Best model with eval accuracy 0.8580121703853956 with 2032 samples seen is saved
Epoch 1/1, Loss after 2064 samples: 0.3308
Epoch 1/1, Loss after 2272 samples: 0.1885
Epoch 1/1, Loss after 2480 samples: 0.2411
Average Loss on fact answering task after 2544 samples: 6.0271
Average Loss on fact answering task after 2544 samples: 5.9175
Average Loss on fact answering task after 2544 samples: 5.9450
Average Loss on fact answering task after 2544 samples: 5.8983
Average Loss on fact answering task after 2544 samples: 5.9314
Mean accuracy: 0.8290, std: 0.0084, lower bound: 0.8129, upper bound: 0.8458 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 2544 samples: 0.8291
Epoch 1/1, Loss after 2688 samples: 0.2884
Epoch 1/1, Loss after 2896 samples: 0.2005
Average Loss on fact answering task after 3056 samples: 6.1078
Average Loss on fact answering task after 3056 samples: 6.4519
Average Loss on fact answering task after 3056 samples: 6.4172
Average Loss on fact answering task after 3056 samples: 6.5068
Average Loss on fact answering task after 3056 samples: 6.5150
Mean accuracy: 0.8140, std: 0.0087, lower bound: 0.7961, upper bound: 0.8306 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 3056 samples: 0.8139
Epoch 1/1, Loss after 3104 samples: 0.2792
Epoch 1/1, Loss after 3312 samples: 0.1661
Epoch 1/1, Loss after 3520 samples: 0.2063
Average Loss on fact answering task after 3568 samples: 6.2246
Average Loss on fact answering task after 3568 samples: 6.4792
Average Loss on fact answering task after 3568 samples: 6.3284
Average Loss on fact answering task after 3568 samples: 6.2089
Average Loss on fact answering task after 3568 samples: 6.3033
Mean accuracy: 0.8973, std: 0.0066, lower bound: 0.8834, upper bound: 0.9097 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 3568 samples: 0.8976
Best model with eval accuracy 0.8975659229208925 with 3568 samples seen is saved
Epoch 1/1, Loss after 3728 samples: 0.1902
Epoch 1/1, Loss after 3936 samples: 0.1958
Average Loss on fact answering task after 4080 samples: 6.2140
Average Loss on fact answering task after 4080 samples: 6.0778
Average Loss on fact answering task after 4080 samples: 6.1622
Average Loss on fact answering task after 4080 samples: 6.1967
Average Loss on fact answering task after 4080 samples: 6.1453
Mean accuracy: 0.9357, std: 0.0056, lower bound: 0.9244, upper bound: 0.9462 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 4080 samples: 0.9356
Best model with eval accuracy 0.9355983772819473 with 4080 samples seen is saved
Epoch 1/1, Loss after 4144 samples: 0.3303
Epoch 1/1, Loss after 4352 samples: 0.2888
Epoch 1/1, Loss after 4560 samples: 0.1434
Average Loss on fact answering task after 4592 samples: 6.2059
Average Loss on fact answering task after 4592 samples: 6.1105
Average Loss on fact answering task after 4592 samples: 6.1799
Average Loss on fact answering task after 4592 samples: 6.0165
Average Loss on fact answering task after 4592 samples: 6.1120
Mean accuracy: 0.8910, std: 0.0070, lower bound: 0.8768, upper bound: 0.9047 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 4592 samples: 0.8905
Epoch 1/1, Loss after 4768 samples: 0.1101
Epoch 1/1, Loss after 4976 samples: 0.1805
Average Loss on fact answering task after 5104 samples: 6.0131
Average Loss on fact answering task after 5104 samples: 6.1149
Average Loss on fact answering task after 5104 samples: 6.0992
Average Loss on fact answering task after 5104 samples: 6.0344
Average Loss on fact answering task after 5104 samples: 6.2393
Mean accuracy: 0.9255, std: 0.0061, lower bound: 0.9133, upper bound: 0.9371 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 5104 samples: 0.9255
Epoch 1/1, Loss after 5184 samples: 0.0849
Epoch 1/1, Loss after 5392 samples: 0.1609
Epoch 1/1, Loss after 5600 samples: 0.1428
Average Loss on fact answering task after 5616 samples: 6.1233
Average Loss on fact answering task after 5616 samples: 5.9308
Average Loss on fact answering task after 5616 samples: 6.4030
Average Loss on fact answering task after 5616 samples: 6.1377
Average Loss on fact answering task after 5616 samples: 6.1661
Mean accuracy: 0.8893, std: 0.0072, lower bound: 0.8742, upper bound: 0.9031 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 5616 samples: 0.8889
Epoch 1/1, Loss after 5808 samples: 0.1753
Epoch 1/1, Loss after 6016 samples: 0.1874
Average Loss on fact answering task after 6128 samples: 6.2394
Average Loss on fact answering task after 6128 samples: 6.3965
Average Loss on fact answering task after 6128 samples: 6.1907
Average Loss on fact answering task after 6128 samples: 6.1133
Average Loss on fact answering task after 6128 samples: 6.3848
Mean accuracy: 0.8618, std: 0.0079, lower bound: 0.8458, upper bound: 0.8768 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 6128 samples: 0.8621
Epoch 1/1, Loss after 6224 samples: 0.1874
Epoch 1/1, Loss after 6432 samples: 0.1846
Epoch 1/1, Loss after 6640 samples: 0.1219
Average Loss on fact answering task after 6640 samples: 6.4005
Average Loss on fact answering task after 6640 samples: 6.1273
Average Loss on fact answering task after 6640 samples: 6.3113
Average Loss on fact answering task after 6640 samples: 6.1846
Average Loss on fact answering task after 6640 samples: 6.4559
Mean accuracy: 0.8327, std: 0.0085, lower bound: 0.8164, upper bound: 0.8499 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 6640 samples: 0.8332
Epoch 1/1, Loss after 6848 samples: 0.1568
Epoch 1/1, Loss after 7056 samples: 0.1068
Average Loss on fact answering task after 7152 samples: 6.2281
Average Loss on fact answering task after 7152 samples: 6.3972
Average Loss on fact answering task after 7152 samples: 6.2967
Average Loss on fact answering task after 7152 samples: 6.2691
Average Loss on fact answering task after 7152 samples: 6.3324
Mean accuracy: 0.9483, std: 0.0049, lower bound: 0.9381, upper bound: 0.9574 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 7152 samples: 0.9483
Best model with eval accuracy 0.9482758620689655 with 7152 samples seen is saved
Epoch 1/1, Loss after 7264 samples: 0.1773
Epoch 1/1, Loss after 7472 samples: 0.1318
Average Loss on fact answering task after 7664 samples: 6.4558
Average Loss on fact answering task after 7664 samples: 6.4191
Average Loss on fact answering task after 7664 samples: 6.3706
Average Loss on fact answering task after 7664 samples: 6.3666
Average Loss on fact answering task after 7664 samples: 6.4810
Mean accuracy: 0.9563, std: 0.0045, lower bound: 0.9473, upper bound: 0.9655 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 7664 samples: 0.9564
Best model with eval accuracy 0.9563894523326572 with 7664 samples seen is saved
Epoch 1/1, Loss after 7680 samples: 0.1386
Epoch 1/1, Loss after 7888 samples: 0.1810
Epoch 1/1, Loss after 8096 samples: 0.1057
Average Loss on fact answering task after 8176 samples: 6.4520
Average Loss on fact answering task after 8176 samples: 6.5389
Average Loss on fact answering task after 8176 samples: 6.3539
Average Loss on fact answering task after 8176 samples: 6.4647
Average Loss on fact answering task after 8176 samples: 6.1227
Mean accuracy: 0.9352, std: 0.0057, lower bound: 0.9239, upper bound: 0.9457 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 8176 samples: 0.9351
Epoch 1/1, Loss after 8304 samples: 0.1334
Epoch 1/1, Loss after 8512 samples: 0.0824
Average Loss on fact answering task after 8688 samples: 6.6546
Average Loss on fact answering task after 8688 samples: 6.5853
Average Loss on fact answering task after 8688 samples: 6.3796
Average Loss on fact answering task after 8688 samples: 6.6720
Average Loss on fact answering task after 8688 samples: 6.4310
Mean accuracy: 0.8639, std: 0.0076, lower bound: 0.8484, upper bound: 0.8783 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 8688 samples: 0.8636
Epoch 1/1, Loss after 8720 samples: 0.1298
Epoch 1/1, Loss after 8928 samples: 0.1204
Epoch 1/1, Loss after 9136 samples: 0.0888
Average Loss on fact answering task after 9200 samples: 6.3990
Average Loss on fact answering task after 9200 samples: 6.6550
Average Loss on fact answering task after 9200 samples: 6.4389
Average Loss on fact answering task after 9200 samples: 6.3741
Average Loss on fact answering task after 9200 samples: 6.3805
Mean accuracy: 0.9509, std: 0.0049, lower bound: 0.9407, upper bound: 0.9604 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 9200 samples: 0.9508
Epoch 1/1, Loss after 9344 samples: 0.1299
Epoch 1/1, Loss after 9552 samples: 0.1216
Average Loss on fact answering task after 9712 samples: 6.4824
Average Loss on fact answering task after 9712 samples: 6.4072
Average Loss on fact answering task after 9712 samples: 6.4468
Average Loss on fact answering task after 9712 samples: 6.3365
Average Loss on fact answering task after 9712 samples: 6.6851
Mean accuracy: 0.9343, std: 0.0054, lower bound: 0.9239, upper bound: 0.9452 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 9712 samples: 0.9346
Epoch 1/1, Loss after 9760 samples: 0.1573
Epoch 1/1, Loss after 9968 samples: 0.1437
Epoch 1/1, Loss after 10176 samples: 0.1286
Average Loss on fact answering task after 10224 samples: 6.4269
Average Loss on fact answering task after 10224 samples: 6.5375
Average Loss on fact answering task after 10224 samples: 6.5041
Average Loss on fact answering task after 10224 samples: 6.3496
Average Loss on fact answering task after 10224 samples: 6.4305
Mean accuracy: 0.8839, std: 0.0072, lower bound: 0.8697, upper bound: 0.8976 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 10224 samples: 0.8839
Epoch 1/1, Loss after 10384 samples: 0.1133
Epoch 1/1, Loss after 10592 samples: 0.1017
Average Loss on fact answering task after 10736 samples: 6.3157
Average Loss on fact answering task after 10736 samples: 6.4594
Average Loss on fact answering task after 10736 samples: 6.5587
Average Loss on fact answering task after 10736 samples: 6.7312
Average Loss on fact answering task after 10736 samples: 6.5195
Mean accuracy: 0.9315, std: 0.0057, lower bound: 0.9199, upper bound: 0.9427 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 10736 samples: 0.9315
Epoch 1/1, Loss after 10800 samples: 0.1053
Epoch 1/1, Loss after 11008 samples: 0.0947
Epoch 1/1, Loss after 11216 samples: 0.0871
Average Loss on fact answering task after 11248 samples: 6.5133
Average Loss on fact answering task after 11248 samples: 6.7740
Average Loss on fact answering task after 11248 samples: 6.5429
Average Loss on fact answering task after 11248 samples: 6.6652
Average Loss on fact answering task after 11248 samples: 6.6406
Mean accuracy: 0.9392, std: 0.0054, lower bound: 0.9290, upper bound: 0.9498 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 11248 samples: 0.9391
Epoch 1/1, Loss after 11424 samples: 0.1464
Epoch 1/1, Loss after 11632 samples: 0.0916
Average Loss on fact answering task after 11760 samples: 6.2948
Average Loss on fact answering task after 11760 samples: 6.3970
Average Loss on fact answering task after 11760 samples: 6.4776
Average Loss on fact answering task after 11760 samples: 6.5350
Average Loss on fact answering task after 11760 samples: 6.6073
Mean accuracy: 0.9372, std: 0.0055, lower bound: 0.9254, upper bound: 0.9478 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 11760 samples: 0.9371
Epoch 1/1, Loss after 11840 samples: 0.0676
Epoch 1/1, Loss after 12048 samples: 0.1006
Epoch 1/1, Loss after 12256 samples: 0.0772
Average Loss on fact answering task after 12272 samples: 6.6700
Average Loss on fact answering task after 12272 samples: 6.4877
Average Loss on fact answering task after 12272 samples: 6.6339
Average Loss on fact answering task after 12272 samples: 6.4099
Average Loss on fact answering task after 12272 samples: 6.6671
Mean accuracy: 0.8550, std: 0.0082, lower bound: 0.8397, upper bound: 0.8707 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 12272 samples: 0.8550
Epoch 1/1, Loss after 12464 samples: 0.1202
Epoch 1/1, Loss after 12672 samples: 0.0957
Average Loss on fact answering task after 12784 samples: 6.4890
Average Loss on fact answering task after 12784 samples: 6.4485
Average Loss on fact answering task after 12784 samples: 6.4650
Average Loss on fact answering task after 12784 samples: 6.3714
Average Loss on fact answering task after 12784 samples: 6.6815
Mean accuracy: 0.9237, std: 0.0061, lower bound: 0.9123, upper bound: 0.9366 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 12784 samples: 0.9239
Epoch 1/1, Loss after 12880 samples: 0.0754
Epoch 1/1, Loss after 13088 samples: 0.0681
Epoch 1/1, Loss after 13296 samples: 0.1353
Average Loss on fact answering task after 13296 samples: 6.5325
Average Loss on fact answering task after 13296 samples: 6.3281
Average Loss on fact answering task after 13296 samples: 6.2659
Average Loss on fact answering task after 13296 samples: 6.5426
Average Loss on fact answering task after 13296 samples: 6.2243
Mean accuracy: 0.9092, std: 0.0063, lower bound: 0.8960, upper bound: 0.9209 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 13296 samples: 0.9092
Epoch 1/1, Loss after 13504 samples: 0.0623
Epoch 1/1, Loss after 13712 samples: 0.0701
Average Loss on fact answering task after 13808 samples: 6.2747
Average Loss on fact answering task after 13808 samples: 6.3956
Average Loss on fact answering task after 13808 samples: 6.8088
Average Loss on fact answering task after 13808 samples: 6.7172
Average Loss on fact answering task after 13808 samples: 6.7767
Mean accuracy: 0.8964, std: 0.0065, lower bound: 0.8834, upper bound: 0.9087 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 13808 samples: 0.8966
Epoch 1/1, Loss after 13920 samples: 0.0596
Epoch 1/1, Loss after 14128 samples: 0.1582
Average Loss on fact answering task after 14320 samples: 6.4621
Average Loss on fact answering task after 14320 samples: 6.5092
Average Loss on fact answering task after 14320 samples: 6.5756
Average Loss on fact answering task after 14320 samples: 6.5801
Average Loss on fact answering task after 14320 samples: 6.5294
Mean accuracy: 0.8993, std: 0.0065, lower bound: 0.8859, upper bound: 0.9113 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 14320 samples: 0.8996
Epoch 1/1, Loss after 14336 samples: 0.1555
Epoch 1/1, Loss after 14544 samples: 0.1330
Epoch 1/1, Loss after 14752 samples: 0.0975
Average Loss on fact answering task after 14832 samples: 6.3568
Average Loss on fact answering task after 14832 samples: 6.6026
Average Loss on fact answering task after 14832 samples: 6.4900
Average Loss on fact answering task after 14832 samples: 6.4304
Average Loss on fact answering task after 14832 samples: 6.3234
Mean accuracy: 0.9212, std: 0.0059, lower bound: 0.9097, upper bound: 0.9320 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 14832 samples: 0.9214
Epoch 1/1, Loss after 14960 samples: 0.0958
Epoch 1/1, Loss after 15168 samples: 0.0920
Average Loss on fact answering task after 15344 samples: 6.5846
Average Loss on fact answering task after 15344 samples: 6.6733
Average Loss on fact answering task after 15344 samples: 6.5481
Average Loss on fact answering task after 15344 samples: 6.6711
Average Loss on fact answering task after 15344 samples: 6.4590
Mean accuracy: 0.9091, std: 0.0064, lower bound: 0.8966, upper bound: 0.9214 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 15344 samples: 0.9087
Epoch 1/1, Loss after 15376 samples: 0.1088
Epoch 1/1, Loss after 15584 samples: 0.1333
Training signal is False, stopping training
Training finished
Best model: {'eval_acc': 0.9563894523326572, 'nb_samples': 7664}
Training loss logs: [{'samples': 192, 'loss': 0.7259404109074519}, {'samples': 400, 'loss': 0.7041426438551682}, {'samples': 608, 'loss': 0.6881490854116586}, {'samples': 816, 'loss': 0.6841137225811298}, {'samples': 1024, 'loss': 0.6739689753605769}, {'samples': 1232, 'loss': 0.5344657897949219}, {'samples': 1440, 'loss': 0.43827108236459583}, {'samples': 1648, 'loss': 0.3473652876340426}, {'samples': 1856, 'loss': 0.28156617054572475}, {'samples': 2064, 'loss': 0.33077027247502255}, {'samples': 2272, 'loss': 0.18850424198003915}, {'samples': 2480, 'loss': 0.24109705136372492}, {'samples': 2688, 'loss': 0.28835806250572205}, {'samples': 2896, 'loss': 0.20054695239433876}, {'samples': 3104, 'loss': 0.27915703791838425}, {'samples': 3312, 'loss': 0.16605580540803763}, {'samples': 3520, 'loss': 0.20630713609548715}, {'samples': 3728, 'loss': 0.19023302426704994}, {'samples': 3936, 'loss': 0.19582599859971267}, {'samples': 4144, 'loss': 0.33027891700084394}, {'samples': 4352, 'loss': 0.2887809918476985}, {'samples': 4560, 'loss': 0.14338038517878607}, {'samples': 4768, 'loss': 0.110087507046186}, {'samples': 4976, 'loss': 0.18050185992167547}, {'samples': 5184, 'loss': 0.08485776873735282}, {'samples': 5392, 'loss': 0.160878626199869}, {'samples': 5600, 'loss': 0.14277013677817124}, {'samples': 5808, 'loss': 0.17533304141117975}, {'samples': 6016, 'loss': 0.18741615460469171}, {'samples': 6224, 'loss': 0.1874476785843189}, {'samples': 6432, 'loss': 0.18462837888644293}, {'samples': 6640, 'loss': 0.12191472603724553}, {'samples': 6848, 'loss': 0.15682033392099234}, {'samples': 7056, 'loss': 0.10683532059192657}, {'samples': 7264, 'loss': 0.17729797386206114}, {'samples': 7472, 'loss': 0.1318037876716027}, {'samples': 7680, 'loss': 0.13856755540921137}, {'samples': 7888, 'loss': 0.18100042297289923}, {'samples': 8096, 'loss': 0.10568334964605477}, {'samples': 8304, 'loss': 0.13339283145391023}, {'samples': 8512, 'loss': 0.08239026482288654}, {'samples': 8720, 'loss': 0.12984039921026963}, {'samples': 8928, 'loss': 0.1204079080086488}, {'samples': 9136, 'loss': 0.08877353828686935}, {'samples': 9344, 'loss': 0.1298858913091513}, {'samples': 9552, 'loss': 0.12164301941028008}, {'samples': 9760, 'loss': 0.15731278749612662}, {'samples': 9968, 'loss': 0.1436755473797138}, {'samples': 10176, 'loss': 0.12860940167537102}, {'samples': 10384, 'loss': 0.11327222906626187}, {'samples': 10592, 'loss': 0.10173880022305709}, {'samples': 10800, 'loss': 0.10531088824455555}, {'samples': 11008, 'loss': 0.09471256916339581}, {'samples': 11216, 'loss': 0.08708233787463261}, {'samples': 11424, 'loss': 0.1464223162486003}, {'samples': 11632, 'loss': 0.09161557715672713}, {'samples': 11840, 'loss': 0.06755148562101218}, {'samples': 12048, 'loss': 0.10060151609090659}, {'samples': 12256, 'loss': 0.0772144697033442}, {'samples': 12464, 'loss': 0.12020904570817947}, {'samples': 12672, 'loss': 0.09566528292802665}, {'samples': 12880, 'loss': 0.07536770976506747}, {'samples': 13088, 'loss': 0.06806497390453632}, {'samples': 13296, 'loss': 0.13534533404386961}, {'samples': 13504, 'loss': 0.06229995649594527}, {'samples': 13712, 'loss': 0.07014226684203514}, {'samples': 13920, 'loss': 0.05962647268405327}, {'samples': 14128, 'loss': 0.1581869274377823}, {'samples': 14336, 'loss': 0.15552575083879325}, {'samples': 14544, 'loss': 0.13299657633671394}, {'samples': 14752, 'loss': 0.09748344352612129}, {'samples': 14960, 'loss': 0.09583757129999307}, {'samples': 15168, 'loss': 0.09203520646462074}, {'samples': 15376, 'loss': 0.10878292872355534}, {'samples': 15584, 'loss': 0.133261413528369}]
Evaluation accuracy logs: [{'samples': 496, 'accuracy': 0.5020441176470588, 'std': 0.0112483291337151, 'lower_bound': 0.481237322515213, 'upper_bound': 0.5228194726166329}, {'samples': 1008, 'accuracy': 0.5108777890466532, 'std': 0.011518141751421535, 'lower_bound': 0.48883113590263694, 'upper_bound': 0.5334685598377282}, {'samples': 1520, 'accuracy': 0.8511749492900608, 'std': 0.007853751835466901, 'lower_bound': 0.834685598377282, 'upper_bound': 0.8666328600405679}, {'samples': 2032, 'accuracy': 0.8577307302231237, 'std': 0.007867021943698796, 'lower_bound': 0.8427991886409736, 'upper_bound': 0.8732251521298174}, {'samples': 2544, 'accuracy': 0.8290070993914808, 'std': 0.008438182572706253, 'lower_bound': 0.8128803245436106, 'upper_bound': 0.845841784989858}, {'samples': 3056, 'accuracy': 0.8139685598377281, 'std': 0.008735906524819266, 'lower_bound': 0.7961333671399594, 'upper_bound': 0.8306414807302231}, {'samples': 3568, 'accuracy': 0.8972778904665314, 'std': 0.0065977387391822325, 'lower_bound': 0.883354462474645, 'upper_bound': 0.90973630831643}, {'samples': 4080, 'accuracy': 0.9357033468559837, 'std': 0.005555323038990056, 'lower_bound': 0.9244421906693712, 'upper_bound': 0.9462474645030426}, {'samples': 4592, 'accuracy': 0.8910045638945232, 'std': 0.007031537496448143, 'lower_bound': 0.8767748478701826, 'upper_bound': 0.9046653144016227}, {'samples': 5104, 'accuracy': 0.9255370182555781, 'std': 0.006138913460931026, 'lower_bound': 0.9132860040567952, 'upper_bound': 0.9371196754563894}, {'samples': 5616, 'accuracy': 0.8892748478701826, 'std': 0.007241434352436535, 'lower_bound': 0.8742393509127789, 'upper_bound': 0.9031440162271805}, {'samples': 6128, 'accuracy': 0.8618022312373226, 'std': 0.007923114784884635, 'lower_bound': 0.845841784989858, 'upper_bound': 0.8767748478701826}, {'samples': 6640, 'accuracy': 0.8326734279918865, 'std': 0.008452557058176376, 'lower_bound': 0.8164173427991887, 'upper_bound': 0.8498985801217038}, {'samples': 7152, 'accuracy': 0.948301724137931, 'std': 0.004930414467317149, 'lower_bound': 0.9381338742393509, 'upper_bound': 0.9574036511156186}, {'samples': 7664, 'accuracy': 0.9563062880324543, 'std': 0.004525222226235554, 'lower_bound': 0.947261663286004, 'upper_bound': 0.9655172413793104}, {'samples': 8176, 'accuracy': 0.9352358012170384, 'std': 0.005676066013239312, 'lower_bound': 0.9239350912778904, 'upper_bound': 0.9457403651115619}, {'samples': 8688, 'accuracy': 0.8638539553752536, 'std': 0.0075714812987356505, 'lower_bound': 0.8483772819472617, 'upper_bound': 0.8782961460446247}, {'samples': 9200, 'accuracy': 0.9509153144016227, 'std': 0.004909575277264265, 'lower_bound': 0.9406693711967545, 'upper_bound': 0.960446247464503}, {'samples': 9712, 'accuracy': 0.9343468559837728, 'std': 0.005435125626928989, 'lower_bound': 0.9239350912778904, 'upper_bound': 0.9452459432048682}, {'samples': 10224, 'accuracy': 0.8839127789046652, 'std': 0.007190022486401649, 'lower_bound': 0.8696627789046653, 'upper_bound': 0.8975659229208925}, {'samples': 10736, 'accuracy': 0.9314705882352942, 'std': 0.005745872471877126, 'lower_bound': 0.9198782961460447, 'upper_bound': 0.9426977687626775}, {'samples': 11248, 'accuracy': 0.9392048681541583, 'std': 0.005387616766875733, 'lower_bound': 0.9290060851926978, 'upper_bound': 0.9497971602434077}, {'samples': 11760, 'accuracy': 0.9371653144016228, 'std': 0.0055272879944132484, 'lower_bound': 0.9254437119675456, 'upper_bound': 0.9477814401622718}, {'samples': 12272, 'accuracy': 0.8549533468559838, 'std': 0.008190039428560374, 'lower_bound': 0.8397439148073021, 'upper_bound': 0.8706896551724138}, {'samples': 12784, 'accuracy': 0.9237053752535496, 'std': 0.006077365465505652, 'lower_bound': 0.9122718052738337, 'upper_bound': 0.9366125760649088}, {'samples': 13296, 'accuracy': 0.9091577079107506, 'std': 0.006335843535924719, 'lower_bound': 0.8960446247464503, 'upper_bound': 0.920892494929006}, {'samples': 13808, 'accuracy': 0.896405172413793, 'std': 0.006527798878373578, 'lower_bound': 0.8833671399594321, 'upper_bound': 0.9087347870182556}, {'samples': 14320, 'accuracy': 0.8992576064908723, 'std': 0.00649275581188948, 'lower_bound': 0.8859026369168357, 'upper_bound': 0.9112702839756592}, {'samples': 14832, 'accuracy': 0.9212261663286003, 'std': 0.005872487618155453, 'lower_bound': 0.90973630831643, 'upper_bound': 0.9320486815415822}, {'samples': 15344, 'accuracy': 0.909078093306288, 'std': 0.006416143981188581, 'lower_bound': 0.896551724137931, 'upper_bound': 0.9213995943204868}]
