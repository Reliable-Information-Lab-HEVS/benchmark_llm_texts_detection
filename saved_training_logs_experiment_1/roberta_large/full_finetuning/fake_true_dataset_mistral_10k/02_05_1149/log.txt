log_loss_steps: 208
eval_steps: 512
check_degradation: 512
Average Loss on fact answering task after 0 samples: 5.3285
Average Loss on fact answering task after 0 samples: 5.2662
Average Loss on fact answering task after 0 samples: 5.0870
Average Loss on fact answering task after 0 samples: 5.3071
Average Loss on fact answering task after 0 samples: 5.5565
----------------Epoch 1/1----------------
Epoch 1/1, Loss after 192 samples: 0.7084
Epoch 1/1, Loss after 400 samples: 0.6875
Average Loss on fact answering task after 496 samples: 5.3663
Average Loss on fact answering task after 496 samples: 5.1599
Average Loss on fact answering task after 496 samples: 5.2845
Average Loss on fact answering task after 496 samples: 5.3653
Average Loss on fact answering task after 496 samples: 5.2634
Mean accuracy: 0.7646, std: 0.0094, lower bound: 0.7459, upper bound: 0.7835 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 496 samples: 0.7652
Best model with eval accuracy 0.7652129817444219 with 496 samples seen is saved
Epoch 1/1, Loss after 608 samples: 0.6136
Epoch 1/1, Loss after 816 samples: 0.4488
Average Loss on fact answering task after 1008 samples: 6.0683
Average Loss on fact answering task after 1008 samples: 6.1929
Average Loss on fact answering task after 1008 samples: 5.9172
Average Loss on fact answering task after 1008 samples: 6.0821
Average Loss on fact answering task after 1008 samples: 6.1757
Mean accuracy: 0.8389, std: 0.0084, lower bound: 0.8215, upper bound: 0.8550 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 1008 samples: 0.8387
Best model with eval accuracy 0.8387423935091278 with 1008 samples seen is saved
Epoch 1/1, Loss after 1024 samples: 0.4419
Epoch 1/1, Loss after 1232 samples: 0.3468
Epoch 1/1, Loss after 1440 samples: 0.3000
Average Loss on fact answering task after 1520 samples: 7.4507
Average Loss on fact answering task after 1520 samples: 7.6956
Average Loss on fact answering task after 1520 samples: 7.3881
Average Loss on fact answering task after 1520 samples: 7.5759
Average Loss on fact answering task after 1520 samples: 7.5382
Mean accuracy: 0.8987, std: 0.0068, lower bound: 0.8854, upper bound: 0.9123 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 1520 samples: 0.8986
Best model with eval accuracy 0.8985801217038539 with 1520 samples seen is saved
Epoch 1/1, Loss after 1648 samples: 0.3624
Epoch 1/1, Loss after 1856 samples: 0.4087
Average Loss on fact answering task after 2032 samples: 7.3760
Average Loss on fact answering task after 2032 samples: 7.6027
Average Loss on fact answering task after 2032 samples: 7.5738
Average Loss on fact answering task after 2032 samples: 7.5512
Average Loss on fact answering task after 2032 samples: 7.1754
Mean accuracy: 0.8640, std: 0.0077, lower bound: 0.8484, upper bound: 0.8788 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 2032 samples: 0.8641
Epoch 1/1, Loss after 2064 samples: 0.2428
Epoch 1/1, Loss after 2272 samples: 0.2480
Epoch 1/1, Loss after 2480 samples: 0.2051
Average Loss on fact answering task after 2544 samples: 8.0641
Average Loss on fact answering task after 2544 samples: 8.1125
Average Loss on fact answering task after 2544 samples: 8.2533
Average Loss on fact answering task after 2544 samples: 8.0852
Average Loss on fact answering task after 2544 samples: 7.9173
Mean accuracy: 0.8841, std: 0.0074, lower bound: 0.8697, upper bound: 0.8981 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 2544 samples: 0.8844
Epoch 1/1, Loss after 2688 samples: 0.2361
Epoch 1/1, Loss after 2896 samples: 0.2407
Average Loss on fact answering task after 3056 samples: 8.8694
Average Loss on fact answering task after 3056 samples: 9.0279
Average Loss on fact answering task after 3056 samples: 8.8560
Average Loss on fact answering task after 3056 samples: 8.7725
Average Loss on fact answering task after 3056 samples: 8.9651
Mean accuracy: 0.8817, std: 0.0070, lower bound: 0.8676, upper bound: 0.8950 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 3056 samples: 0.8818
Epoch 1/1, Loss after 3104 samples: 0.2611
Epoch 1/1, Loss after 3312 samples: 0.1530
Epoch 1/1, Loss after 3520 samples: 0.2673
Average Loss on fact answering task after 3568 samples: 10.9830
Average Loss on fact answering task after 3568 samples: 11.0354
Average Loss on fact answering task after 3568 samples: 10.7364
Average Loss on fact answering task after 3568 samples: 10.8048
Average Loss on fact answering task after 3568 samples: 11.0296
Mean accuracy: 0.8304, std: 0.0084, lower bound: 0.8134, upper bound: 0.8458 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 3568 samples: 0.8301
Epoch 1/1, Loss after 3728 samples: 0.1627
Epoch 1/1, Loss after 3936 samples: 0.2652
Average Loss on fact answering task after 4080 samples: 9.6759
Average Loss on fact answering task after 4080 samples: 9.3268
Average Loss on fact answering task after 4080 samples: 9.2215
Average Loss on fact answering task after 4080 samples: 9.4750
Average Loss on fact answering task after 4080 samples: 9.5144
Mean accuracy: 0.9104, std: 0.0065, lower bound: 0.8976, upper bound: 0.9229 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 4080 samples: 0.9102
Best model with eval accuracy 0.9102434077079108 with 4080 samples seen is saved
Epoch 1/1, Loss after 4144 samples: 0.3586
Epoch 1/1, Loss after 4352 samples: 0.2729
Epoch 1/1, Loss after 4560 samples: 0.1670
Average Loss on fact answering task after 4592 samples: 8.3378
Average Loss on fact answering task after 4592 samples: 8.4908
Average Loss on fact answering task after 4592 samples: 8.3314
Average Loss on fact answering task after 4592 samples: 8.6551
Average Loss on fact answering task after 4592 samples: 8.6369
Mean accuracy: 0.8753, std: 0.0074, lower bound: 0.8600, upper bound: 0.8895 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 4592 samples: 0.8753
Epoch 1/1, Loss after 4768 samples: 0.1393
Epoch 1/1, Loss after 4976 samples: 0.2370
Average Loss on fact answering task after 5104 samples: 8.5000
Average Loss on fact answering task after 5104 samples: 8.8416
Average Loss on fact answering task after 5104 samples: 8.4588
Average Loss on fact answering task after 5104 samples: 8.4560
Average Loss on fact answering task after 5104 samples: 8.6964
Mean accuracy: 0.8991, std: 0.0068, lower bound: 0.8869, upper bound: 0.9123 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 5104 samples: 0.8991
Epoch 1/1, Loss after 5184 samples: 0.1190
Epoch 1/1, Loss after 5392 samples: 0.2331
Epoch 1/1, Loss after 5600 samples: 0.1433
Average Loss on fact answering task after 5616 samples: 9.1157
Average Loss on fact answering task after 5616 samples: 9.0094
Average Loss on fact answering task after 5616 samples: 9.1615
Average Loss on fact answering task after 5616 samples: 9.0365
Average Loss on fact answering task after 5616 samples: 9.1674
Mean accuracy: 0.9278, std: 0.0058, lower bound: 0.9163, upper bound: 0.9392 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 5616 samples: 0.9280
Best model with eval accuracy 0.9279918864097363 with 5616 samples seen is saved
Epoch 1/1, Loss after 5808 samples: 0.1412
Epoch 1/1, Loss after 6016 samples: 0.1866
Average Loss on fact answering task after 6128 samples: 9.3464
Average Loss on fact answering task after 6128 samples: 9.5911
Average Loss on fact answering task after 6128 samples: 9.6892
Average Loss on fact answering task after 6128 samples: 9.0702
Average Loss on fact answering task after 6128 samples: 9.3647
Mean accuracy: 0.9493, std: 0.0049, lower bound: 0.9391, upper bound: 0.9584 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 6128 samples: 0.9493
Best model with eval accuracy 0.949290060851927 with 6128 samples seen is saved
Epoch 1/1, Loss after 6224 samples: 0.2496
Epoch 1/1, Loss after 6432 samples: 0.1838
Epoch 1/1, Loss after 6640 samples: 0.1569
Average Loss on fact answering task after 6640 samples: 8.9503
Average Loss on fact answering task after 6640 samples: 8.8355
Average Loss on fact answering task after 6640 samples: 8.7474
Average Loss on fact answering task after 6640 samples: 8.8612
Average Loss on fact answering task after 6640 samples: 8.9259
Mean accuracy: 0.8802, std: 0.0072, lower bound: 0.8661, upper bound: 0.8945 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 6640 samples: 0.8798
Epoch 1/1, Loss after 6848 samples: 0.1587
Epoch 1/1, Loss after 7056 samples: 0.0973
Average Loss on fact answering task after 7152 samples: 8.8230
Average Loss on fact answering task after 7152 samples: 8.7108
Average Loss on fact answering task after 7152 samples: 8.9044
Average Loss on fact answering task after 7152 samples: 8.7721
Average Loss on fact answering task after 7152 samples: 8.7063
Mean accuracy: 0.9376, std: 0.0054, lower bound: 0.9270, upper bound: 0.9483 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 7152 samples: 0.9376
Epoch 1/1, Loss after 7264 samples: 0.2575
Epoch 1/1, Loss after 7472 samples: 0.1387
Average Loss on fact answering task after 7664 samples: 7.5492
Average Loss on fact answering task after 7664 samples: 7.2087
Average Loss on fact answering task after 7664 samples: 7.6055
Average Loss on fact answering task after 7664 samples: 7.4368
Average Loss on fact answering task after 7664 samples: 7.4728
Mean accuracy: 0.9517, std: 0.0050, lower bound: 0.9422, upper bound: 0.9605 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 7664 samples: 0.9518
Best model with eval accuracy 0.9518255578093306 with 7664 samples seen is saved
Epoch 1/1, Loss after 7680 samples: 0.1504
Epoch 1/1, Loss after 7888 samples: 0.1593
Epoch 1/1, Loss after 8096 samples: 0.0956
Average Loss on fact answering task after 8176 samples: 7.7079
Average Loss on fact answering task after 8176 samples: 7.6330
Average Loss on fact answering task after 8176 samples: 7.8172
Average Loss on fact answering task after 8176 samples: 7.4596
Average Loss on fact answering task after 8176 samples: 7.3701
Mean accuracy: 0.9136, std: 0.0065, lower bound: 0.9011, upper bound: 0.9260 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 8176 samples: 0.9138
Epoch 1/1, Loss after 8304 samples: 0.1123
Epoch 1/1, Loss after 8512 samples: 0.0662
Average Loss on fact answering task after 8688 samples: 7.4199
Average Loss on fact answering task after 8688 samples: 7.4679
Average Loss on fact answering task after 8688 samples: 7.5967
Average Loss on fact answering task after 8688 samples: 7.4232
Average Loss on fact answering task after 8688 samples: 7.4260
Mean accuracy: 0.9264, std: 0.0059, lower bound: 0.9143, upper bound: 0.9371 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 8688 samples: 0.9265
Epoch 1/1, Loss after 8720 samples: 0.1071
Epoch 1/1, Loss after 8928 samples: 0.0721
Epoch 1/1, Loss after 9136 samples: 0.0779
Average Loss on fact answering task after 9200 samples: 7.4234
Average Loss on fact answering task after 9200 samples: 7.5126
Average Loss on fact answering task after 9200 samples: 7.4187
Average Loss on fact answering task after 9200 samples: 7.4902
Average Loss on fact answering task after 9200 samples: 7.4197
Mean accuracy: 0.9404, std: 0.0054, lower bound: 0.9295, upper bound: 0.9508 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 9200 samples: 0.9402
Epoch 1/1, Loss after 9344 samples: 0.1322
Epoch 1/1, Loss after 9552 samples: 0.1254
Average Loss on fact answering task after 9712 samples: 7.4044
Average Loss on fact answering task after 9712 samples: 7.4687
Average Loss on fact answering task after 9712 samples: 7.4695
Average Loss on fact answering task after 9712 samples: 7.5300
Average Loss on fact answering task after 9712 samples: 7.5690
Mean accuracy: 0.9544, std: 0.0047, lower bound: 0.9447, upper bound: 0.9635 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 9712 samples: 0.9544
Best model with eval accuracy 0.9543610547667343 with 9712 samples seen is saved
Epoch 1/1, Loss after 9760 samples: 0.1532
Epoch 1/1, Loss after 9968 samples: 0.1698
Epoch 1/1, Loss after 10176 samples: 0.1185
Average Loss on fact answering task after 10224 samples: 7.3408
Average Loss on fact answering task after 10224 samples: 7.1249
Average Loss on fact answering task after 10224 samples: 7.1634
Average Loss on fact answering task after 10224 samples: 7.3379
Average Loss on fact answering task after 10224 samples: 7.2841
Mean accuracy: 0.8779, std: 0.0070, lower bound: 0.8641, upper bound: 0.8920 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 10224 samples: 0.8783
Epoch 1/1, Loss after 10384 samples: 0.1196
Epoch 1/1, Loss after 10592 samples: 0.1077
Average Loss on fact answering task after 10736 samples: 7.0965
Average Loss on fact answering task after 10736 samples: 7.0956
Average Loss on fact answering task after 10736 samples: 6.8996
Average Loss on fact answering task after 10736 samples: 7.5811
Average Loss on fact answering task after 10736 samples: 7.3131
Mean accuracy: 0.9491, std: 0.0051, lower bound: 0.9386, upper bound: 0.9594 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 10736 samples: 0.9493
Epoch 1/1, Loss after 10800 samples: 0.1238
Epoch 1/1, Loss after 11008 samples: 0.1273
Epoch 1/1, Loss after 11216 samples: 0.0855
Average Loss on fact answering task after 11248 samples: 7.2806
Average Loss on fact answering task after 11248 samples: 7.1948
Average Loss on fact answering task after 11248 samples: 7.3458
Average Loss on fact answering task after 11248 samples: 7.2093
Average Loss on fact answering task after 11248 samples: 7.2325
Mean accuracy: 0.9449, std: 0.0051, lower bound: 0.9341, upper bound: 0.9549 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 11248 samples: 0.9447
Epoch 1/1, Loss after 11424 samples: 0.1784
Epoch 1/1, Loss after 11632 samples: 0.1437
Average Loss on fact answering task after 11760 samples: 7.5853
Average Loss on fact answering task after 11760 samples: 7.9085
Average Loss on fact answering task after 11760 samples: 8.0190
Average Loss on fact answering task after 11760 samples: 7.7727
Average Loss on fact answering task after 11760 samples: 7.8221
Mean accuracy: 0.9194, std: 0.0062, lower bound: 0.9072, upper bound: 0.9320 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 11760 samples: 0.9194
Epoch 1/1, Loss after 11840 samples: 0.0753
Epoch 1/1, Loss after 12048 samples: 0.1173
Epoch 1/1, Loss after 12256 samples: 0.0734
Average Loss on fact answering task after 12272 samples: 8.1220
Average Loss on fact answering task after 12272 samples: 7.9421
Average Loss on fact answering task after 12272 samples: 7.9078
Average Loss on fact answering task after 12272 samples: 7.9322
Average Loss on fact answering task after 12272 samples: 7.8240
Mean accuracy: 0.8824, std: 0.0075, lower bound: 0.8676, upper bound: 0.8971 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 12272 samples: 0.8824
Epoch 1/1, Loss after 12464 samples: 0.0924
Epoch 1/1, Loss after 12672 samples: 0.1086
Average Loss on fact answering task after 12784 samples: 7.6872
Average Loss on fact answering task after 12784 samples: 7.8034
Average Loss on fact answering task after 12784 samples: 7.7586
Average Loss on fact answering task after 12784 samples: 7.6983
Average Loss on fact answering task after 12784 samples: 7.8253
Mean accuracy: 0.9351, std: 0.0057, lower bound: 0.9239, upper bound: 0.9468 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 12784 samples: 0.9351
Epoch 1/1, Loss after 12880 samples: 0.0704
Epoch 1/1, Loss after 13088 samples: 0.0745
Epoch 1/1, Loss after 13296 samples: 0.1269
Average Loss on fact answering task after 13296 samples: 7.8604
Average Loss on fact answering task after 13296 samples: 7.7721
Average Loss on fact answering task after 13296 samples: 7.8669
Average Loss on fact answering task after 13296 samples: 7.9351
Average Loss on fact answering task after 13296 samples: 7.8861
Mean accuracy: 0.9299, std: 0.0059, lower bound: 0.9173, upper bound: 0.9407 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 13296 samples: 0.9300
Epoch 1/1, Loss after 13504 samples: 0.0587
Epoch 1/1, Loss after 13712 samples: 0.0839
Average Loss on fact answering task after 13808 samples: 8.0262
Average Loss on fact answering task after 13808 samples: 8.2323
Average Loss on fact answering task after 13808 samples: 7.9271
Average Loss on fact answering task after 13808 samples: 8.4420
Average Loss on fact answering task after 13808 samples: 8.3738
Mean accuracy: 0.8808, std: 0.0072, lower bound: 0.8671, upper bound: 0.8950 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 13808 samples: 0.8808
Epoch 1/1, Loss after 13920 samples: 0.0776
Epoch 1/1, Loss after 14128 samples: 0.1180
Average Loss on fact answering task after 14320 samples: 8.1413
Average Loss on fact answering task after 14320 samples: 8.2423
Average Loss on fact answering task after 14320 samples: 8.0376
Average Loss on fact answering task after 14320 samples: 8.1779
Average Loss on fact answering task after 14320 samples: 8.0354
Mean accuracy: 0.9005, std: 0.0064, lower bound: 0.8884, upper bound: 0.9128 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 14320 samples: 0.9001
Epoch 1/1, Loss after 14336 samples: 0.1024
Epoch 1/1, Loss after 14544 samples: 0.1214
Epoch 1/1, Loss after 14752 samples: 0.1082
Average Loss on fact answering task after 14832 samples: 8.2264
Average Loss on fact answering task after 14832 samples: 8.0674
Average Loss on fact answering task after 14832 samples: 7.9082
Average Loss on fact answering task after 14832 samples: 7.9740
Average Loss on fact answering task after 14832 samples: 8.1832
Mean accuracy: 0.9199, std: 0.0062, lower bound: 0.9072, upper bound: 0.9310 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 14832 samples: 0.9199
Epoch 1/1, Loss after 14960 samples: 0.0804
Epoch 1/1, Loss after 15168 samples: 0.0838
Average Loss on fact answering task after 15344 samples: 8.2312
Average Loss on fact answering task after 15344 samples: 8.2484
Average Loss on fact answering task after 15344 samples: 7.8139
Average Loss on fact answering task after 15344 samples: 8.1172
Average Loss on fact answering task after 15344 samples: 7.9372
Mean accuracy: 0.9074, std: 0.0068, lower bound: 0.8935, upper bound: 0.9204 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 15344 samples: 0.9072
Epoch 1/1, Loss after 15376 samples: 0.1288
Epoch 1/1, Loss after 15584 samples: 0.1321
Training signal is False, stopping training
Training finished
Best model: {'eval_acc': 0.9543610547667343, 'nb_samples': 9712}
Training loss logs: [{'samples': 192, 'loss': 0.7083705021784856}, {'samples': 400, 'loss': 0.6875375600961539}, {'samples': 608, 'loss': 0.6136049123910757}, {'samples': 816, 'loss': 0.4488185002253606}, {'samples': 1024, 'loss': 0.441892513862023}, {'samples': 1232, 'loss': 0.34679541221031773}, {'samples': 1440, 'loss': 0.299950333741995}, {'samples': 1648, 'loss': 0.3623707156914931}, {'samples': 1856, 'loss': 0.4087387231680063}, {'samples': 2064, 'loss': 0.24276739817399245}, {'samples': 2272, 'loss': 0.24804014884508574}, {'samples': 2480, 'loss': 0.2050987298672016}, {'samples': 2688, 'loss': 0.23610321948161492}, {'samples': 2896, 'loss': 0.24072408103025877}, {'samples': 3104, 'loss': 0.26109534960526687}, {'samples': 3312, 'loss': 0.15299681746042693}, {'samples': 3520, 'loss': 0.2672807895220243}, {'samples': 3728, 'loss': 0.1627254027586717}, {'samples': 3936, 'loss': 0.26519909042578477}, {'samples': 4144, 'loss': 0.35858301474497867}, {'samples': 4352, 'loss': 0.27290018246724057}, {'samples': 4560, 'loss': 0.1669928477360652}, {'samples': 4768, 'loss': 0.13931082303707415}, {'samples': 4976, 'loss': 0.23703817220834586}, {'samples': 5184, 'loss': 0.11901690180485065}, {'samples': 5392, 'loss': 0.23312723636627197}, {'samples': 5600, 'loss': 0.1432597843500284}, {'samples': 5808, 'loss': 0.14118879804244408}, {'samples': 6016, 'loss': 0.18664507224009588}, {'samples': 6224, 'loss': 0.24957942045651949}, {'samples': 6432, 'loss': 0.18382952419611123}, {'samples': 6640, 'loss': 0.15686085934822375}, {'samples': 6848, 'loss': 0.1587078456695263}, {'samples': 7056, 'loss': 0.09730857553390357}, {'samples': 7264, 'loss': 0.25753342990691847}, {'samples': 7472, 'loss': 0.13866779322807604}, {'samples': 7680, 'loss': 0.1503516470010464}, {'samples': 7888, 'loss': 0.15925707610753867}, {'samples': 8096, 'loss': 0.09561563455141507}, {'samples': 8304, 'loss': 0.11226956259745818}, {'samples': 8512, 'loss': 0.06615349707695153}, {'samples': 8720, 'loss': 0.10713334152331719}, {'samples': 8928, 'loss': 0.07210597395896912}, {'samples': 9136, 'loss': 0.07788380235433578}, {'samples': 9344, 'loss': 0.13217275303143722}, {'samples': 9552, 'loss': 0.1253977154309933}, {'samples': 9760, 'loss': 0.15323213717112175}, {'samples': 9968, 'loss': 0.1697524499434691}, {'samples': 10176, 'loss': 0.11852840162240542}, {'samples': 10384, 'loss': 0.11955869197845459}, {'samples': 10592, 'loss': 0.10769171554308671}, {'samples': 10800, 'loss': 0.12377542028060326}, {'samples': 11008, 'loss': 0.12731166298572832}, {'samples': 11216, 'loss': 0.08551859053281638}, {'samples': 11424, 'loss': 0.17838468230687654}, {'samples': 11632, 'loss': 0.14374690216321212}, {'samples': 11840, 'loss': 0.07534532592846797}, {'samples': 12048, 'loss': 0.11730042845010757}, {'samples': 12256, 'loss': 0.07336139736267236}, {'samples': 12464, 'loss': 0.09235042333602905}, {'samples': 12672, 'loss': 0.10858337638469842}, {'samples': 12880, 'loss': 0.07040774134489206}, {'samples': 13088, 'loss': 0.07453884298984821}, {'samples': 13296, 'loss': 0.12693954545717973}, {'samples': 13504, 'loss': 0.058680567603844866}, {'samples': 13712, 'loss': 0.0838786386526548}, {'samples': 13920, 'loss': 0.07762704675014202}, {'samples': 14128, 'loss': 0.11801262887624595}, {'samples': 14336, 'loss': 0.10238836934933296}, {'samples': 14544, 'loss': 0.12143525538536218}, {'samples': 14752, 'loss': 0.10821063300737968}, {'samples': 14960, 'loss': 0.0804462914283459}, {'samples': 15168, 'loss': 0.08383428076138863}, {'samples': 15376, 'loss': 0.12882923850646386}, {'samples': 15584, 'loss': 0.13206779326383883}]
Evaluation accuracy logs: [{'samples': 496, 'accuracy': 0.7646059837728194, 'std': 0.009448150215873885, 'lower_bound': 0.7459305273833671, 'upper_bound': 0.7834812373225153}, {'samples': 1008, 'accuracy': 0.8388569979716025, 'std': 0.008420429661640258, 'lower_bound': 0.821501014198783, 'upper_bound': 0.8549695740365112}, {'samples': 1520, 'accuracy': 0.898747971602434, 'std': 0.006826571913941217, 'lower_bound': 0.8853955375253549, 'upper_bound': 0.9122718052738337}, {'samples': 2032, 'accuracy': 0.8640076064908722, 'std': 0.007719406511679557, 'lower_bound': 0.8483772819472617, 'upper_bound': 0.8788032454361054}, {'samples': 2544, 'accuracy': 0.8840603448275861, 'std': 0.0074029270916366385, 'lower_bound': 0.8696754563894523, 'upper_bound': 0.8980730223123732}, {'samples': 3056, 'accuracy': 0.8817489858012171, 'std': 0.007032510946946833, 'lower_bound': 0.8676343813387424, 'upper_bound': 0.8950431034482759}, {'samples': 3568, 'accuracy': 0.8303737322515214, 'std': 0.008389759685534666, 'lower_bound': 0.8133874239350912, 'upper_bound': 0.845841784989858}, {'samples': 4080, 'accuracy': 0.9104127789046653, 'std': 0.006545088529894693, 'lower_bound': 0.8975659229208925, 'upper_bound': 0.922920892494929}, {'samples': 4592, 'accuracy': 0.8752946247464504, 'std': 0.007380211704945327, 'lower_bound': 0.8600405679513184, 'upper_bound': 0.8894523326572008}, {'samples': 5104, 'accuracy': 0.8991237322515212, 'std': 0.006786134638747763, 'lower_bound': 0.8869168356997972, 'upper_bound': 0.9122844827586207}, {'samples': 5616, 'accuracy': 0.9278443204868154, 'std': 0.005813542749800829, 'lower_bound': 0.9163159229208925, 'upper_bound': 0.9391607505070995}, {'samples': 6128, 'accuracy': 0.9492636916835699, 'std': 0.004941170225517892, 'lower_bound': 0.9391480730223124, 'upper_bound': 0.9584178498985801}, {'samples': 6640, 'accuracy': 0.8801693711967545, 'std': 0.007212450311491896, 'lower_bound': 0.8661130831643001, 'upper_bound': 0.8945233265720081}, {'samples': 7152, 'accuracy': 0.9375583164300203, 'std': 0.005446983393530552, 'lower_bound': 0.9269776876267748, 'upper_bound': 0.9482758620689655}, {'samples': 7664, 'accuracy': 0.9516861054766734, 'std': 0.004970282243489274, 'lower_bound': 0.9421779918864097, 'upper_bound': 0.9604589249492901}, {'samples': 8176, 'accuracy': 0.9136424949290061, 'std': 0.00650129881296395, 'lower_bound': 0.9011156186612576, 'upper_bound': 0.9259761663286005}, {'samples': 8688, 'accuracy': 0.9264158215010143, 'std': 0.0059341536072010604, 'lower_bound': 0.9142875253549695, 'upper_bound': 0.9371196754563894}, {'samples': 9200, 'accuracy': 0.9404315415821499, 'std': 0.005403763018009074, 'lower_bound': 0.9295131845841785, 'upper_bound': 0.9508113590263692}, {'samples': 9712, 'accuracy': 0.9544127789046652, 'std': 0.004694644880736484, 'lower_bound': 0.9447261663286004, 'upper_bound': 0.9634888438133874}, {'samples': 10224, 'accuracy': 0.8779442190669371, 'std': 0.0069763748676661625, 'lower_bound': 0.8640846855983773, 'upper_bound': 0.8919878296146044}, {'samples': 10736, 'accuracy': 0.9490578093306288, 'std': 0.005132893907200806, 'lower_bound': 0.9386409736308317, 'upper_bound': 0.9594320486815415}, {'samples': 11248, 'accuracy': 0.944872210953347, 'std': 0.005133966401984783, 'lower_bound': 0.934077079107505, 'upper_bound': 0.954868154158215}, {'samples': 11760, 'accuracy': 0.9194426977687626, 'std': 0.006189336991149527, 'lower_bound': 0.9072008113590264, 'upper_bound': 0.9320486815415822}, {'samples': 12272, 'accuracy': 0.8823874239350913, 'std': 0.007453798325684792, 'lower_bound': 0.8676470588235294, 'upper_bound': 0.8970588235294118}, {'samples': 12784, 'accuracy': 0.9350562880324544, 'std': 0.005658516657614084, 'lower_bound': 0.9239350912778904, 'upper_bound': 0.9467545638945233}, {'samples': 13296, 'accuracy': 0.9298539553752535, 'std': 0.005861253338543168, 'lower_bound': 0.9173427991886409, 'upper_bound': 0.9406693711967545}, {'samples': 13808, 'accuracy': 0.8808083164300203, 'std': 0.007219853902791972, 'lower_bound': 0.8671399594320487, 'upper_bound': 0.8950304259634888}, {'samples': 14320, 'accuracy': 0.9004893509127789, 'std': 0.006392264405012732, 'lower_bound': 0.8884381338742393, 'upper_bound': 0.9127789046653144}, {'samples': 14832, 'accuracy': 0.9198980730223124, 'std': 0.006167785484155147, 'lower_bound': 0.9072008113590264, 'upper_bound': 0.9310344827586207}, {'samples': 15344, 'accuracy': 0.907449290060852, 'std': 0.006783994915181165, 'lower_bound': 0.8935091277890467, 'upper_bound': 0.9203853955375254}]
