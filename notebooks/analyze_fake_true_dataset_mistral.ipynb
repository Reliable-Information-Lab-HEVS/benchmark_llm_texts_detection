{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_from_disk, Dataset, DatasetDict, concatenate_datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import wasserstein_distance\n",
    "\n",
    "\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label: true = 0, fake = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"mistral_10k\"\n",
    "fake_train_dataset_df = pd.read_json(f\"fake_true_datasets/fake_true_dataset_{experiment_name}_train.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Four groups that advocate for immigrant right...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Four groups that advocate for immigrant right...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Former Vice President Dick Cheney on Sunday d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Former Vice President Dick Cheney on Sunday d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Space shuttle Discovery launched just before ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15753</th>\n",
       "      <td>[A Pablo Picasso sketchbook with 33 pencil dra...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15754</th>\n",
       "      <td>[A Pablo Picasso sketchbook with 33 pencil dra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15755</th>\n",
       "      <td>[At a time when she really needed a miracle, A...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15756</th>\n",
       "      <td>[At a time when she really needed a miracle, A...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15757</th>\n",
       "      <td>[South Africa pace bowler Dale Steyn ripped th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15758 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0      [Four groups that advocate for immigrant right...      1\n",
       "1      [Four groups that advocate for immigrant right...      0\n",
       "2      [Former Vice President Dick Cheney on Sunday d...      1\n",
       "3      [Former Vice President Dick Cheney on Sunday d...      0\n",
       "4      [Space shuttle Discovery launched just before ...      0\n",
       "...                                                  ...    ...\n",
       "15753  [A Pablo Picasso sketchbook with 33 pencil dra...      1\n",
       "15754  [A Pablo Picasso sketchbook with 33 pencil dra...      0\n",
       "15755  [At a time when she really needed a miracle, A...      0\n",
       "15756  [At a time when she really needed a miracle, A...      1\n",
       "15757  [South Africa pace bowler Dale Steyn ripped th...      0\n",
       "\n",
       "[15758 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_train_dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Four groups that advocate for immigrant rights said Thursday they will not attend a planned rally against the construction of a mosque in the city of Murfreesboro, Tenn., because the organizers are not willing to denounce a group that is trying to stop the building of the mosque. “We’re going to stand with our friends and neighbors in Murfreesboro and be there with them on Saturday,” said a statement issued by the Tennessee Immigrant and Refugee Rights Coalition, the Tennessee Immigrant and Refu'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_train_dataset_df.iloc[0][\"text\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_train_dataset_df[\"text_sentences\"] = fake_train_dataset_df[\"text\"].apply(lambda x: x[0].split(\".\"))\n",
    "\n",
    "fake_texts_df = fake_train_dataset_df[fake_train_dataset_df[\"label\"] == 1]\n",
    "true_texts_df = fake_train_dataset_df[fake_train_dataset_df[\"label\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Four groups that advocate for immigrant rights said Thursday they will not attend a planned rally against the construction of a mosque in the city of Murfreesboro, Tenn',\n",
       " ', because the organizers are not willing to denounce a group that is trying to stop the building of the mosque',\n",
       " ' “We’re going to stand with our friends and neighbors in Murfreesboro and be there with them on Saturday,” said a statement issued by the Tennessee Immigrant and Refugee Rights Coalition, the Tennessee Immigrant and Refu']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_train_dataset_df[\"text_sentences\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of sentences in fake texts: 5.9761451592437504\n",
      "Average number of sentences in true texts: 5.234860987685667\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average number of sentences in fake texts: {np.mean(fake_texts_df['text_sentences'].apply(len))}\")\n",
    "print(f\"Average number of sentences in true texts: {np.mean(true_texts_df['text_sentences'].apply(len))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of 'the' in fake texts: 6.4211394493084635\n",
      "Average number of 'the' in true texts: 5.136854132283864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69727/176004568.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fake_texts_df[\"the_count\"] = fake_texts_df[\"text\"].apply(lambda x: x[0].count(\"the\"))\n",
      "/tmp/ipykernel_69727/176004568.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  true_texts_df[\"the_count\"] = true_texts_df[\"text\"].apply(lambda x: x[0].count(\"the\"))\n"
     ]
    }
   ],
   "source": [
    "# add column: number of \"the\" in text\n",
    "fake_texts_df[\"the_count\"] = fake_texts_df[\"text\"].apply(lambda x: x[0].count(\"the\"))\n",
    "true_texts_df[\"the_count\"] = true_texts_df[\"text\"].apply(lambda x: x[0].count(\"the\"))\n",
    "\n",
    "print(f\"Average number of 'the' in fake texts: {np.mean(fake_texts_df['the_count'])}\")\n",
    "print(f\"Average number of 'the' in true texts: {np.mean(true_texts_df['the_count'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_train_dataset_full_text = \" \".join([text for text in fake_train_dataset_df[\"text\"].apply(lambda x: x[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7894757"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fake_train_dataset_full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run through all the texts and count occurence of each characters in unicode representation\n",
    "\n",
    "def count_chars(texts):\n",
    "    char_counts = {}\n",
    "    for text in texts:\n",
    "        for char in text:\n",
    "            if char in char_counts:\n",
    "                char_counts[char] += 1\n",
    "            else:\n",
    "                char_counts[char] = 1\n",
    "    return char_counts\n",
    "\n",
    "fake_char_counts = count_chars(fake_train_dataset_full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 1348618,\n",
       " 'e': 739172,\n",
       " 'a': 551880,\n",
       " 't': 508465,\n",
       " 'i': 448472,\n",
       " 'o': 444178,\n",
       " 'n': 441168,\n",
       " 's': 389375,\n",
       " 'r': 389325,\n",
       " 'h': 300765,\n",
       " 'd': 246826,\n",
       " 'l': 238681,\n",
       " 'c': 174237,\n",
       " 'u': 151188,\n",
       " 'm': 138377,\n",
       " 'f': 129985,\n",
       " 'g': 116896,\n",
       " 'p': 110137,\n",
       " 'w': 107191,\n",
       " 'y': 103724,\n",
       " 'b': 82004,\n",
       " ',': 72967,\n",
       " '.': 72575,\n",
       " 'v': 57199,\n",
       " 'k': 46381,\n",
       " 'T': 35435,\n",
       " 'S': 27507,\n",
       " 'A': 25617,\n",
       " '-': 22738,\n",
       " 'I': 20806,\n",
       " 'C': 20415,\n",
       " '0': 20131,\n",
       " '\"': 18907,\n",
       " \"'\": 17884,\n",
       " 'M': 17780,\n",
       " '1': 15168,\n",
       " 'B': 14120,\n",
       " 'P': 13620,\n",
       " 'H': 11952,\n",
       " '2': 11724,\n",
       " 'N': 11677,\n",
       " 'W': 11063,\n",
       " 'F': 10453,\n",
       " 'D': 9632,\n",
       " 'x': 9603,\n",
       " 'R': 8667,\n",
       " 'L': 7926,\n",
       " 'j': 7782,\n",
       " 'U': 7602,\n",
       " 'J': 7536,\n",
       " 'G': 7330,\n",
       " 'O': 7186,\n",
       " 'z': 7163,\n",
       " 'E': 5817,\n",
       " '3': 5537,\n",
       " '9': 5401,\n",
       " 'K': 5371,\n",
       " '5': 5340,\n",
       " 'q': 4803,\n",
       " '4': 4528,\n",
       " '’': 4527,\n",
       " '8': 3740,\n",
       " '7': 3734,\n",
       " '6': 3702,\n",
       " 'V': 3081,\n",
       " '“': 2540,\n",
       " 'Y': 2479,\n",
       " ':': 2294,\n",
       " '#': 1931,\n",
       " '”': 1908,\n",
       " '(': 1775,\n",
       " ')': 1737,\n",
       " '$': 1400,\n",
       " '?': 1105,\n",
       " 'Z': 1011,\n",
       " 'Q': 737,\n",
       " '>': 396,\n",
       " '/': 317,\n",
       " ';': 286,\n",
       " '*': 277,\n",
       " 'X': 267,\n",
       " '!': 249,\n",
       " '&': 174,\n",
       " '%': 171,\n",
       " '[': 103,\n",
       " ']': 97,\n",
       " 'é': 85,\n",
       " '£': 82,\n",
       " '‘': 65,\n",
       " '—': 62,\n",
       " '–': 51,\n",
       " '•': 46,\n",
       " '+': 24,\n",
       " 'ñ': 23,\n",
       " '½': 21,\n",
       " '@': 18,\n",
       " 'á': 17,\n",
       " '€': 15,\n",
       " 'í': 14,\n",
       " 'ü': 13,\n",
       " '_': 13,\n",
       " '»': 10,\n",
       " 'ö': 10,\n",
       " 'ó': 10,\n",
       " '°': 9,\n",
       " '…': 8,\n",
       " 'ã': 8,\n",
       " '\\u200b': 8,\n",
       " 'è': 7,\n",
       " 'ı': 6,\n",
       " '■': 6,\n",
       " 'İ': 4,\n",
       " 'ï': 4,\n",
       " 'ä': 4,\n",
       " '^': 3,\n",
       " '|': 3,\n",
       " 'ş': 3,\n",
       " '\\xad': 3,\n",
       " 'ğ': 3,\n",
       " 'ú': 3,\n",
       " 'å': 3,\n",
       " 'ç': 3,\n",
       " '¥': 3,\n",
       " 'ø': 3,\n",
       " 'ë': 2,\n",
       " '®': 2,\n",
       " 'Ş': 2,\n",
       " '年': 2,\n",
       " '月': 2,\n",
       " '日': 2,\n",
       " '′': 2,\n",
       " '×': 2,\n",
       " '·': 2,\n",
       " 'â': 1,\n",
       " 'ô': 1,\n",
       " '{': 1,\n",
       " '}': 1,\n",
       " 'ń': 1,\n",
       " '⚠': 1,\n",
       " '️': 1,\n",
       " '″': 1,\n",
       " 'ė': 1,\n",
       " 'Ü': 1,\n",
       " '\\\\': 1,\n",
       " 'à': 1,\n",
       " '=': 1,\n",
       " 'ð': 1,\n",
       " 'Á': 1,\n",
       " 'ê': 1,\n",
       " 'É': 1,\n",
       " 'Ó': 1,\n",
       " 'Ø': 1,\n",
       " '♦': 1,\n",
       " 'ř': 1}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_char_counts_sorted = dict(sorted(fake_char_counts.items(), key=lambda item: item[1], reverse=True))\n",
    "fake_char_counts_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{32: 1348618,\n",
       " 101: 739172,\n",
       " 97: 551880,\n",
       " 116: 508465,\n",
       " 105: 448472,\n",
       " 111: 444178,\n",
       " 110: 441168,\n",
       " 115: 389375,\n",
       " 114: 389325,\n",
       " 104: 300765,\n",
       " 100: 246826,\n",
       " 108: 238681,\n",
       " 99: 174237,\n",
       " 117: 151188,\n",
       " 109: 138377,\n",
       " 102: 129985,\n",
       " 103: 116896,\n",
       " 112: 110137,\n",
       " 119: 107191,\n",
       " 121: 103724,\n",
       " 98: 82004,\n",
       " 44: 72967,\n",
       " 46: 72575,\n",
       " 118: 57199,\n",
       " 107: 46381,\n",
       " 84: 35435,\n",
       " 83: 27507,\n",
       " 65: 25617,\n",
       " 45: 22738,\n",
       " 73: 20806,\n",
       " 67: 20415,\n",
       " 48: 20131,\n",
       " 34: 18907,\n",
       " 39: 17884,\n",
       " 77: 17780,\n",
       " 49: 15168,\n",
       " 66: 14120,\n",
       " 80: 13620,\n",
       " 72: 11952,\n",
       " 50: 11724,\n",
       " 78: 11677,\n",
       " 87: 11063,\n",
       " 70: 10453,\n",
       " 68: 9632,\n",
       " 120: 9603,\n",
       " 82: 8667,\n",
       " 76: 7926,\n",
       " 106: 7782,\n",
       " 85: 7602,\n",
       " 74: 7536,\n",
       " 71: 7330,\n",
       " 79: 7186,\n",
       " 122: 7163,\n",
       " 69: 5817,\n",
       " 51: 5537,\n",
       " 57: 5401,\n",
       " 75: 5371,\n",
       " 53: 5340,\n",
       " 113: 4803,\n",
       " 52: 4528,\n",
       " 8217: 4527,\n",
       " 56: 3740,\n",
       " 55: 3734,\n",
       " 54: 3702,\n",
       " 86: 3081,\n",
       " 8220: 2540,\n",
       " 89: 2479,\n",
       " 58: 2294,\n",
       " 35: 1931,\n",
       " 8221: 1908,\n",
       " 40: 1775,\n",
       " 41: 1737,\n",
       " 36: 1400,\n",
       " 63: 1105,\n",
       " 90: 1011,\n",
       " 81: 737,\n",
       " 62: 396,\n",
       " 47: 317,\n",
       " 59: 286,\n",
       " 42: 277,\n",
       " 88: 267,\n",
       " 33: 249,\n",
       " 38: 174,\n",
       " 37: 171,\n",
       " 91: 103,\n",
       " 93: 97,\n",
       " 233: 85,\n",
       " 163: 82,\n",
       " 8216: 65,\n",
       " 8212: 62,\n",
       " 8211: 51,\n",
       " 8226: 46,\n",
       " 43: 24,\n",
       " 241: 23,\n",
       " 189: 21,\n",
       " 64: 18,\n",
       " 225: 17,\n",
       " 8364: 15,\n",
       " 237: 14,\n",
       " 252: 13,\n",
       " 95: 13,\n",
       " 187: 10,\n",
       " 246: 10,\n",
       " 243: 10,\n",
       " 176: 9,\n",
       " 8230: 8,\n",
       " 227: 8,\n",
       " 8203: 8,\n",
       " 232: 7,\n",
       " 305: 6,\n",
       " 9632: 6,\n",
       " 304: 4,\n",
       " 239: 4,\n",
       " 228: 4,\n",
       " 94: 3,\n",
       " 124: 3,\n",
       " 351: 3,\n",
       " 173: 3,\n",
       " 287: 3,\n",
       " 250: 3,\n",
       " 229: 3,\n",
       " 231: 3,\n",
       " 165: 3,\n",
       " 248: 3,\n",
       " 235: 2,\n",
       " 174: 2,\n",
       " 350: 2,\n",
       " 24180: 2,\n",
       " 26376: 2,\n",
       " 26085: 2,\n",
       " 8242: 2,\n",
       " 215: 2,\n",
       " 183: 2,\n",
       " 226: 1,\n",
       " 244: 1,\n",
       " 123: 1,\n",
       " 125: 1,\n",
       " 324: 1,\n",
       " 9888: 1,\n",
       " 65039: 1,\n",
       " 8243: 1,\n",
       " 279: 1,\n",
       " 220: 1,\n",
       " 92: 1,\n",
       " 224: 1,\n",
       " 61: 1,\n",
       " 240: 1,\n",
       " 193: 1,\n",
       " 234: 1,\n",
       " 201: 1,\n",
       " 211: 1,\n",
       " 216: 1,\n",
       " 9830: 1,\n",
       " 345: 1}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert keys in char_counts to unicode\n",
    "fake_char_counts_unicode = {ord(k): v for k, v in fake_char_counts_sorted.items()}\n",
    "fake_char_counts_unicode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'’': 4527,\n",
       " '“': 2540,\n",
       " '”': 1908,\n",
       " 'é': 85,\n",
       " '£': 82,\n",
       " '‘': 65,\n",
       " '—': 62,\n",
       " '–': 51,\n",
       " '•': 46,\n",
       " 'ñ': 23,\n",
       " '½': 21,\n",
       " 'á': 17,\n",
       " '€': 15,\n",
       " 'í': 14,\n",
       " 'ü': 13,\n",
       " '»': 10,\n",
       " 'ö': 10,\n",
       " 'ó': 10,\n",
       " '°': 9,\n",
       " '…': 8,\n",
       " 'ã': 8,\n",
       " '\\u200b': 8,\n",
       " 'è': 7,\n",
       " 'ı': 6,\n",
       " '■': 6,\n",
       " 'İ': 4,\n",
       " 'ï': 4,\n",
       " 'ä': 4,\n",
       " 'ş': 3,\n",
       " '\\xad': 3,\n",
       " 'ğ': 3,\n",
       " 'ú': 3,\n",
       " 'å': 3,\n",
       " 'ç': 3,\n",
       " '¥': 3,\n",
       " 'ø': 3,\n",
       " 'ë': 2,\n",
       " '®': 2,\n",
       " 'Ş': 2,\n",
       " '年': 2,\n",
       " '月': 2,\n",
       " '日': 2,\n",
       " '′': 2,\n",
       " '×': 2,\n",
       " '·': 2,\n",
       " 'â': 1,\n",
       " 'ô': 1,\n",
       " 'ń': 1,\n",
       " '⚠': 1,\n",
       " '️': 1,\n",
       " '″': 1,\n",
       " 'ė': 1,\n",
       " 'Ü': 1,\n",
       " 'à': 1,\n",
       " 'ð': 1,\n",
       " 'Á': 1,\n",
       " 'ê': 1,\n",
       " 'É': 1,\n",
       " 'Ó': 1,\n",
       " 'Ø': 1,\n",
       " '♦': 1,\n",
       " 'ř': 1}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exclude from count all ascii characters, ie. all keys above 128\n",
    "fake_char_counts_special = {k: v for k, v in fake_char_counts_sorted.items() if ord(k) > 128}\n",
    "fake_char_counts_special"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of normal apostrophes: 7100\n",
      "Number of special apostrophes: 4527\n"
     ]
    }
   ],
   "source": [
    "# count different kind of apostrophes\n",
    "count_apostrophe_type_1 = 0\n",
    "count_apostrophe_type_2 = 0\n",
    "\n",
    "# iterate over fake texts and count occurence of different apostrophes\n",
    "for text in fake_texts_df[\"text\"].apply(lambda x: x[0]):\n",
    "    count_apostrophe_type_1 += text.count(\"'\")\n",
    "    count_apostrophe_type_2 += text.count(\"’\")\n",
    "\n",
    "print(f\"Number of normal apostrophes: {count_apostrophe_type_1}\")\n",
    "print(f\"Number of special apostrophes: {count_apostrophe_type_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'—'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert form unicode to character\n",
    "chr(8212)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'–'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr(8211)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_detector",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
