{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_from_disk, Dataset, DatasetDict, concatenate_datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import wasserstein_distance\n",
    "\n",
    "\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label: true = 0, fake = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"gpt2_10k\"\n",
    "fake_train_dataset_df = pd.read_json(f\"fake_true_datasets/fake_true_dataset_{experiment_name}_train.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Four groups that advocate for immigrant right...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Four groups that advocate for immigrant right...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Former Vice President Dick Cheney on Sunday d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Former Vice President Dick Cheney on Sunday d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Space shuttle Discovery launched just before ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15891</th>\n",
       "      <td>[South Africa pace bowler Dale Steyn ripped th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15892</th>\n",
       "      <td>[South Africa pace bowler Dale Steyn ripped th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15893</th>\n",
       "      <td>[In a bustling room full of computers, giant w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15894</th>\n",
       "      <td>[In a bustling room full of computers, giant w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15895</th>\n",
       "      <td>[President Obama said Thursday that watching t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15896 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0      [Four groups that advocate for immigrant right...      0\n",
       "1      [Four groups that advocate for immigrant right...      1\n",
       "2      [Former Vice President Dick Cheney on Sunday d...      1\n",
       "3      [Former Vice President Dick Cheney on Sunday d...      0\n",
       "4      [Space shuttle Discovery launched just before ...      0\n",
       "...                                                  ...    ...\n",
       "15891  [South Africa pace bowler Dale Steyn ripped th...      1\n",
       "15892  [South Africa pace bowler Dale Steyn ripped th...      0\n",
       "15893  [In a bustling room full of computers, giant w...      0\n",
       "15894  [In a bustling room full of computers, giant w...      1\n",
       "15895  [President Obama said Thursday that watching t...      1\n",
       "\n",
       "[15896 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_train_dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Four groups that advocate for immigrant rights said Thursday they will challenge Arizona\\'s new immigration law, which allows police to ask anyone for proof of legal U.S. residency. The Mexican American Legal Defense and Educational Fund, the American Civil Liberties Union, the ACLU of Arizona and the National Immigration Law Center held a news conference Thursday in Phoenix to announce the legal challenge. \"The Arizona community can be assured that a vigorous and sophisticated legal challenge wi'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_train_dataset_df.iloc[0][\"text\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_train_dataset_df[\"text_sentences\"] = fake_train_dataset_df[\"text\"].apply(lambda x: x[0].split(\".\"))\n",
    "\n",
    "fake_texts_df = fake_train_dataset_df[fake_train_dataset_df[\"label\"] == 1]\n",
    "true_texts_df = fake_train_dataset_df[fake_train_dataset_df[\"label\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Four groups that advocate for immigrant rights said Thursday they will challenge Arizona's new immigration law, which allows police to ask anyone for proof of legal U\",\n",
       " 'S',\n",
       " ' residency',\n",
       " ' The Mexican American Legal Defense and Educational Fund, the American Civil Liberties Union, the ACLU of Arizona and the National Immigration Law Center held a news conference Thursday in Phoenix to announce the legal challenge',\n",
       " ' \"The Arizona community can be assured that a vigorous and sophisticated legal challenge wi']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_train_dataset_df[\"text_sentences\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of sentences in fake texts: 3.2786514026921627\n",
      "Average number of sentences in true texts: 5.230778910280609\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average number of sentences in fake texts: {np.mean(fake_texts_df['text_sentences'].apply(len))}\")\n",
    "print(f\"Average number of sentences in true texts: {np.mean(true_texts_df['text_sentences'].apply(len))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of 'the' in fake texts: 3.2274499937099006\n",
      "Average number of 'the' in true texts: 5.14080785201963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_163101/176004568.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fake_texts_df[\"the_count\"] = fake_texts_df[\"text\"].apply(lambda x: x[0].count(\"the\"))\n",
      "/tmp/ipykernel_163101/176004568.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  true_texts_df[\"the_count\"] = true_texts_df[\"text\"].apply(lambda x: x[0].count(\"the\"))\n"
     ]
    }
   ],
   "source": [
    "# add column: number of \"the\" in text\n",
    "fake_texts_df[\"the_count\"] = fake_texts_df[\"text\"].apply(lambda x: x[0].count(\"the\"))\n",
    "true_texts_df[\"the_count\"] = true_texts_df[\"text\"].apply(lambda x: x[0].count(\"the\"))\n",
    "\n",
    "print(f\"Average number of 'the' in fake texts: {np.mean(fake_texts_df['the_count'])}\")\n",
    "print(f\"Average number of 'the' in true texts: {np.mean(true_texts_df['the_count'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_train_dataset_full_text = \" \".join([text for text in fake_train_dataset_df[\"text\"].apply(lambda x: x[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7963895"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fake_train_dataset_full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run through all the texts and count occurence of each characters in unicode representation\n",
    "\n",
    "def count_chars(texts):\n",
    "    char_counts = {}\n",
    "    for text in texts:\n",
    "        for char in text:\n",
    "            if char in char_counts:\n",
    "                char_counts[char] += 1\n",
    "            else:\n",
    "                char_counts[char] = 1\n",
    "    return char_counts\n",
    "\n",
    "fake_char_counts = count_chars(fake_train_dataset_full_text)\n",
    "true_char_counts = count_chars(\" \".join([text for text in true_texts_df[\"text\"].apply(lambda x: x[0])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 1338478,\n",
       " 'e': 742644,\n",
       " 'a': 544795,\n",
       " 't': 504932,\n",
       " 'i': 458463,\n",
       " 'o': 457655,\n",
       " 'n': 450094,\n",
       " 'r': 410526,\n",
       " 's': 399733,\n",
       " 'h': 291556,\n",
       " 'l': 248791,\n",
       " 'd': 243313,\n",
       " 'c': 172994,\n",
       " 'u': 161707,\n",
       " 'm': 145277,\n",
       " 'g': 131199,\n",
       " 'f': 128126,\n",
       " 'w': 114671,\n",
       " 'y': 114521,\n",
       " 'p': 111566,\n",
       " 'b': 88241,\n",
       " 'v': 59831,\n",
       " '.': 51735,\n",
       " ',': 49898,\n",
       " 'k': 48388,\n",
       " 'T': 30333,\n",
       " 'S': 28164,\n",
       " 'A': 27058,\n",
       " \"'\": 24791,\n",
       " '\"': 23964,\n",
       " '-': 23175,\n",
       " 'C': 19343,\n",
       " 'I': 18883,\n",
       " 'M': 17731,\n",
       " 'P': 17462,\n",
       " '0': 15067,\n",
       " 'B': 13283,\n",
       " 'N': 12431,\n",
       " '1': 12388,\n",
       " 'H': 11603,\n",
       " 'W': 11442,\n",
       " 'F': 10835,\n",
       " 'x': 10431,\n",
       " 'R': 9495,\n",
       " 'D': 9444,\n",
       " '2': 9359,\n",
       " 'j': 8235,\n",
       " 'J': 8091,\n",
       " 'O': 7598,\n",
       " 'L': 7545,\n",
       " '(': 7536,\n",
       " ')': 7425,\n",
       " 'G': 7371,\n",
       " 'U': 7164,\n",
       " ':': 6618,\n",
       " 'z': 6469,\n",
       " 'E': 6192,\n",
       " 'K': 4895,\n",
       " 'q': 4725,\n",
       " '3': 4281,\n",
       " '5': 4151,\n",
       " '4': 3577,\n",
       " '9': 3555,\n",
       " 'V': 3045,\n",
       " '6': 2947,\n",
       " '7': 2913,\n",
       " '—': 2834,\n",
       " '8': 2832,\n",
       " 'Y': 2782,\n",
       " '/': 2357,\n",
       " ';': 1481,\n",
       " '$': 1360,\n",
       " '?': 1214,\n",
       " '!': 1120,\n",
       " '–': 1102,\n",
       " 'Z': 978,\n",
       " '[': 669,\n",
       " ']': 663,\n",
       " 'Q': 648,\n",
       " '&': 494,\n",
       " '…': 484,\n",
       " '|': 332,\n",
       " 'X': 328,\n",
       " '@': 305,\n",
       " '_': 210,\n",
       " '%': 196,\n",
       " '=': 133,\n",
       " '�': 90,\n",
       " '»': 90,\n",
       " '£': 83,\n",
       " '*': 72,\n",
       " 'é': 70,\n",
       " '´': 68,\n",
       " '+': 62,\n",
       " '•': 57,\n",
       " '#': 55,\n",
       " '>': 45,\n",
       " '`': 40,\n",
       " '‑': 31,\n",
       " 'á': 29,\n",
       " '©': 27,\n",
       " '›': 27,\n",
       " '\\\\': 26,\n",
       " '€': 25,\n",
       " 'ñ': 25,\n",
       " '‐': 22,\n",
       " 'í': 20,\n",
       " 'ó': 19,\n",
       " '<': 18,\n",
       " '·': 18,\n",
       " 'ö': 17,\n",
       " '½': 16,\n",
       " 'ü': 10,\n",
       " '×': 9,\n",
       " '\\xad': 8,\n",
       " '\\u200b': 6,\n",
       " '°': 6,\n",
       " '®': 6,\n",
       " '→': 5,\n",
       " '🙂': 5,\n",
       " 'ã': 5,\n",
       " '′': 4,\n",
       " 'Á': 4,\n",
       " '″': 4,\n",
       " 'ë': 4,\n",
       " 'è': 4,\n",
       " 'ú': 4,\n",
       " 'ä': 4,\n",
       " '{': 4,\n",
       " '―': 4,\n",
       " '~': 4,\n",
       " '}': 4,\n",
       " 'â': 3,\n",
       " 'Â': 3,\n",
       " 'ğ': 3,\n",
       " '™': 3,\n",
       " 'É': 3,\n",
       " '^': 2,\n",
       " 'ô': 2,\n",
       " 'Þ': 2,\n",
       " 'ا': 2,\n",
       " 'ل': 2,\n",
       " 'ï': 2,\n",
       " 'å': 2,\n",
       " 'ç': 2,\n",
       " '¥': 2,\n",
       " 'ø': 2,\n",
       " 'ð': 1,\n",
       " '\\ue606': 1,\n",
       " '货': 1,\n",
       " '源': 1,\n",
       " '\\ue607': 1,\n",
       " 'ه': 1,\n",
       " 'ع': 1,\n",
       " 'ن': 1,\n",
       " 'د': 1,\n",
       " 'ي': 1,\n",
       " 'م': 1,\n",
       " 'à': 1,\n",
       " '「': 1,\n",
       " '」': 1,\n",
       " 'ı': 1,\n",
       " 'ć': 1,\n",
       " '\\uf04b': 1,\n",
       " '自': 1,\n",
       " '洋': 1,\n",
       " '\\uf099': 1,\n",
       " '\\uf101': 1,\n",
       " '🇨': 1,\n",
       " '🍾': 1,\n",
       " '날': 1,\n",
       " '자': 1,\n",
       " '과': 1,\n",
       " '陳': 1,\n",
       " '家': 1,\n",
       " '\\ue800': 1,\n",
       " 'ㅠ': 1,\n",
       " '😉': 1,\n",
       " 'č': 1,\n",
       " 'š': 1}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_char_counts_sorted = dict(sorted(fake_char_counts.items(), key=lambda item: item[1], reverse=True))\n",
    "fake_char_counts_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{32: 1338478,\n",
       " 101: 742644,\n",
       " 97: 544795,\n",
       " 116: 504932,\n",
       " 105: 458463,\n",
       " 111: 457655,\n",
       " 110: 450094,\n",
       " 114: 410526,\n",
       " 115: 399733,\n",
       " 104: 291556,\n",
       " 108: 248791,\n",
       " 100: 243313,\n",
       " 99: 172994,\n",
       " 117: 161707,\n",
       " 109: 145277,\n",
       " 103: 131199,\n",
       " 102: 128126,\n",
       " 119: 114671,\n",
       " 121: 114521,\n",
       " 112: 111566,\n",
       " 98: 88241,\n",
       " 118: 59831,\n",
       " 46: 51735,\n",
       " 44: 49898,\n",
       " 107: 48388,\n",
       " 84: 30333,\n",
       " 83: 28164,\n",
       " 65: 27058,\n",
       " 39: 24791,\n",
       " 34: 23964,\n",
       " 45: 23175,\n",
       " 67: 19343,\n",
       " 73: 18883,\n",
       " 77: 17731,\n",
       " 80: 17462,\n",
       " 48: 15067,\n",
       " 66: 13283,\n",
       " 78: 12431,\n",
       " 49: 12388,\n",
       " 72: 11603,\n",
       " 87: 11442,\n",
       " 70: 10835,\n",
       " 120: 10431,\n",
       " 82: 9495,\n",
       " 68: 9444,\n",
       " 50: 9359,\n",
       " 106: 8235,\n",
       " 74: 8091,\n",
       " 79: 7598,\n",
       " 76: 7545,\n",
       " 40: 7536,\n",
       " 41: 7425,\n",
       " 71: 7371,\n",
       " 85: 7164,\n",
       " 58: 6618,\n",
       " 122: 6469,\n",
       " 69: 6192,\n",
       " 75: 4895,\n",
       " 113: 4725,\n",
       " 51: 4281,\n",
       " 53: 4151,\n",
       " 52: 3577,\n",
       " 57: 3555,\n",
       " 86: 3045,\n",
       " 54: 2947,\n",
       " 55: 2913,\n",
       " 8212: 2834,\n",
       " 56: 2832,\n",
       " 89: 2782,\n",
       " 47: 2357,\n",
       " 59: 1481,\n",
       " 36: 1360,\n",
       " 63: 1214,\n",
       " 33: 1120,\n",
       " 8211: 1102,\n",
       " 90: 978,\n",
       " 91: 669,\n",
       " 93: 663,\n",
       " 81: 648,\n",
       " 38: 494,\n",
       " 8230: 484,\n",
       " 124: 332,\n",
       " 88: 328,\n",
       " 64: 305,\n",
       " 95: 210,\n",
       " 37: 196,\n",
       " 61: 133,\n",
       " 65533: 90,\n",
       " 187: 90,\n",
       " 163: 83,\n",
       " 42: 72,\n",
       " 233: 70,\n",
       " 180: 68,\n",
       " 43: 62,\n",
       " 8226: 57,\n",
       " 35: 55,\n",
       " 62: 45,\n",
       " 96: 40,\n",
       " 8209: 31,\n",
       " 225: 29,\n",
       " 169: 27,\n",
       " 8250: 27,\n",
       " 92: 26,\n",
       " 8364: 25,\n",
       " 241: 25,\n",
       " 8208: 22,\n",
       " 237: 20,\n",
       " 243: 19,\n",
       " 60: 18,\n",
       " 183: 18,\n",
       " 246: 17,\n",
       " 189: 16,\n",
       " 252: 10,\n",
       " 215: 9,\n",
       " 173: 8,\n",
       " 8203: 6,\n",
       " 176: 6,\n",
       " 174: 6,\n",
       " 8594: 5,\n",
       " 128578: 5,\n",
       " 227: 5,\n",
       " 8242: 4,\n",
       " 193: 4,\n",
       " 8243: 4,\n",
       " 235: 4,\n",
       " 232: 4,\n",
       " 250: 4,\n",
       " 228: 4,\n",
       " 123: 4,\n",
       " 8213: 4,\n",
       " 126: 4,\n",
       " 125: 4,\n",
       " 226: 3,\n",
       " 194: 3,\n",
       " 287: 3,\n",
       " 8482: 3,\n",
       " 201: 3,\n",
       " 94: 2,\n",
       " 244: 2,\n",
       " 222: 2,\n",
       " 1575: 2,\n",
       " 1604: 2,\n",
       " 239: 2,\n",
       " 229: 2,\n",
       " 231: 2,\n",
       " 165: 2,\n",
       " 248: 2,\n",
       " 240: 1,\n",
       " 58886: 1,\n",
       " 36135: 1,\n",
       " 28304: 1,\n",
       " 58887: 1,\n",
       " 1607: 1,\n",
       " 1593: 1,\n",
       " 1606: 1,\n",
       " 1583: 1,\n",
       " 1610: 1,\n",
       " 1605: 1,\n",
       " 224: 1,\n",
       " 12300: 1,\n",
       " 12301: 1,\n",
       " 305: 1,\n",
       " 263: 1,\n",
       " 61515: 1,\n",
       " 33258: 1,\n",
       " 27915: 1,\n",
       " 61593: 1,\n",
       " 61697: 1,\n",
       " 127464: 1,\n",
       " 127870: 1,\n",
       " 45216: 1,\n",
       " 51088: 1,\n",
       " 44284: 1,\n",
       " 38515: 1,\n",
       " 23478: 1,\n",
       " 59392: 1,\n",
       " 12640: 1,\n",
       " 128521: 1,\n",
       " 269: 1,\n",
       " 353: 1}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert keys in char_counts to unicode\n",
    "fake_char_counts_unicode = {ord(k): v for k, v in fake_char_counts_sorted.items()}\n",
    "true_char_counts_unicode = {ord(k): v for k, v in true_char_counts.items()}\n",
    "fake_char_counts_unicode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'—': 2834,\n",
       " '–': 1102,\n",
       " '…': 484,\n",
       " '�': 90,\n",
       " '»': 90,\n",
       " '£': 83,\n",
       " 'é': 70,\n",
       " '´': 68,\n",
       " '•': 57,\n",
       " '‑': 31,\n",
       " 'á': 29,\n",
       " '©': 27,\n",
       " '›': 27,\n",
       " '€': 25,\n",
       " 'ñ': 25,\n",
       " '‐': 22,\n",
       " 'í': 20,\n",
       " 'ó': 19,\n",
       " '·': 18,\n",
       " 'ö': 17,\n",
       " '½': 16,\n",
       " 'ü': 10,\n",
       " '×': 9,\n",
       " '\\xad': 8,\n",
       " '\\u200b': 6,\n",
       " '°': 6,\n",
       " '®': 6,\n",
       " '→': 5,\n",
       " '🙂': 5,\n",
       " 'ã': 5,\n",
       " '′': 4,\n",
       " 'Á': 4,\n",
       " '″': 4,\n",
       " 'ë': 4,\n",
       " 'è': 4,\n",
       " 'ú': 4,\n",
       " 'ä': 4,\n",
       " '―': 4,\n",
       " 'â': 3,\n",
       " 'Â': 3,\n",
       " 'ğ': 3,\n",
       " '™': 3,\n",
       " 'É': 3,\n",
       " 'ô': 2,\n",
       " 'Þ': 2,\n",
       " 'ا': 2,\n",
       " 'ل': 2,\n",
       " 'ï': 2,\n",
       " 'å': 2,\n",
       " 'ç': 2,\n",
       " '¥': 2,\n",
       " 'ø': 2,\n",
       " 'ð': 1,\n",
       " '\\ue606': 1,\n",
       " '货': 1,\n",
       " '源': 1,\n",
       " '\\ue607': 1,\n",
       " 'ه': 1,\n",
       " 'ع': 1,\n",
       " 'ن': 1,\n",
       " 'د': 1,\n",
       " 'ي': 1,\n",
       " 'م': 1,\n",
       " 'à': 1,\n",
       " '「': 1,\n",
       " '」': 1,\n",
       " 'ı': 1,\n",
       " 'ć': 1,\n",
       " '\\uf04b': 1,\n",
       " '自': 1,\n",
       " '洋': 1,\n",
       " '\\uf099': 1,\n",
       " '\\uf101': 1,\n",
       " '🇨': 1,\n",
       " '🍾': 1,\n",
       " '날': 1,\n",
       " '자': 1,\n",
       " '과': 1,\n",
       " '陳': 1,\n",
       " '家': 1,\n",
       " '\\ue800': 1,\n",
       " 'ㅠ': 1,\n",
       " '😉': 1,\n",
       " 'č': 1,\n",
       " 'š': 1}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exclude from count all ascii characters, ie. all keys above 128\n",
    "fake_char_counts_special = {k: v for k, v in fake_char_counts_sorted.items() if ord(k) > 128}\n",
    "fake_char_counts_special"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'•': 38,\n",
       " 'é': 33,\n",
       " '£': 19,\n",
       " '½': 12,\n",
       " 'ñ': 12,\n",
       " '»': 10,\n",
       " '€': 7,\n",
       " 'í': 4,\n",
       " 'ä': 4,\n",
       " 'ã': 4,\n",
       " '\\xad': 3,\n",
       " '°': 3,\n",
       " 'è': 3,\n",
       " 'ú': 3,\n",
       " 'ö': 3,\n",
       " 'á': 2,\n",
       " 'ó': 2,\n",
       " 'â': 1,\n",
       " 'ô': 1,\n",
       " 'à': 1,\n",
       " 'ë': 1,\n",
       " '®': 1,\n",
       " 'Á': 1,\n",
       " 'ï': 1,\n",
       " 'ü': 1,\n",
       " 'É': 1,\n",
       " '¥': 1,\n",
       " 'ø': 1,\n",
       " 'å': 1}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_char_counts_special = {k: v for k, v in true_char_counts.items() if ord(k) > 128}\n",
    "\n",
    "# sort by value true_char_counts_special\n",
    "true_char_counts_special_sorted = dict(sorted(true_char_counts_special.items(), key=lambda item: item[1], reverse=True))\n",
    "true_char_counts_special_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of normal apostrophes: 10903\n",
      "Number of special apostrophes: 0\n"
     ]
    }
   ],
   "source": [
    "# count different kind of apostrophes\n",
    "count_apostrophe_type_1 = 0\n",
    "count_apostrophe_type_2 = 0\n",
    "\n",
    "# iterate over fake texts and count occurence of different apostrophes\n",
    "for text in true_texts_df[\"text\"].apply(lambda x: x[0]):\n",
    "    count_apostrophe_type_1 += text.count(\"'\")\n",
    "    count_apostrophe_type_2 += text.count(\"’\")\n",
    "\n",
    "print(f\"Number of normal apostrophes: {count_apostrophe_type_1}\")\n",
    "print(f\"Number of special apostrophes: {count_apostrophe_type_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of normal apostrophes: 13888\n",
      "Number of special apostrophes: 0\n"
     ]
    }
   ],
   "source": [
    "# count different kind of apostrophes\n",
    "count_apostrophe_type_1 = 0\n",
    "count_apostrophe_type_2 = 0\n",
    "\n",
    "# iterate over fake texts and count occurence of different apostrophes\n",
    "for text in fake_texts_df[\"text\"].apply(lambda x: x[0]):\n",
    "    count_apostrophe_type_1 += text.count(\"'\")\n",
    "    count_apostrophe_type_2 += text.count(\"’\")\n",
    "\n",
    "print(f\"Number of normal apostrophes: {count_apostrophe_type_1}\")\n",
    "print(f\"Number of special apostrophes: {count_apostrophe_type_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'—'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert form unicode to character\n",
    "chr(8212)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'–'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr(8211)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_detector",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
