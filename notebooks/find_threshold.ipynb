{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import jsonlines\n",
    "\n",
    "os.chdir(\"../\")\n",
    "\n",
    "SRC_PATH = [\"src\"]\n",
    "for module_path in SRC_PATH:\n",
    "    if module_path not in sys.path:\n",
    "        sys.path.append(module_path)\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = [\"phi\", \"gemma\", \"mistral\", \"round_robin\", \"gemma_chat\", \"zephyr\", \"llama3\"]\n",
    "training_method = \"full_finetuning\"\n",
    "trained_on_models = {\n",
    "    \"distil_roberta-base\": {\"10_06_1040\": \"phi\", \"10_06_1047\": \"gemma\", \"10_06_1054\": \"mistral\", \"10_06_1100\": \"round_robin\"},\n",
    "    \"roberta_large\": {\"10_06_1156\": \"phi\", \"10_06_1221\": \"gemma\", \"10_06_1246\": \"mistral\", \"10_06_1312\": \"round_robin\"},\n",
    "    \"electra_large\": {\"10_06_1146\": \"phi\", \"10_06_1215\": \"gemma\", \"10_06_1242\": \"mistral\", \"10_06_1308\": \"round_robin\"}\n",
    "    }\n",
    "#dataset_names = [\"zephyr\"]\n",
    "#training_method = \"full_finetuning\"\n",
    "#trained_on_models = { \"electra_large\": {\"03_05_1842\": \"phi\"}}\n",
    "\n",
    "test_results_df = create_df_from_test_logs(\"full_finetuning\", trained_on_models, dataset_names, use_eval_split=True)\n",
    "\n",
    "fast_detect_gpt_results = {\"fast_detect_gpt\": {\"07_05_0942\" : \"phi\", \"07_05_0949\" : \"gemma\", \"07_05_0956\" : \"mistral\", \"07_05_1003\" : \"round_robin\",\n",
    "                           \"07_05_1007\": \"gemma_chat\", \"07_05_1014\" : \"zephyr\", \"07_05_1020\" : \"llama3\"}}\n",
    "roberta_open_ai_results = {\"roberta_base_open_ai\": {\"06_05_1716\" : \"phi\", \"06_05_1718\" : \"gemma\", \"06_05_1719\" : \"mistral\", \"06_05_1721\" : \"round_robin\",\n",
    "                           \"06_05_1723\": \"gemma_chat\", \"06_05_1724\" : \"zephyr\", \"06_05_1726\" : \"llama3\"}}\n",
    "gpt_zero_results = {\"gpt_zero\": {\"06_05_1716\" : \"phi\", \"06_05_1718\" : \"gemma\", \"06_05_1719\" : \"mistral\", \"06_05_1721\" : \"round_robin\",\n",
    "                           \"06_05_1723\": \"gemma_chat\", \"06_05_1724\" : \"zephyr\", \"06_05_1726\" : \"llama3\"}}\n",
    "\n",
    "test_results_df = add_test_logs_to_results_df(test_results_df, fast_detect_gpt_results, use_timestamp=False, use_eval_split=True)\n",
    "test_results_df = add_test_logs_to_results_df(test_results_df, roberta_open_ai_results, use_timestamp=False, use_eval_split=True)\n",
    "test_results_df = add_test_logs_to_results_df(test_results_df, gpt_zero_results, use_timestamp=False, use_eval_split=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>fp_rate</th>\n",
       "      <th>tp_rate</th>\n",
       "      <th>std_accuracy</th>\n",
       "      <th>std_precision</th>\n",
       "      <th>std_recall</th>\n",
       "      <th>std_f1_score</th>\n",
       "      <th>...</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>fpr_at_thresholds</th>\n",
       "      <th>tpr_at_thresholds</th>\n",
       "      <th>thresholds</th>\n",
       "      <th>base_detector</th>\n",
       "      <th>trained_on_dataset</th>\n",
       "      <th>detector</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.946226</td>\n",
       "      <td>0.929217</td>\n",
       "      <td>0.966037</td>\n",
       "      <td>0.947244</td>\n",
       "      <td>0.073585</td>\n",
       "      <td>0.966037</td>\n",
       "      <td>0.005117</td>\n",
       "      <td>0.008175</td>\n",
       "      <td>0.005638</td>\n",
       "      <td>0.005145</td>\n",
       "      <td>...</td>\n",
       "      <td>72.777</td>\n",
       "      <td>33.588</td>\n",
       "      <td>0.992784</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0010111223458038423, 0.00101...</td>\n",
       "      <td>[0.0, 0.0010111223458038423, 0.666329625884732...</td>\n",
       "      <td>[inf, 3.7198092937469482, 1.8714631795883179, ...</td>\n",
       "      <td>distil_roberta-base</td>\n",
       "      <td>gemma</td>\n",
       "      <td>distil_roberta-base_gemma</td>\n",
       "      <td>gemma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.917906</td>\n",
       "      <td>0.925724</td>\n",
       "      <td>0.908924</td>\n",
       "      <td>0.917209</td>\n",
       "      <td>0.073110</td>\n",
       "      <td>0.908924</td>\n",
       "      <td>0.005968</td>\n",
       "      <td>0.008054</td>\n",
       "      <td>0.009114</td>\n",
       "      <td>0.006281</td>\n",
       "      <td>...</td>\n",
       "      <td>72.726</td>\n",
       "      <td>90.805</td>\n",
       "      <td>0.975545</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.001004016064257028, 0.001004...</td>\n",
       "      <td>[0.0, 0.001004016064257028, 0.4417670682730923...</td>\n",
       "      <td>[inf, 3.4843339920043945, 1.8711109161376953, ...</td>\n",
       "      <td>distil_roberta-base</td>\n",
       "      <td>gemma</td>\n",
       "      <td>distil_roberta-base_gemma</td>\n",
       "      <td>gemma_chat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.937235</td>\n",
       "      <td>0.928494</td>\n",
       "      <td>0.947612</td>\n",
       "      <td>0.937927</td>\n",
       "      <td>0.073181</td>\n",
       "      <td>0.947612</td>\n",
       "      <td>0.005515</td>\n",
       "      <td>0.008043</td>\n",
       "      <td>0.007003</td>\n",
       "      <td>0.005499</td>\n",
       "      <td>...</td>\n",
       "      <td>72.788</td>\n",
       "      <td>52.239</td>\n",
       "      <td>0.987563</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.001004016064257028, 0.001004...</td>\n",
       "      <td>[0.0, 0.001004016064257028, 0.5080321285140562...</td>\n",
       "      <td>[inf, 3.1349806785583496, 1.8709336519241333, ...</td>\n",
       "      <td>distil_roberta-base</td>\n",
       "      <td>gemma</td>\n",
       "      <td>distil_roberta-base_gemma</td>\n",
       "      <td>llama3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.932106</td>\n",
       "      <td>0.926762</td>\n",
       "      <td>0.938414</td>\n",
       "      <td>0.932520</td>\n",
       "      <td>0.074200</td>\n",
       "      <td>0.938414</td>\n",
       "      <td>0.005282</td>\n",
       "      <td>0.008034</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.005430</td>\n",
       "      <td>...</td>\n",
       "      <td>73.146</td>\n",
       "      <td>60.740</td>\n",
       "      <td>0.984585</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0010141987829614604, 0.00101...</td>\n",
       "      <td>[0.0, 0.0010141987829614604, 0.594320486815415...</td>\n",
       "      <td>[inf, 3.6040687561035156, 1.8827871084213257, ...</td>\n",
       "      <td>distil_roberta-base</td>\n",
       "      <td>gemma</td>\n",
       "      <td>distil_roberta-base_gemma</td>\n",
       "      <td>mistral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.945991</td>\n",
       "      <td>0.928965</td>\n",
       "      <td>0.965958</td>\n",
       "      <td>0.947077</td>\n",
       "      <td>0.074012</td>\n",
       "      <td>0.965958</td>\n",
       "      <td>0.005197</td>\n",
       "      <td>0.008101</td>\n",
       "      <td>0.005626</td>\n",
       "      <td>0.005264</td>\n",
       "      <td>...</td>\n",
       "      <td>73.643</td>\n",
       "      <td>33.942</td>\n",
       "      <td>0.990238</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.001004016064257028, 0.001004...</td>\n",
       "      <td>[0.0, 0.001004016064257028, 0.6355421686746988...</td>\n",
       "      <td>[inf, 3.6319003105163574, 1.8785992860794067, ...</td>\n",
       "      <td>distil_roberta-base</td>\n",
       "      <td>gemma</td>\n",
       "      <td>distil_roberta-base_gemma</td>\n",
       "      <td>phi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy  precision    recall  f1_score   fp_rate   tp_rate  std_accuracy  \\\n",
       "8   0.946226   0.929217  0.966037  0.947244  0.073585  0.966037      0.005117   \n",
       "11  0.917906   0.925724  0.908924  0.917209  0.073110  0.908924      0.005968   \n",
       "13  0.937235   0.928494  0.947612  0.937927  0.073181  0.947612      0.005515   \n",
       "9   0.932106   0.926762  0.938414  0.932520  0.074200  0.938414      0.005282   \n",
       "7   0.945991   0.928965  0.965958  0.947077  0.074012  0.965958      0.005197   \n",
       "\n",
       "    std_precision  std_recall  std_f1_score  ...      FP      FN   roc_auc  \\\n",
       "8        0.008175    0.005638      0.005145  ...  72.777  33.588  0.992784   \n",
       "11       0.008054    0.009114      0.006281  ...  72.726  90.805  0.975545   \n",
       "13       0.008043    0.007003      0.005499  ...  72.788  52.239  0.987563   \n",
       "9        0.008034    0.007281      0.005430  ...  73.146  60.740  0.984585   \n",
       "7        0.008101    0.005626      0.005264  ...  73.643  33.942  0.990238   \n",
       "\n",
       "                                    fpr_at_thresholds  \\\n",
       "8   [0.0, 0.0, 0.0, 0.0010111223458038423, 0.00101...   \n",
       "11  [0.0, 0.0, 0.0, 0.001004016064257028, 0.001004...   \n",
       "13  [0.0, 0.0, 0.0, 0.001004016064257028, 0.001004...   \n",
       "9   [0.0, 0.0, 0.0, 0.0010141987829614604, 0.00101...   \n",
       "7   [0.0, 0.0, 0.0, 0.001004016064257028, 0.001004...   \n",
       "\n",
       "                                    tpr_at_thresholds  \\\n",
       "8   [0.0, 0.0010111223458038423, 0.666329625884732...   \n",
       "11  [0.0, 0.001004016064257028, 0.4417670682730923...   \n",
       "13  [0.0, 0.001004016064257028, 0.5080321285140562...   \n",
       "9   [0.0, 0.0010141987829614604, 0.594320486815415...   \n",
       "7   [0.0, 0.001004016064257028, 0.6355421686746988...   \n",
       "\n",
       "                                           thresholds        base_detector  \\\n",
       "8   [inf, 3.7198092937469482, 1.8714631795883179, ...  distil_roberta-base   \n",
       "11  [inf, 3.4843339920043945, 1.8711109161376953, ...  distil_roberta-base   \n",
       "13  [inf, 3.1349806785583496, 1.8709336519241333, ...  distil_roberta-base   \n",
       "9   [inf, 3.6040687561035156, 1.8827871084213257, ...  distil_roberta-base   \n",
       "7   [inf, 3.6319003105163574, 1.8785992860794067, ...  distil_roberta-base   \n",
       "\n",
       "   trained_on_dataset                   detector     dataset  \n",
       "8               gemma  distil_roberta-base_gemma       gemma  \n",
       "11              gemma  distil_roberta-base_gemma  gemma_chat  \n",
       "13              gemma  distil_roberta-base_gemma      llama3  \n",
       "9               gemma  distil_roberta-base_gemma     mistral  \n",
       "7               gemma  distil_roberta-base_gemma         phi  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>fp_rate</th>\n",
       "      <th>tp_rate</th>\n",
       "      <th>std_accuracy</th>\n",
       "      <th>std_precision</th>\n",
       "      <th>std_recall</th>\n",
       "      <th>std_f1_score</th>\n",
       "      <th>...</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>fpr_at_thresholds</th>\n",
       "      <th>tpr_at_thresholds</th>\n",
       "      <th>thresholds</th>\n",
       "      <th>base_detector</th>\n",
       "      <th>trained_on_dataset</th>\n",
       "      <th>detector</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.948246</td>\n",
       "      <td>0.918602</td>\n",
       "      <td>0.983633</td>\n",
       "      <td>0.949983</td>\n",
       "      <td>0.087126</td>\n",
       "      <td>0.983633</td>\n",
       "      <td>0.004839</td>\n",
       "      <td>0.008243</td>\n",
       "      <td>0.004062</td>\n",
       "      <td>0.004820</td>\n",
       "      <td>...</td>\n",
       "      <td>86.794</td>\n",
       "      <td>16.300</td>\n",
       "      <td>0.990802</td>\n",
       "      <td>[0.0, 0.001004016064257028, 0.0010040160642570...</td>\n",
       "      <td>[0.0, 0.5381526104417671, 0.5873493975903614, ...</td>\n",
       "      <td>[inf, 1.0, 0.99, 0.98, 0.97, 0.96, 0.95, 0.94,...</td>\n",
       "      <td>fast_detect_gpt</td>\n",
       "      <td>z</td>\n",
       "      <td>fast_detect_gpt</td>\n",
       "      <td>phi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.945303</td>\n",
       "      <td>0.918089</td>\n",
       "      <td>0.977780</td>\n",
       "      <td>0.946971</td>\n",
       "      <td>0.087139</td>\n",
       "      <td>0.977780</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>0.008499</td>\n",
       "      <td>0.004738</td>\n",
       "      <td>0.005181</td>\n",
       "      <td>...</td>\n",
       "      <td>86.229</td>\n",
       "      <td>21.961</td>\n",
       "      <td>0.989422</td>\n",
       "      <td>[0.0, 0.0010111223458038423, 0.001011122345803...</td>\n",
       "      <td>[0.0, 0.48533872598584427, 0.5308392315470172,...</td>\n",
       "      <td>[inf, 1.0, 0.99, 0.98, 0.97, 0.96, 0.95, 0.94,...</td>\n",
       "      <td>fast_detect_gpt</td>\n",
       "      <td>z</td>\n",
       "      <td>fast_detect_gpt</td>\n",
       "      <td>gemma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.927976</td>\n",
       "      <td>0.915620</td>\n",
       "      <td>0.942931</td>\n",
       "      <td>0.929043</td>\n",
       "      <td>0.087009</td>\n",
       "      <td>0.942931</td>\n",
       "      <td>0.005820</td>\n",
       "      <td>0.008539</td>\n",
       "      <td>0.007631</td>\n",
       "      <td>0.006015</td>\n",
       "      <td>...</td>\n",
       "      <td>85.732</td>\n",
       "      <td>56.299</td>\n",
       "      <td>0.977622</td>\n",
       "      <td>[0.0, 0.0010141987829614604, 0.001014198782961...</td>\n",
       "      <td>[0.0, 0.31643002028397565, 0.3539553752535497,...</td>\n",
       "      <td>[inf, 1.0, 0.99, 0.98, 0.97, 0.96, 0.95, 0.94,...</td>\n",
       "      <td>fast_detect_gpt</td>\n",
       "      <td>z</td>\n",
       "      <td>fast_detect_gpt</td>\n",
       "      <td>mistral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.951673</td>\n",
       "      <td>0.933286</td>\n",
       "      <td>0.973025</td>\n",
       "      <td>0.952680</td>\n",
       "      <td>0.069703</td>\n",
       "      <td>0.973025</td>\n",
       "      <td>0.008013</td>\n",
       "      <td>0.013062</td>\n",
       "      <td>0.008238</td>\n",
       "      <td>0.008050</td>\n",
       "      <td>...</td>\n",
       "      <td>26.113</td>\n",
       "      <td>10.132</td>\n",
       "      <td>0.983794</td>\n",
       "      <td>[0.0, 0.008, 0.008, 0.008, 0.008, 0.008, 0.016...</td>\n",
       "      <td>[0.0, 0.496, 0.536, 0.5706666666666667, 0.576,...</td>\n",
       "      <td>[inf, 1.0, 0.99, 0.98, 0.97, 0.96, 0.95, 0.94,...</td>\n",
       "      <td>fast_detect_gpt</td>\n",
       "      <td>z</td>\n",
       "      <td>fast_detect_gpt</td>\n",
       "      <td>round_robin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.934354</td>\n",
       "      <td>0.918162</td>\n",
       "      <td>0.953767</td>\n",
       "      <td>0.935596</td>\n",
       "      <td>0.085077</td>\n",
       "      <td>0.953767</td>\n",
       "      <td>0.005458</td>\n",
       "      <td>0.008390</td>\n",
       "      <td>0.006603</td>\n",
       "      <td>0.005463</td>\n",
       "      <td>...</td>\n",
       "      <td>84.705</td>\n",
       "      <td>46.061</td>\n",
       "      <td>0.983149</td>\n",
       "      <td>[0.0, 0.001004016064257028, 0.0010040160642570...</td>\n",
       "      <td>[0.0, 0.41566265060240964, 0.45582329317269077...</td>\n",
       "      <td>[inf, 1.0, 0.99, 0.98, 0.97, 0.96, 0.95, 0.94,...</td>\n",
       "      <td>fast_detect_gpt</td>\n",
       "      <td>z</td>\n",
       "      <td>fast_detect_gpt</td>\n",
       "      <td>gemma_chat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.901909</td>\n",
       "      <td>0.910640</td>\n",
       "      <td>0.891196</td>\n",
       "      <td>0.900761</td>\n",
       "      <td>0.087392</td>\n",
       "      <td>0.891196</td>\n",
       "      <td>0.007239</td>\n",
       "      <td>0.009793</td>\n",
       "      <td>0.010517</td>\n",
       "      <td>0.007524</td>\n",
       "      <td>...</td>\n",
       "      <td>77.324</td>\n",
       "      <td>96.199</td>\n",
       "      <td>0.965321</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0011312217194570137, 0....</td>\n",
       "      <td>[0.0, 0.23502824858757063, 0.2677966101694915,...</td>\n",
       "      <td>[inf, 1.0, 0.99, 0.98, 0.97, 0.96, 0.95, 0.94,...</td>\n",
       "      <td>fast_detect_gpt</td>\n",
       "      <td>z</td>\n",
       "      <td>fast_detect_gpt</td>\n",
       "      <td>zephyr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.946131</td>\n",
       "      <td>0.918557</td>\n",
       "      <td>0.979021</td>\n",
       "      <td>0.947801</td>\n",
       "      <td>0.086729</td>\n",
       "      <td>0.979021</td>\n",
       "      <td>0.005237</td>\n",
       "      <td>0.008508</td>\n",
       "      <td>0.004622</td>\n",
       "      <td>0.005160</td>\n",
       "      <td>...</td>\n",
       "      <td>86.420</td>\n",
       "      <td>20.888</td>\n",
       "      <td>0.990578</td>\n",
       "      <td>[0.0, 0.001004016064257028, 0.0010040160642570...</td>\n",
       "      <td>[0.0, 0.5301204819277109, 0.5813253012048193, ...</td>\n",
       "      <td>[inf, 1.0, 0.99, 0.98, 0.97, 0.96, 0.95, 0.94,...</td>\n",
       "      <td>fast_detect_gpt</td>\n",
       "      <td>z</td>\n",
       "      <td>fast_detect_gpt</td>\n",
       "      <td>llama3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  precision    recall  f1_score   fp_rate   tp_rate  std_accuracy  \\\n",
       "0  0.948246   0.918602  0.983633  0.949983  0.087126  0.983633      0.004839   \n",
       "1  0.945303   0.918089  0.977780  0.946971  0.087139  0.977780      0.005200   \n",
       "2  0.927976   0.915620  0.942931  0.929043  0.087009  0.942931      0.005820   \n",
       "3  0.951673   0.933286  0.973025  0.952680  0.069703  0.973025      0.008013   \n",
       "4  0.934354   0.918162  0.953767  0.935596  0.085077  0.953767      0.005458   \n",
       "5  0.901909   0.910640  0.891196  0.900761  0.087392  0.891196      0.007239   \n",
       "6  0.946131   0.918557  0.979021  0.947801  0.086729  0.979021      0.005237   \n",
       "\n",
       "   std_precision  std_recall  std_f1_score  ...      FP      FN   roc_auc  \\\n",
       "0       0.008243    0.004062      0.004820  ...  86.794  16.300  0.990802   \n",
       "1       0.008499    0.004738      0.005181  ...  86.229  21.961  0.989422   \n",
       "2       0.008539    0.007631      0.006015  ...  85.732  56.299  0.977622   \n",
       "3       0.013062    0.008238      0.008050  ...  26.113  10.132  0.983794   \n",
       "4       0.008390    0.006603      0.005463  ...  84.705  46.061  0.983149   \n",
       "5       0.009793    0.010517      0.007524  ...  77.324  96.199  0.965321   \n",
       "6       0.008508    0.004622      0.005160  ...  86.420  20.888  0.990578   \n",
       "\n",
       "                                   fpr_at_thresholds  \\\n",
       "0  [0.0, 0.001004016064257028, 0.0010040160642570...   \n",
       "1  [0.0, 0.0010111223458038423, 0.001011122345803...   \n",
       "2  [0.0, 0.0010141987829614604, 0.001014198782961...   \n",
       "3  [0.0, 0.008, 0.008, 0.008, 0.008, 0.008, 0.016...   \n",
       "4  [0.0, 0.001004016064257028, 0.0010040160642570...   \n",
       "5  [0.0, 0.0, 0.0, 0.0, 0.0011312217194570137, 0....   \n",
       "6  [0.0, 0.001004016064257028, 0.0010040160642570...   \n",
       "\n",
       "                                   tpr_at_thresholds  \\\n",
       "0  [0.0, 0.5381526104417671, 0.5873493975903614, ...   \n",
       "1  [0.0, 0.48533872598584427, 0.5308392315470172,...   \n",
       "2  [0.0, 0.31643002028397565, 0.3539553752535497,...   \n",
       "3  [0.0, 0.496, 0.536, 0.5706666666666667, 0.576,...   \n",
       "4  [0.0, 0.41566265060240964, 0.45582329317269077...   \n",
       "5  [0.0, 0.23502824858757063, 0.2677966101694915,...   \n",
       "6  [0.0, 0.5301204819277109, 0.5813253012048193, ...   \n",
       "\n",
       "                                          thresholds    base_detector  \\\n",
       "0  [inf, 1.0, 0.99, 0.98, 0.97, 0.96, 0.95, 0.94,...  fast_detect_gpt   \n",
       "1  [inf, 1.0, 0.99, 0.98, 0.97, 0.96, 0.95, 0.94,...  fast_detect_gpt   \n",
       "2  [inf, 1.0, 0.99, 0.98, 0.97, 0.96, 0.95, 0.94,...  fast_detect_gpt   \n",
       "3  [inf, 1.0, 0.99, 0.98, 0.97, 0.96, 0.95, 0.94,...  fast_detect_gpt   \n",
       "4  [inf, 1.0, 0.99, 0.98, 0.97, 0.96, 0.95, 0.94,...  fast_detect_gpt   \n",
       "5  [inf, 1.0, 0.99, 0.98, 0.97, 0.96, 0.95, 0.94,...  fast_detect_gpt   \n",
       "6  [inf, 1.0, 0.99, 0.98, 0.97, 0.96, 0.95, 0.94,...  fast_detect_gpt   \n",
       "\n",
       "  trained_on_dataset         detector      dataset  \n",
       "0                  z  fast_detect_gpt          phi  \n",
       "1                  z  fast_detect_gpt        gemma  \n",
       "2                  z  fast_detect_gpt      mistral  \n",
       "3                  z  fast_detect_gpt  round_robin  \n",
       "4                  z  fast_detect_gpt   gemma_chat  \n",
       "5                  z  fast_detect_gpt       zephyr  \n",
       "6                  z  fast_detect_gpt       llama3  \n",
       "\n",
       "[7 rows x 24 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results_df[test_results_df[\"detector\"] == \"fast_detect_gpt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['distil_roberta-base_gemma', 'electra_large_gemma',\n",
       "       'roberta_large_gemma', 'distil_roberta-base_mistral',\n",
       "       'electra_large_mistral', 'roberta_large_mistral',\n",
       "       'distil_roberta-base_phi', 'electra_large_phi',\n",
       "       'roberta_large_phi', 'distil_roberta-base_round_robin',\n",
       "       'electra_large_round_robin', 'roberta_large_round_robin',\n",
       "       'fast_detect_gpt', 'roberta_base_open_ai', 'gpt_zero'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detectors = test_results_df[\"detector\"].unique()\n",
    "detectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detector distil_roberta-base_gemma on dataset phi\n",
      "Threshold for target FPR 0.05: 0.26239141821861267\n",
      "TPR at threshold: 0.9467871485943775\n",
      "FPR at threshold: 0.05421686746987952\n",
      "\n",
      "Detector distil_roberta-base_gemma on dataset gemma\n",
      "Threshold for target FPR 0.05: 0.27046048641204834\n",
      "TPR at threshold: 0.9544994944388271\n",
      "FPR at threshold: 0.05055611729019211\n",
      "\n",
      "Detector distil_roberta-base_gemma on dataset mistral\n",
      "Threshold for target FPR 0.05: 0.27046048641204834\n",
      "TPR at threshold: 0.9178498985801217\n",
      "FPR at threshold: 0.05070993914807302\n",
      "\n",
      "Detector distil_roberta-base_gemma on dataset round_robin\n",
      "Threshold for target FPR 0.05: 0.16181477904319763\n",
      "TPR at threshold: 0.952\n",
      "FPR at threshold: 0.050666666666666665\n",
      "\n",
      "Detector distil_roberta-base_gemma on dataset gemma_chat\n",
      "Threshold for target FPR 0.05: 0.27046048641204834\n",
      "TPR at threshold: 0.8704819277108434\n",
      "FPR at threshold: 0.050200803212851405\n",
      "\n",
      "Detector distil_roberta-base_gemma on dataset zephyr\n",
      "Threshold for target FPR 0.05: 0.16181477904319763\n",
      "TPR at threshold: 0.8508474576271187\n",
      "FPR at threshold: 0.05090497737556561\n",
      "\n",
      "Detector distil_roberta-base_gemma on dataset llama3\n",
      "Threshold for target FPR 0.05: 0.27046048641204834\n",
      "TPR at threshold: 0.928714859437751\n",
      "FPR at threshold: 0.050200803212851405\n",
      "\n",
      "Detector electra_large_gemma on dataset phi\n",
      "Threshold for target FPR 0.05: -0.44769975543022156\n",
      "TPR at threshold: 0.9789156626506024\n",
      "FPR at threshold: 0.050200803212851405\n",
      "\n",
      "Detector electra_large_gemma on dataset gemma\n",
      "Threshold for target FPR 0.05: -0.5850827097892761\n",
      "TPR at threshold: 0.9908998988877654\n",
      "FPR at threshold: 0.0525783619817998\n",
      "\n",
      "Detector electra_large_gemma on dataset mistral\n",
      "Threshold for target FPR 0.05: -0.6413555145263672\n",
      "TPR at threshold: 0.9695740365111561\n",
      "FPR at threshold: 0.05476673427991886\n",
      "\n",
      "Detector electra_large_gemma on dataset round_robin\n",
      "Threshold for target FPR 0.05: -1.6195952892303467\n",
      "TPR at threshold: 0.992\n",
      "FPR at threshold: 0.08533333333333333\n",
      "\n",
      "Detector electra_large_gemma on dataset gemma_chat\n",
      "Threshold for target FPR 0.05: -0.5850827097892761\n",
      "TPR at threshold: 0.9738955823293173\n",
      "FPR at threshold: 0.05220883534136546\n",
      "\n",
      "Detector electra_large_gemma on dataset zephyr\n",
      "Threshold for target FPR 0.05: -0.7194408774375916\n",
      "TPR at threshold: 0.9299435028248587\n",
      "FPR at threshold: 0.05203619909502263\n",
      "\n",
      "Detector electra_large_gemma on dataset llama3\n",
      "Threshold for target FPR 0.05: -0.5809829831123352\n",
      "TPR at threshold: 0.9789156626506024\n",
      "FPR at threshold: 0.05120481927710843\n",
      "\n",
      "Detector roberta_large_gemma on dataset phi\n",
      "Threshold for target FPR 0.05: 0.6218387484550476\n",
      "TPR at threshold: 0.9668674698795181\n",
      "FPR at threshold: 0.05120481927710843\n",
      "\n",
      "Detector roberta_large_gemma on dataset gemma\n",
      "Threshold for target FPR 0.05: 0.553473949432373\n",
      "TPR at threshold: 0.9817997977755308\n",
      "FPR at threshold: 0.054600606673407485\n",
      "\n",
      "Detector roberta_large_gemma on dataset mistral\n",
      "Threshold for target FPR 0.05: 0.6006136536598206\n",
      "TPR at threshold: 0.9381338742393509\n",
      "FPR at threshold: 0.05172413793103448\n",
      "\n",
      "Detector roberta_large_gemma on dataset round_robin\n",
      "Threshold for target FPR 0.05: 0.44436612725257874\n",
      "TPR at threshold: 0.9653333333333334\n",
      "FPR at threshold: 0.06133333333333333\n",
      "\n",
      "Detector roberta_large_gemma on dataset gemma_chat\n",
      "Threshold for target FPR 0.05: 0.5798153281211853\n",
      "TPR at threshold: 0.9176706827309237\n",
      "FPR at threshold: 0.05321285140562249\n",
      "\n",
      "Detector roberta_large_gemma on dataset zephyr\n",
      "Threshold for target FPR 0.05: 0.507049560546875\n",
      "TPR at threshold: 0.9570621468926553\n",
      "FPR at threshold: 0.05090497737556561\n",
      "\n",
      "Detector roberta_large_gemma on dataset llama3\n",
      "Threshold for target FPR 0.05: 0.528086245059967\n",
      "TPR at threshold: 0.9688755020080321\n",
      "FPR at threshold: 0.055220883534136546\n",
      "\n",
      "Detector distil_roberta-base_mistral on dataset phi\n",
      "Threshold for target FPR 0.05: 0.38079580664634705\n",
      "TPR at threshold: 0.9799196787148594\n",
      "FPR at threshold: 0.05321285140562249\n",
      "\n",
      "Detector distil_roberta-base_mistral on dataset gemma\n",
      "Threshold for target FPR 0.05: 0.2950550615787506\n",
      "TPR at threshold: 0.9726996966632963\n",
      "FPR at threshold: 0.06370070778564206\n",
      "\n",
      "Detector distil_roberta-base_mistral on dataset mistral\n",
      "Threshold for target FPR 0.05: 0.4447759687900543\n",
      "TPR at threshold: 0.9482758620689655\n",
      "FPR at threshold: 0.05273833671399594\n",
      "\n",
      "Detector distil_roberta-base_mistral on dataset round_robin\n",
      "Threshold for target FPR 0.05: 0.34728097915649414\n",
      "TPR at threshold: 0.9653333333333334\n",
      "FPR at threshold: 0.050666666666666665\n",
      "\n",
      "Detector distil_roberta-base_mistral on dataset gemma_chat\n",
      "Threshold for target FPR 0.05: 0.4447759687900543\n",
      "TPR at threshold: 0.8785140562248996\n",
      "FPR at threshold: 0.05220883534136546\n",
      "\n",
      "Detector distil_roberta-base_mistral on dataset zephyr\n",
      "Threshold for target FPR 0.05: 0.3131090998649597\n",
      "TPR at threshold: 0.880225988700565\n",
      "FPR at threshold: 0.05090497737556561\n",
      "\n",
      "Detector distil_roberta-base_mistral on dataset llama3\n",
      "Threshold for target FPR 0.05: 0.4473596513271332\n",
      "TPR at threshold: 0.9497991967871486\n",
      "FPR at threshold: 0.05120481927710843\n",
      "\n",
      "Detector electra_large_mistral on dataset phi\n",
      "Threshold for target FPR 0.05: 0.20634852349758148\n",
      "TPR at threshold: 0.9799196787148594\n",
      "FPR at threshold: 0.05120481927710843\n",
      "\n",
      "Detector electra_large_mistral on dataset gemma\n",
      "Threshold for target FPR 0.05: 0.10198206454515457\n",
      "TPR at threshold: 0.9817997977755308\n",
      "FPR at threshold: 0.057633973710819006\n",
      "\n",
      "Detector electra_large_mistral on dataset mistral\n",
      "Threshold for target FPR 0.05: 0.19038350880146027\n",
      "TPR at threshold: 0.9695740365111561\n",
      "FPR at threshold: 0.05273833671399594\n",
      "\n",
      "Detector electra_large_mistral on dataset round_robin\n",
      "Threshold for target FPR 0.05: -0.17242999374866486\n",
      "TPR at threshold: 0.9813333333333333\n",
      "FPR at threshold: 0.05333333333333334\n",
      "\n",
      "Detector electra_large_mistral on dataset gemma_chat\n",
      "Threshold for target FPR 0.05: 0.19038350880146027\n",
      "TPR at threshold: 0.9317269076305221\n",
      "FPR at threshold: 0.05220883534136546\n",
      "\n",
      "Detector electra_large_mistral on dataset zephyr\n",
      "Threshold for target FPR 0.05: 0.10198206454515457\n",
      "TPR at threshold: 0.9186440677966101\n",
      "FPR at threshold: 0.05203619909502263\n",
      "\n",
      "Detector electra_large_mistral on dataset llama3\n",
      "Threshold for target FPR 0.05: 0.19038350880146027\n",
      "TPR at threshold: 0.9748995983935743\n",
      "FPR at threshold: 0.05220883534136546\n",
      "\n",
      "Detector roberta_large_mistral on dataset phi\n",
      "Threshold for target FPR 0.05: 0.006803194992244244\n",
      "TPR at threshold: 0.9738955823293173\n",
      "FPR at threshold: 0.05421686746987952\n",
      "\n",
      "Detector roberta_large_mistral on dataset gemma\n",
      "Threshold for target FPR 0.05: 0.006803194992244244\n",
      "TPR at threshold: 0.9757330637007078\n",
      "FPR at threshold: 0.0525783619817998\n",
      "\n",
      "Detector roberta_large_mistral on dataset mistral\n",
      "Threshold for target FPR 0.05: 0.006803194992244244\n",
      "TPR at threshold: 0.9685598377281948\n",
      "FPR at threshold: 0.05273833671399594\n",
      "\n",
      "Detector roberta_large_mistral on dataset round_robin\n",
      "Threshold for target FPR 0.05: -0.35557883977890015\n",
      "TPR at threshold: 0.9813333333333333\n",
      "FPR at threshold: 0.05333333333333334\n",
      "\n",
      "Detector roberta_large_mistral on dataset gemma_chat\n",
      "Threshold for target FPR 0.05: 0.02354467287659645\n",
      "TPR at threshold: 0.9226907630522089\n",
      "FPR at threshold: 0.05120481927710843\n",
      "\n",
      "Detector roberta_large_mistral on dataset zephyr\n",
      "Threshold for target FPR 0.05: -0.127238929271698\n",
      "TPR at threshold: 0.9333333333333333\n",
      "FPR at threshold: 0.05090497737556561\n",
      "\n",
      "Detector roberta_large_mistral on dataset llama3\n",
      "Threshold for target FPR 0.05: 0.02354467287659645\n",
      "TPR at threshold: 0.9799196787148594\n",
      "FPR at threshold: 0.05120481927710843\n",
      "\n",
      "Detector distil_roberta-base_phi on dataset phi\n",
      "Threshold for target FPR 0.05: 0.0540054589509964\n",
      "TPR at threshold: 0.9769076305220884\n",
      "FPR at threshold: 0.050200803212851405\n",
      "\n",
      "Detector distil_roberta-base_phi on dataset gemma\n",
      "Threshold for target FPR 0.05: 0.004177845548838377\n",
      "TPR at threshold: 0.9079878665318504\n",
      "FPR at threshold: 0.0525783619817998\n",
      "\n",
      "Detector distil_roberta-base_phi on dataset mistral\n",
      "Threshold for target FPR 0.05: -0.016925202682614326\n",
      "TPR at threshold: 0.896551724137931\n",
      "FPR at threshold: 0.05476673427991886\n",
      "\n",
      "Detector distil_roberta-base_phi on dataset round_robin\n",
      "Threshold for target FPR 0.05: 0.16298839449882507\n",
      "TPR at threshold: 0.9386666666666666\n",
      "FPR at threshold: 0.056\n",
      "\n",
      "Detector distil_roberta-base_phi on dataset gemma_chat\n",
      "Threshold for target FPR 0.05: 0.03146934509277344\n",
      "TPR at threshold: 0.9397590361445783\n",
      "FPR at threshold: 0.05120481927710843\n",
      "\n",
      "Detector distil_roberta-base_phi on dataset zephyr\n",
      "Threshold for target FPR 0.05: -0.03668294847011566\n",
      "TPR at threshold: 0.8677966101694915\n",
      "FPR at threshold: 0.05090497737556561\n",
      "\n",
      "Detector distil_roberta-base_phi on dataset llama3\n",
      "Threshold for target FPR 0.05: 0.03146934509277344\n",
      "TPR at threshold: 0.9487951807228916\n",
      "FPR at threshold: 0.05120481927710843\n",
      "\n",
      "Detector electra_large_phi on dataset phi\n",
      "Threshold for target FPR 0.05: -1.0533567667007446\n",
      "TPR at threshold: 0.9939759036144579\n",
      "FPR at threshold: 0.05120481927710843\n",
      "\n",
      "Detector electra_large_phi on dataset gemma\n",
      "Threshold for target FPR 0.05: -1.106029748916626\n",
      "TPR at threshold: 0.980788675429727\n",
      "FPR at threshold: 0.05358948432760364\n",
      "\n",
      "Detector electra_large_phi on dataset mistral\n",
      "Threshold for target FPR 0.05: -1.0533567667007446\n",
      "TPR at threshold: 0.9442190669371197\n",
      "FPR at threshold: 0.05070993914807302\n",
      "\n",
      "Detector electra_large_phi on dataset round_robin\n",
      "Threshold for target FPR 0.05: -1.74638831615448\n",
      "TPR at threshold: 0.9866666666666667\n",
      "FPR at threshold: 0.058666666666666666\n",
      "\n",
      "Detector electra_large_phi on dataset gemma_chat\n",
      "Threshold for target FPR 0.05: -1.0533567667007446\n",
      "TPR at threshold: 0.9558232931726908\n",
      "FPR at threshold: 0.050200803212851405\n",
      "\n",
      "Detector electra_large_phi on dataset zephyr\n",
      "Threshold for target FPR 0.05: -1.308728814125061\n",
      "TPR at threshold: 0.9209039548022598\n",
      "FPR at threshold: 0.05090497737556561\n",
      "\n",
      "Detector electra_large_phi on dataset llama3\n",
      "Threshold for target FPR 0.05: -1.0892279148101807\n",
      "TPR at threshold: 0.9779116465863453\n",
      "FPR at threshold: 0.05120481927710843\n",
      "\n",
      "Detector roberta_large_phi on dataset phi\n",
      "Threshold for target FPR 0.05: 0.06297480314970016\n",
      "TPR at threshold: 0.9708835341365462\n",
      "FPR at threshold: 0.050200803212851405\n",
      "\n",
      "Detector roberta_large_phi on dataset gemma\n",
      "Threshold for target FPR 0.05: 0.02794809266924858\n",
      "TPR at threshold: 0.897876643073812\n",
      "FPR at threshold: 0.05055611729019211\n",
      "\n",
      "Detector roberta_large_phi on dataset mistral\n",
      "Threshold for target FPR 0.05: 0.003424449823796749\n",
      "TPR at threshold: 0.8630831643002028\n",
      "FPR at threshold: 0.05476673427991886\n",
      "\n",
      "Detector roberta_large_phi on dataset round_robin\n",
      "Threshold for target FPR 0.05: -0.3990408778190613\n",
      "TPR at threshold: 0.9386666666666666\n",
      "FPR at threshold: 0.050666666666666665\n",
      "\n",
      "Detector roberta_large_phi on dataset gemma_chat\n",
      "Threshold for target FPR 0.05: 0.025044936686754227\n",
      "TPR at threshold: 0.9598393574297188\n",
      "FPR at threshold: 0.05120481927710843\n",
      "\n",
      "Detector roberta_large_phi on dataset zephyr\n",
      "Threshold for target FPR 0.05: -0.055254511535167694\n",
      "TPR at threshold: 0.9231638418079096\n",
      "FPR at threshold: 0.05090497737556561\n",
      "\n",
      "Detector roberta_large_phi on dataset llama3\n",
      "Threshold for target FPR 0.05: 0.02113502286374569\n",
      "TPR at threshold: 0.9658634538152611\n",
      "FPR at threshold: 0.05321285140562249\n",
      "\n",
      "Detector distil_roberta-base_round_robin on dataset phi\n",
      "Threshold for target FPR 0.05: 0.40544983744621277\n",
      "TPR at threshold: 0.9528112449799196\n",
      "FPR at threshold: 0.05421686746987952\n",
      "\n",
      "Detector distil_roberta-base_round_robin on dataset gemma\n",
      "Threshold for target FPR 0.05: 0.43468260765075684\n",
      "TPR at threshold: 0.9049544994944388\n",
      "FPR at threshold: 0.05055611729019211\n",
      "\n",
      "Detector distil_roberta-base_round_robin on dataset mistral\n",
      "Threshold for target FPR 0.05: 0.444585919380188\n",
      "TPR at threshold: 0.8975659229208925\n",
      "FPR at threshold: 0.05070993914807302\n",
      "\n",
      "Detector distil_roberta-base_round_robin on dataset round_robin\n",
      "Threshold for target FPR 0.05: 0.1273074895143509\n",
      "TPR at threshold: 0.9386666666666666\n",
      "FPR at threshold: 0.050666666666666665\n",
      "\n",
      "Detector distil_roberta-base_round_robin on dataset gemma_chat\n",
      "Threshold for target FPR 0.05: 0.444585919380188\n",
      "TPR at threshold: 0.8845381526104418\n",
      "FPR at threshold: 0.050200803212851405\n",
      "\n",
      "Detector distil_roberta-base_round_robin on dataset zephyr\n",
      "Threshold for target FPR 0.05: 0.13705286383628845\n",
      "TPR at threshold: 0.831638418079096\n",
      "FPR at threshold: 0.05203619909502263\n",
      "\n",
      "Detector distil_roberta-base_round_robin on dataset llama3\n",
      "Threshold for target FPR 0.05: 0.444585919380188\n",
      "TPR at threshold: 0.9267068273092369\n",
      "FPR at threshold: 0.050200803212851405\n",
      "\n",
      "Detector electra_large_round_robin on dataset phi\n",
      "Threshold for target FPR 0.05: 0.4765685498714447\n",
      "TPR at threshold: 0.9688755020080321\n",
      "FPR at threshold: 0.050200803212851405\n",
      "\n",
      "Detector electra_large_round_robin on dataset gemma\n",
      "Threshold for target FPR 0.05: 0.39848220348358154\n",
      "TPR at threshold: 0.9605662285136501\n",
      "FPR at threshold: 0.0525783619817998\n",
      "\n",
      "Detector electra_large_round_robin on dataset mistral\n",
      "Threshold for target FPR 0.05: 0.4068852365016937\n",
      "TPR at threshold: 0.9249492900608519\n",
      "FPR at threshold: 0.05273833671399594\n",
      "\n",
      "Detector electra_large_round_robin on dataset round_robin\n",
      "Threshold for target FPR 0.05: 0.10936053097248077\n",
      "TPR at threshold: 0.9573333333333334\n",
      "FPR at threshold: 0.050666666666666665\n",
      "\n",
      "Detector electra_large_round_robin on dataset gemma_chat\n",
      "Threshold for target FPR 0.05: 0.4068852365016937\n",
      "TPR at threshold: 0.9748995983935743\n",
      "FPR at threshold: 0.05220883534136546\n",
      "\n",
      "Detector electra_large_round_robin on dataset zephyr\n",
      "Threshold for target FPR 0.05: 0.17757119238376617\n",
      "TPR at threshold: 0.9446327683615819\n",
      "FPR at threshold: 0.05090497737556561\n",
      "\n",
      "Detector electra_large_round_robin on dataset llama3\n",
      "Threshold for target FPR 0.05: 0.290040522813797\n",
      "TPR at threshold: 0.9799196787148594\n",
      "FPR at threshold: 0.05622489959839357\n",
      "\n",
      "Detector roberta_large_round_robin on dataset phi\n",
      "Threshold for target FPR 0.05: 0.33022233843803406\n",
      "TPR at threshold: 0.9568273092369478\n",
      "FPR at threshold: 0.05421686746987952\n",
      "\n",
      "Detector roberta_large_round_robin on dataset gemma\n",
      "Threshold for target FPR 0.05: 0.33603039383888245\n",
      "TPR at threshold: 0.9413549039433772\n",
      "FPR at threshold: 0.05156723963599596\n",
      "\n",
      "Detector roberta_large_round_robin on dataset mistral\n",
      "Threshold for target FPR 0.05: 0.3412937819957733\n",
      "TPR at threshold: 0.8894523326572008\n",
      "FPR at threshold: 0.05070993914807302\n",
      "\n",
      "Detector roberta_large_round_robin on dataset round_robin\n",
      "Threshold for target FPR 0.05: 0.004385998472571373\n",
      "TPR at threshold: 0.9546666666666667\n",
      "FPR at threshold: 0.05333333333333334\n",
      "\n",
      "Detector roberta_large_round_robin on dataset gemma_chat\n",
      "Threshold for target FPR 0.05: 0.3412937819957733\n",
      "TPR at threshold: 0.9447791164658634\n",
      "FPR at threshold: 0.050200803212851405\n",
      "\n",
      "Detector roberta_large_round_robin on dataset zephyr\n",
      "Threshold for target FPR 0.05: 0.17443764209747314\n",
      "TPR at threshold: 0.943502824858757\n",
      "FPR at threshold: 0.05090497737556561\n",
      "\n",
      "Detector roberta_large_round_robin on dataset llama3\n",
      "Threshold for target FPR 0.05: 0.30781668424606323\n",
      "TPR at threshold: 0.963855421686747\n",
      "FPR at threshold: 0.05622489959839357\n",
      "\n",
      "Detector fast_detect_gpt on dataset phi\n",
      "Threshold for target FPR 0.05: 0.63\n",
      "TPR at threshold: 0.9608433734939759\n",
      "FPR at threshold: 0.05120481927710843\n",
      "\n",
      "Detector fast_detect_gpt on dataset gemma\n",
      "Threshold for target FPR 0.05: 0.63\n",
      "TPR at threshold: 0.9544994944388271\n",
      "FPR at threshold: 0.05156723963599596\n",
      "\n",
      "Detector fast_detect_gpt on dataset mistral\n",
      "Threshold for target FPR 0.05: 0.63\n",
      "TPR at threshold: 0.8924949290060852\n",
      "FPR at threshold: 0.05172413793103448\n",
      "\n",
      "Detector fast_detect_gpt on dataset round_robin\n",
      "Threshold for target FPR 0.05: 0.53\n",
      "TPR at threshold: 0.968\n",
      "FPR at threshold: 0.06933333333333333\n",
      "\n",
      "Detector fast_detect_gpt on dataset gemma_chat\n",
      "Threshold for target FPR 0.05: 0.63\n",
      "TPR at threshold: 0.9267068273092369\n",
      "FPR at threshold: 0.05120481927710843\n",
      "\n",
      "Detector fast_detect_gpt on dataset zephyr\n",
      "Threshold for target FPR 0.05: 0.63\n",
      "TPR at threshold: 0.8282485875706215\n",
      "FPR at threshold: 0.05090497737556561\n",
      "\n",
      "Detector fast_detect_gpt on dataset llama3\n",
      "Threshold for target FPR 0.05: 0.63\n",
      "TPR at threshold: 0.9668674698795181\n",
      "FPR at threshold: 0.05120481927710843\n",
      "\n",
      "Detector roberta_base_open_ai on dataset phi\n",
      "Threshold for target FPR 0.05: 0.9726407527923584\n",
      "TPR at threshold: 0.7028112449799196\n",
      "FPR at threshold: 0.050200803212851405\n",
      "\n",
      "Detector roberta_base_open_ai on dataset gemma\n",
      "Threshold for target FPR 0.05: 0.9726407527923584\n",
      "TPR at threshold: 0.6713852376137512\n",
      "FPR at threshold: 0.05055611729019211\n",
      "\n",
      "Detector roberta_base_open_ai on dataset mistral\n",
      "Threshold for target FPR 0.05: 0.9726407527923584\n",
      "TPR at threshold: 0.5020283975659229\n",
      "FPR at threshold: 0.05070993914807302\n",
      "\n",
      "Detector roberta_base_open_ai on dataset round_robin\n",
      "Threshold for target FPR 0.05: 0.9726407527923584\n",
      "TPR at threshold: 0.6613333333333333\n",
      "FPR at threshold: 0.056\n",
      "\n",
      "Detector roberta_base_open_ai on dataset gemma_chat\n",
      "Threshold for target FPR 0.05: 0.9307770729064941\n",
      "TPR at threshold: 0.5903614457831325\n",
      "FPR at threshold: 0.05220883534136546\n",
      "\n",
      "Detector roberta_base_open_ai on dataset zephyr\n",
      "Threshold for target FPR 0.05: 1.009648323059082\n",
      "TPR at threshold: 0.2858757062146893\n",
      "FPR at threshold: 0.05090497737556561\n",
      "\n",
      "Detector roberta_base_open_ai on dataset llama3\n",
      "Threshold for target FPR 0.05: 0.9726407527923584\n",
      "TPR at threshold: 0.5040160642570282\n",
      "FPR at threshold: 0.050200803212851405\n",
      "\n",
      "Detector gpt_zero on dataset phi\n",
      "Threshold for target FPR 0.05: 0.052343355792348105\n",
      "TPR at threshold: 0.5020080321285141\n",
      "FPR at threshold: 0.050200803212851405\n",
      "\n",
      "Detector gpt_zero on dataset gemma\n",
      "Threshold for target FPR 0.05: 0.052343355792348105\n",
      "TPR at threshold: 0.4196157735085945\n",
      "FPR at threshold: 0.05055611729019211\n",
      "\n",
      "Detector gpt_zero on dataset mistral\n",
      "Threshold for target FPR 0.05: 0.052343355792348105\n",
      "TPR at threshold: 0.36004056795131845\n",
      "FPR at threshold: 0.05070993914807302\n",
      "\n",
      "Detector gpt_zero on dataset round_robin\n",
      "Threshold for target FPR 0.05: 0.052343355792348105\n",
      "TPR at threshold: 0.432\n",
      "FPR at threshold: 0.050666666666666665\n",
      "\n",
      "Detector gpt_zero on dataset gemma_chat\n",
      "Threshold for target FPR 0.05: 0.052343355792348105\n",
      "TPR at threshold: 0.9789156626506024\n",
      "FPR at threshold: 0.050200803212851405\n",
      "\n",
      "Detector gpt_zero on dataset zephyr\n",
      "Threshold for target FPR 0.05: 0.034219332135828756\n",
      "TPR at threshold: 0.8813559322033898\n",
      "FPR at threshold: 0.05203619909502263\n",
      "\n",
      "Detector gpt_zero on dataset llama3\n",
      "Threshold for target FPR 0.05: 0.052343355792348105\n",
      "TPR at threshold: 0.9528112449799196\n",
      "FPR at threshold: 0.050200803212851405\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_threshold_for_detector_dataset(detector: str, dataset: str, target_fpr: float):\n",
    "    \n",
    "    # select the df row according to the detector and dataset\n",
    "    df_row = test_results_df[(test_results_df[\"detector\"] == detector) & (test_results_df[\"dataset\"] == dataset)]\n",
    "    \n",
    "    # check that only one row is selected\n",
    "    if len(df_row) != 1:\n",
    "        print(\"detector: \", detector)\n",
    "        print(\"dataset: \", dataset)\n",
    "        print(\"df_row: \", df_row)   \n",
    "    assert len(df_row) == 1, f\"Expected 1 row, got {len(df_row)}\"\n",
    "    \n",
    "    # get the fpr, tpr and thresholds\n",
    "    fpr_at_thresholds = df_row[\"fpr_at_thresholds\"].values[0]\n",
    "    tpr_at_thresholds = df_row[\"tpr_at_thresholds\"].values[0]\n",
    "    thresholds = df_row[\"thresholds\"].values[0]\n",
    "\n",
    "    # Find the threshold that gives the target FPR\n",
    "    threshold = None\n",
    "    for i, fpr in enumerate(fpr_at_thresholds):\n",
    "        if fpr > target_fpr:\n",
    "            threshold = thresholds[i]\n",
    "            break\n",
    "        \n",
    "    print(f\"Detector {detector} on dataset {dataset}\")\n",
    "    print(f\"Threshold for target FPR {target_fpr}: {threshold}\")\n",
    "    print(f\"TPR at threshold: {tpr_at_thresholds[i]}\")\n",
    "    print(f\"FPR at threshold: {fpr_at_thresholds[i]}\")\n",
    "    print(\"\")\n",
    "    \n",
    "detectors = test_results_df[\"detector\"].unique()\n",
    "datasets = dataset_names\n",
    "\n",
    "target_fpr = 0.05\n",
    "for detector in detectors:\n",
    "    for dataset in datasets:\n",
    "        get_threshold_for_detector_dataset(detector, dataset, target_fpr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[inf,\n",
       " 3.0768046379089355,\n",
       " 2.530024290084839,\n",
       " 2.5292561054229736,\n",
       " 1.7555649280548096,\n",
       " 1.752966046333313,\n",
       " 1.7389878034591675,\n",
       " 1.7351834774017334,\n",
       " 1.5161769390106201,\n",
       " 1.5100491046905518,\n",
       " 1.4612256288528442,\n",
       " 1.4480808973312378,\n",
       " 1.2744879722595215,\n",
       " 1.2726222276687622,\n",
       " 1.1154356002807617,\n",
       " 1.1150074005126953,\n",
       " 1.105417251586914,\n",
       " 1.1022086143493652,\n",
       " 1.066392183303833,\n",
       " 1.0580425262451172,\n",
       " 1.0546480417251587,\n",
       " 1.0392392873764038,\n",
       " 1.0004500150680542,\n",
       " 0.993895411491394,\n",
       " 0.905342161655426,\n",
       " 0.9048994779586792,\n",
       " 0.7553116083145142,\n",
       " 0.7529943585395813,\n",
       " 0.7183533310890198,\n",
       " 0.6738065481185913,\n",
       " 0.6158868074417114,\n",
       " 0.5543252229690552,\n",
       " 0.5044019818305969,\n",
       " 0.4548230469226837,\n",
       " 0.4541120231151581,\n",
       " 0.45098620653152466,\n",
       " 0.4410609006881714,\n",
       " 0.39285287261009216,\n",
       " 0.3895924985408783,\n",
       " 0.3880177438259125,\n",
       " 0.3531041145324707,\n",
       " 0.3448437750339508,\n",
       " 0.31883129477500916,\n",
       " 0.2963715195655823,\n",
       " 0.2868483364582062,\n",
       " 0.28482961654663086,\n",
       " 0.11343418061733246,\n",
       " 0.08156020939350128,\n",
       " 0.06894450634717941,\n",
       " 0.063743457198143,\n",
       " 0.056078098714351654,\n",
       " 0.05032064765691757,\n",
       " -0.04045041650533676,\n",
       " -0.055393245071172714,\n",
       " -0.12232368439435959,\n",
       " -0.1393512785434723,\n",
       " -0.21792663633823395,\n",
       " -0.28785908222198486,\n",
       " -0.30230259895324707,\n",
       " -0.334980309009552,\n",
       " -0.34654220938682556,\n",
       " -0.3656226396560669,\n",
       " -0.39783743023872375,\n",
       " -0.41163548827171326,\n",
       " -0.4410659670829773,\n",
       " -0.44769975543022156,\n",
       " -0.5753551721572876,\n",
       " -0.5850827097892761,\n",
       " -0.6285287737846375,\n",
       " -0.6413555145263672,\n",
       " -0.6659525632858276,\n",
       " -0.724066972732544,\n",
       " -0.729895830154419,\n",
       " -0.824591875076294,\n",
       " -0.8605437278747559,\n",
       " -0.9149242639541626,\n",
       " -0.9158336520195007,\n",
       " -0.9225311279296875,\n",
       " -0.9307282567024231,\n",
       " -0.9388952255249023,\n",
       " -0.9424723982810974,\n",
       " -1.138932228088379,\n",
       " -1.1632192134857178,\n",
       " -1.226737380027771,\n",
       " -1.2329704761505127,\n",
       " -1.3132351636886597,\n",
       " -1.3180736303329468,\n",
       " -1.42965567111969,\n",
       " -1.4411330223083496,\n",
       " -1.4929217100143433,\n",
       " -1.4960721731185913,\n",
       " -1.5143886804580688,\n",
       " -1.5194449424743652,\n",
       " -1.5447916984558105,\n",
       " -1.5535722970962524,\n",
       " -1.5964759588241577,\n",
       " -1.599004864692688,\n",
       " -1.7098981142044067,\n",
       " -1.711816668510437,\n",
       " -1.8087117671966553,\n",
       " -1.8121600151062012,\n",
       " -1.8403677940368652,\n",
       " -1.8413276672363281,\n",
       " -1.9600751399993896,\n",
       " -1.967524766921997,\n",
       " -1.9900609254837036,\n",
       " -2.001232624053955,\n",
       " -2.1631999015808105,\n",
       " -2.163740634918213,\n",
       " -2.2614691257476807,\n",
       " -2.261721134185791,\n",
       " -2.9194753170013428]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_res_df = test_results_df[(test_results_df[\"detector\"] == \"electra_large_gemma\") & (test_results_df[\"dataset\"] == \"gemma_chat\")]\n",
    "check_res_df[\"thresholds\"].values[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[inf,\n",
       " 3.0344460010528564,\n",
       " 2.5299570560455322,\n",
       " 2.5292561054229736,\n",
       " 1.7566367387771606,\n",
       " 1.752966046333313,\n",
       " 1.735711932182312,\n",
       " 1.7351834774017334,\n",
       " 1.5103684663772583,\n",
       " 1.5100491046905518,\n",
       " 1.4590774774551392,\n",
       " 1.4480808973312378,\n",
       " 1.2749454975128174,\n",
       " 1.2726222276687622,\n",
       " 1.1154704093933105,\n",
       " 1.1150074005126953,\n",
       " 1.102232575416565,\n",
       " 1.1022086143493652,\n",
       " 1.0585041046142578,\n",
       " 1.0580425262451172,\n",
       " 1.0457066297531128,\n",
       " 1.0392392873764038,\n",
       " 1.0051417350769043,\n",
       " 0.993895411491394,\n",
       " 0.920891523361206,\n",
       " 0.9048994779586792,\n",
       " 0.7539025545120239,\n",
       " 0.7529943585395813,\n",
       " 0.7011353969573975,\n",
       " 0.6738065481185913,\n",
       " 0.6464124321937561,\n",
       " 0.6147263050079346,\n",
       " 0.5626006126403809,\n",
       " 0.5543252229690552,\n",
       " 0.5146321654319763,\n",
       " 0.4880949854850769,\n",
       " 0.48800989985466003,\n",
       " 0.48737195134162903,\n",
       " 0.4714670777320862,\n",
       " 0.4548230469226837,\n",
       " 0.4546253979206085,\n",
       " 0.45098620653152466,\n",
       " 0.4387664496898651,\n",
       " 0.3880177438259125,\n",
       " 0.35727572441101074,\n",
       " 0.3448437750339508,\n",
       " 0.3201179504394531,\n",
       " 0.31882843375205994,\n",
       " 0.2969263792037964,\n",
       " 0.28482961654663086,\n",
       " 0.13824151456356049,\n",
       " 0.05032064765691757,\n",
       " -0.027912817895412445,\n",
       " -0.055393245071172714,\n",
       " -0.1380671262741089,\n",
       " -0.1393512785434723,\n",
       " -0.2108224481344223,\n",
       " -0.28785908222198486,\n",
       " -0.32034480571746826,\n",
       " -0.3656226396560669,\n",
       " -0.38314059376716614,\n",
       " -0.44769975543022156,\n",
       " -0.5744167566299438,\n",
       " -0.5809829831123352,\n",
       " -0.5837920904159546,\n",
       " -0.5850827097892761,\n",
       " -0.6092320084571838,\n",
       " -0.7425442337989807,\n",
       " -0.7455503344535828,\n",
       " -0.824591875076294,\n",
       " -0.8553341031074524,\n",
       " -0.9159520268440247,\n",
       " -0.9171488285064697,\n",
       " -0.9476456642150879,\n",
       " -0.9755009412765503,\n",
       " -1.0049967765808105,\n",
       " -1.0404781103134155,\n",
       " -1.0563499927520752,\n",
       " -1.066324234008789,\n",
       " -1.1176451444625854,\n",
       " -1.1226797103881836,\n",
       " -1.1877987384796143,\n",
       " -1.205714225769043,\n",
       " -1.3132351636886597,\n",
       " -1.313306450843811,\n",
       " -1.4539552927017212,\n",
       " -1.4731853008270264,\n",
       " -1.5769611597061157,\n",
       " -1.5852526426315308,\n",
       " -1.702354907989502,\n",
       " -1.70439612865448,\n",
       " -1.9900609254837036,\n",
       " -1.9919800758361816,\n",
       " -2.06372332572937,\n",
       " -2.0661323070526123,\n",
       " -2.392561674118042,\n",
       " -2.398245334625244,\n",
       " -2.9194753170013428]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_res_df = test_results_df[(test_results_df[\"detector\"] == \"electra_large_gemma\") & (test_results_df[\"dataset\"] == \"llama3\")]\n",
    "check_res_df[\"thresholds\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[inf,\n",
       " 1.0000000000000002,\n",
       " 1.0,\n",
       " 0.9999999999999999,\n",
       " 0.9852764423076923,\n",
       " 0.9851482782342966,\n",
       " 0.9851429936503517,\n",
       " 0.9851100744681245,\n",
       " 0.984912945133188,\n",
       " 0.9848901401360504,\n",
       " 0.9848689550765525,\n",
       " 0.9848663395786856,\n",
       " 0.9848608524127328,\n",
       " 0.984826669620113,\n",
       " 0.9198382923165256,\n",
       " 0.9177576492878393,\n",
       " 0.9177298624187972,\n",
       " 0.9175655440217254,\n",
       " 0.9174229619679705,\n",
       " 0.9169836524912234,\n",
       " 0.9162038722742147,\n",
       " 0.9160494284491684,\n",
       " 0.9154948262138498,\n",
       " 0.9139067029781253,\n",
       " 0.913232015706006,\n",
       " 0.9131167105495104,\n",
       " 0.9131024761957133,\n",
       " 0.9130726141646427,\n",
       " 0.847720614359518,\n",
       " 0.8454417280732089,\n",
       " 0.8395728659035674,\n",
       " 0.8366408178643527,\n",
       " 0.8341456810181425,\n",
       " 0.8327577344134484,\n",
       " 0.8326803264288972,\n",
       " 0.8261553649657554,\n",
       " 0.8259360816388842,\n",
       " 0.8259090132916168,\n",
       " 0.8258791425270435,\n",
       " 0.8258522284880236,\n",
       " 0.8236104299919657,\n",
       " 0.7930890425265984,\n",
       " 0.780953671091845,\n",
       " 0.7781884184744576,\n",
       " 0.7779202050953373,\n",
       " 0.7778870987578405,\n",
       " 0.77608959686084,\n",
       " 0.7760559424400817,\n",
       " 0.7453537081833737,\n",
       " 0.7409252669039145,\n",
       " 0.7261006804952037,\n",
       " 0.725788395904437,\n",
       " 0.7257498527189367,\n",
       " 0.5952151627647506,\n",
       " 0.5811630224269791,\n",
       " 0.5206733474247655,\n",
       " 0.5195914011282208,\n",
       " 0.47863807497135374,\n",
       " 0.47744052502050865,\n",
       " 0.4760914229962237,\n",
       " 0.4733984274297499,\n",
       " 0.47294506402313097,\n",
       " 0.47288912596051746,\n",
       " 0.46783625730994155,\n",
       " 0.4537372406980573,\n",
       " 0.44705556743700386,\n",
       " 0.44657085073537334,\n",
       " 0.44651104310594514,\n",
       " 0.43629041566736354,\n",
       " 0.43578663296155234,\n",
       " 0.4357244716476263,\n",
       " 0.4339527875439478,\n",
       " 0.25553397311383347,\n",
       " 0.2361583568906867,\n",
       " 0.2356381581201951,\n",
       " 0.23557398656251002,\n",
       " 0.21047776267236357,\n",
       " 0.20861270625907327,\n",
       " 0.20303232853486364,\n",
       " 0.19720980788151202,\n",
       " 0.18609794628751974,\n",
       " 0.1811802944250958,\n",
       " 0.18075254142074695,\n",
       " 0.18069978334023556,\n",
       " 0.17905827243123879,\n",
       " 0.1754860217259636,\n",
       " 0.1750688381113084,\n",
       " 0.17501738458421054,\n",
       " 0.13940544076911293,\n",
       " 0.11336730098147929,\n",
       " 0.10687847137291297,\n",
       " 0.10650474043013303,\n",
       " 0.10645865068710163,\n",
       " 0.10170659845326978,\n",
       " 0.09051811946852577,\n",
       " 0.08441514240664282,\n",
       " 0.07693387125065779,\n",
       " 0.07608635884208369,\n",
       " 0.07570283128722095,\n",
       " 0.0756555335709337,\n",
       " 0.06159769008662176,\n",
       " 0.059536204448651195,\n",
       " 0.056572140256754166,\n",
       " 0.0546795846686843,\n",
       " 0.0543361685408769,\n",
       " 0.05429381994543362,\n",
       " 0.05420501023301986,\n",
       " 0.05271603470818971,\n",
       " 0.05238426731639402,\n",
       " 0.052343355792348105,\n",
       " 0.052257560205867,\n",
       " 0.04552256688114359,\n",
       " 0.043473802316309255,\n",
       " 0.03678397293442569,\n",
       " 0.03674434522883545,\n",
       " 0.0367362600466412,\n",
       " 0.03666124246195081,\n",
       " 0.0346373404107866,\n",
       " 0.034219332135828756,\n",
       " 0.034209945969787194,\n",
       " 0.0335730950095511,\n",
       " 0.03144499632358719,\n",
       " 0.03141405690799554,\n",
       " 0.03137451528149038,\n",
       " 0.031299915414401615,\n",
       " 0.031291593111378344,\n",
       " 0.03121698047054782,\n",
       " 0.031126391416296376,\n",
       " 0.03108710394816048,\n",
       " 0.031078549287025598,\n",
       " 0.03100471483989595,\n",
       " 0.030996182125595476,\n",
       " 0.02442344093237024,\n",
       " 0.02348635187329445,\n",
       " 0.023405100612036992,\n",
       " 0.022983631842904556,\n",
       " 0.0229448438739147,\n",
       " 0.022899958772937705,\n",
       " 0.022863502471081244,\n",
       " 0.02235780005035932,\n",
       " 0.02167103142780387,\n",
       " 0.021285591596749684,\n",
       " 0.020787478601124967,\n",
       " 0.020400676754739656,\n",
       " 0.019901662374151252,\n",
       " 0.015424593234908029,\n",
       " 0.014795796253182182,\n",
       " 0.014399785535109047,\n",
       " 0.014320726414547739,\n",
       " 0.013829223798034484,\n",
       " 0.013748425779537145,\n",
       " 0.013679161545009555,\n",
       " 0.0131870187361661,\n",
       " 0.013035680166659475,\n",
       " 0.012956402044646776,\n",
       " 0.012463537523203394,\n",
       " 0.01213976823800198,\n",
       " 0.011468512379793202,\n",
       " 0.011430584437264545,\n",
       " 0.011388982281569747,\n",
       " 0.01135131433575238,\n",
       " 0.011321657676948586,\n",
       " 0.010894550792945584,\n",
       " 0.010886210187967895,\n",
       " 0.010858500169664064,\n",
       " 0.010830116942220172,\n",
       " 0.009697360427754797,\n",
       " 0.009671982646287994,\n",
       " 0.009592640486663577,\n",
       " 0.00958620055809271,\n",
       " 0.009585354789756043,\n",
       " 0.009099378590470468,\n",
       " 0.009093266768243265,\n",
       " 0.00909301591639827,\n",
       " 0.009092464091054084,\n",
       " 0.009030837884374913,\n",
       " 0.007088203038174683,\n",
       " 0.0065928231147033235,\n",
       " 0.006548026829384868,\n",
       " 0.0037270498564262243,\n",
       " 0.0032729116171750536,\n",
       " 0.0032505993366025547,\n",
       " 0.003188135494846194,\n",
       " 0.002754797855815489,\n",
       " 0.002701835559533258,\n",
       " 0.002636324620446469,\n",
       " 0.0025856341227665953,\n",
       " 0.0025800839872510226,\n",
       " 0.0025690548917801843,\n",
       " 0.0025211562393874652,\n",
       " 0.002098745999265439,\n",
       " 0.0020942387882382073,\n",
       " 0.002085282195198005,\n",
       " 0.001982356474414522,\n",
       " 0.0018657848709747456,\n",
       " 0.001853812774905952,\n",
       " 0.0018192251062673814]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_res_phi = test_results_df[(test_results_df[\"detector\"] == \"gpt_zero\") & (test_results_df[\"dataset\"] == \"llama3\")]\n",
    "thresholds_phi = check_res_phi[\"thresholds\"].values[0]\n",
    "thresholds_phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds_phi.index(0.052343355792348105)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[inf,\n",
       " 1.0000000000000002,\n",
       " 1.0,\n",
       " 0.9999999999999999,\n",
       " 0.9852764423076923,\n",
       " 0.9851482782342966,\n",
       " 0.9851429936503517,\n",
       " 0.9851100744681245,\n",
       " 0.984912945133188,\n",
       " 0.9848901401360504,\n",
       " 0.9848689550765525,\n",
       " 0.9848663395786856,\n",
       " 0.9848608524127328,\n",
       " 0.984826669620113,\n",
       " 0.9198382923165256,\n",
       " 0.9177576492878393,\n",
       " 0.9177298624187972,\n",
       " 0.9175655440217254,\n",
       " 0.9174229619679705,\n",
       " 0.9169836524912234,\n",
       " 0.9162038722742147,\n",
       " 0.9160494284491684,\n",
       " 0.9154948262138498,\n",
       " 0.9139067029781253,\n",
       " 0.913232015706006,\n",
       " 0.9131167105495104,\n",
       " 0.9131024761957133,\n",
       " 0.9130726141646427,\n",
       " 0.847720614359518,\n",
       " 0.8454417280732089,\n",
       " 0.8395728659035674,\n",
       " 0.8366408178643527,\n",
       " 0.8341456810181425,\n",
       " 0.8327577344134484,\n",
       " 0.8326803264288972,\n",
       " 0.8261553649657554,\n",
       " 0.8259360816388842,\n",
       " 0.8259090132916168,\n",
       " 0.8258791425270435,\n",
       " 0.8258522284880236,\n",
       " 0.8236104299919657,\n",
       " 0.7930890425265984,\n",
       " 0.780953671091845,\n",
       " 0.7781884184744576,\n",
       " 0.7779202050953373,\n",
       " 0.7778870987578405,\n",
       " 0.77608959686084,\n",
       " 0.7760559424400817,\n",
       " 0.7453537081833737,\n",
       " 0.7409252669039145,\n",
       " 0.7261006804952037,\n",
       " 0.725788395904437,\n",
       " 0.7257498527189367,\n",
       " 0.5952151627647506,\n",
       " 0.5811630224269791,\n",
       " 0.5206733474247655,\n",
       " 0.5195914011282208,\n",
       " 0.47863807497135374,\n",
       " 0.47744052502050865,\n",
       " 0.4760914229962237,\n",
       " 0.4733984274297499,\n",
       " 0.47294506402313097,\n",
       " 0.47288912596051746,\n",
       " 0.46783625730994155,\n",
       " 0.4537372406980573,\n",
       " 0.44705556743700386,\n",
       " 0.44657085073537334,\n",
       " 0.44651104310594514,\n",
       " 0.43629041566736354,\n",
       " 0.43578663296155234,\n",
       " 0.4357244716476263,\n",
       " 0.4339527875439478,\n",
       " 0.25553397311383347,\n",
       " 0.2361583568906867,\n",
       " 0.2356381581201951,\n",
       " 0.23557398656251002,\n",
       " 0.21047776267236357,\n",
       " 0.20861270625907327,\n",
       " 0.20303232853486364,\n",
       " 0.19720980788151202,\n",
       " 0.18609794628751974,\n",
       " 0.1811802944250958,\n",
       " 0.18075254142074695,\n",
       " 0.18069978334023556,\n",
       " 0.17905827243123879,\n",
       " 0.1754860217259636,\n",
       " 0.1750688381113084,\n",
       " 0.17501738458421054,\n",
       " 0.13940544076911293,\n",
       " 0.11336730098147929,\n",
       " 0.10687847137291297,\n",
       " 0.10650474043013303,\n",
       " 0.10645865068710163,\n",
       " 0.10170659845326978,\n",
       " 0.09051811946852577,\n",
       " 0.08441514240664282,\n",
       " 0.07693387125065779,\n",
       " 0.07608635884208369,\n",
       " 0.07570283128722095,\n",
       " 0.0756555335709337,\n",
       " 0.06159769008662176,\n",
       " 0.059536204448651195,\n",
       " 0.056572140256754166,\n",
       " 0.0546795846686843,\n",
       " 0.0543361685408769,\n",
       " 0.05429381994543362,\n",
       " 0.05420501023301986,\n",
       " 0.05271603470818971,\n",
       " 0.05238426731639402,\n",
       " 0.052343355792348105,\n",
       " 0.052257560205867,\n",
       " 0.04552256688114359,\n",
       " 0.043473802316309255,\n",
       " 0.03678397293442569,\n",
       " 0.03674434522883545,\n",
       " 0.0367362600466412,\n",
       " 0.03666124246195081,\n",
       " 0.0346373404107866,\n",
       " 0.034219332135828756,\n",
       " 0.034209945969787194,\n",
       " 0.0335730950095511,\n",
       " 0.03144499632358719,\n",
       " 0.03141405690799554,\n",
       " 0.03137451528149038,\n",
       " 0.031299915414401615,\n",
       " 0.031291593111378344,\n",
       " 0.03121698047054782,\n",
       " 0.031126391416296376,\n",
       " 0.03108710394816048,\n",
       " 0.031078549287025598,\n",
       " 0.03100471483989595,\n",
       " 0.030996182125595476,\n",
       " 0.02442344093237024,\n",
       " 0.02348635187329445,\n",
       " 0.023405100612036992,\n",
       " 0.022983631842904556,\n",
       " 0.0229448438739147,\n",
       " 0.022899958772937705,\n",
       " 0.022863502471081244,\n",
       " 0.02235780005035932,\n",
       " 0.02167103142780387,\n",
       " 0.021285591596749684,\n",
       " 0.020787478601124967,\n",
       " 0.020400676754739656,\n",
       " 0.019901662374151252,\n",
       " 0.015424593234908029,\n",
       " 0.014795796253182182,\n",
       " 0.014399785535109047,\n",
       " 0.014320726414547739,\n",
       " 0.013829223798034484,\n",
       " 0.013748425779537145,\n",
       " 0.013679161545009555,\n",
       " 0.0131870187361661,\n",
       " 0.013035680166659475,\n",
       " 0.012956402044646776,\n",
       " 0.012463537523203394,\n",
       " 0.01213976823800198,\n",
       " 0.011468512379793202,\n",
       " 0.011430584437264545,\n",
       " 0.011388982281569747,\n",
       " 0.01135131433575238,\n",
       " 0.011321657676948586,\n",
       " 0.010894550792945584,\n",
       " 0.010886210187967895,\n",
       " 0.010858500169664064,\n",
       " 0.010830116942220172,\n",
       " 0.009697360427754797,\n",
       " 0.009671982646287994,\n",
       " 0.009592640486663577,\n",
       " 0.00958620055809271,\n",
       " 0.009585354789756043,\n",
       " 0.009099378590470468,\n",
       " 0.009093266768243265,\n",
       " 0.00909301591639827,\n",
       " 0.009092464091054084,\n",
       " 0.009030837884374913,\n",
       " 0.007088203038174683,\n",
       " 0.0065928231147033235,\n",
       " 0.006548026829384868,\n",
       " 0.0037270498564262243,\n",
       " 0.0032729116171750536,\n",
       " 0.0032505993366025547,\n",
       " 0.003188135494846194,\n",
       " 0.002754797855815489,\n",
       " 0.002701835559533258,\n",
       " 0.002636324620446469,\n",
       " 0.0025856341227665953,\n",
       " 0.0025800839872510226,\n",
       " 0.0025690548917801843,\n",
       " 0.0025211562393874652,\n",
       " 0.002098745999265439,\n",
       " 0.0020942387882382073,\n",
       " 0.002085282195198005,\n",
       " 0.001982356474414522,\n",
       " 0.0018657848709747456,\n",
       " 0.001853812774905952,\n",
       " 0.0018192251062673814]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_res_rr = test_results_df[(test_results_df[\"detector\"] == \"gpt_zero\") & (test_results_df[\"dataset\"] == \"llama3\")]\n",
    "thresholds_rr = check_res_rr[\"thresholds\"].values[0]\n",
    "thresholds_rr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds_rr.index(0.052343355792348105)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_detector",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
