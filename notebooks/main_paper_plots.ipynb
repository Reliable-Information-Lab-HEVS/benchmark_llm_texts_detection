{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import jsonlines\n",
    "import altair as alt\n",
    "from vega_datasets import data\n",
    "\n",
    "\n",
    "\n",
    "os.chdir(\"../\")\n",
    "\n",
    "SRC_PATH = [\"src\"]\n",
    "for module_path in SRC_PATH:\n",
    "    if module_path not in sys.path:\n",
    "        sys.path.append(module_path)\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full finetuning results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = [\"phi\", \"gemma\", \"mistral\", \"gemma_chat\", \"zephyr\", \"llama3\", \"round_robin\"]\n",
    "training_method = \"full_finetuning\"\n",
    "trained_on_models = {\"distil_roberta-base\": {\"03_05_1735\": \"phi\", \"03_05_1741\": \"gemma\", \"03_05_1748\": \"mistral\", \"03_05_1754\": \"round_robin\"},\n",
    "                    \"roberta_large\": {\"03_05_1845\": \"phi\", \"03_05_1910\": \"gemma\", \"03_05_1935\": \"mistral\", \"03_05_2001\": \"round_robin\"},\n",
    "                    \"electra_large\": {\"03_05_1842\": \"phi\", \"03_05_1909\": \"gemma\", \"03_05_1935\": \"mistral\", \"03_05_2001\": \"round_robin\"}}\n",
    "\n",
    "\n",
    "freeze_base_df = create_df_from_test_logs(\"full_finetuning\", trained_on_models, dataset_names)\n",
    "#heatmap_from_df(freeze_base_df, \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>fp_rate</th>\n",
       "      <th>std_accuracy</th>\n",
       "      <th>std_precision</th>\n",
       "      <th>std_recall</th>\n",
       "      <th>std_f1_score</th>\n",
       "      <th>std_fp_rate</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>base_detector</th>\n",
       "      <th>trained_on_dataset</th>\n",
       "      <th>detector</th>\n",
       "      <th>detector_short_name</th>\n",
       "      <th>detector_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>phi</td>\n",
       "      <td>0.947539</td>\n",
       "      <td>0.921121</td>\n",
       "      <td>0.978991</td>\n",
       "      <td>0.949152</td>\n",
       "      <td>0.083968</td>\n",
       "      <td>0.004890</td>\n",
       "      <td>0.008095</td>\n",
       "      <td>0.004428</td>\n",
       "      <td>0.004867</td>\n",
       "      <td>0.008634</td>\n",
       "      <td>975.819</td>\n",
       "      <td>911.679</td>\n",
       "      <td>83.563</td>\n",
       "      <td>20.939</td>\n",
       "      <td>roberta_large</td>\n",
       "      <td>gemma</td>\n",
       "      <td>roberta_large_gemma</td>\n",
       "      <td>roberta</td>\n",
       "      <td>roberta_gemma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>phi</td>\n",
       "      <td>0.964984</td>\n",
       "      <td>0.957048</td>\n",
       "      <td>0.973710</td>\n",
       "      <td>0.965290</td>\n",
       "      <td>0.043752</td>\n",
       "      <td>0.004102</td>\n",
       "      <td>0.006376</td>\n",
       "      <td>0.005173</td>\n",
       "      <td>0.004190</td>\n",
       "      <td>0.006385</td>\n",
       "      <td>970.558</td>\n",
       "      <td>951.691</td>\n",
       "      <td>43.551</td>\n",
       "      <td>26.200</td>\n",
       "      <td>electra_large</td>\n",
       "      <td>gemma</td>\n",
       "      <td>electra_large_gemma</td>\n",
       "      <td>electra</td>\n",
       "      <td>electra_gemma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>phi</td>\n",
       "      <td>0.945348</td>\n",
       "      <td>0.942504</td>\n",
       "      <td>0.948649</td>\n",
       "      <td>0.945541</td>\n",
       "      <td>0.057955</td>\n",
       "      <td>0.005259</td>\n",
       "      <td>0.007493</td>\n",
       "      <td>0.007078</td>\n",
       "      <td>0.005370</td>\n",
       "      <td>0.007521</td>\n",
       "      <td>945.572</td>\n",
       "      <td>937.561</td>\n",
       "      <td>57.681</td>\n",
       "      <td>51.186</td>\n",
       "      <td>distil_roberta-base</td>\n",
       "      <td>gemma</td>\n",
       "      <td>distil_roberta-base_gemma</td>\n",
       "      <td>distil</td>\n",
       "      <td>distil_gemma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>phi</td>\n",
       "      <td>0.949168</td>\n",
       "      <td>0.928045</td>\n",
       "      <td>0.973925</td>\n",
       "      <td>0.950408</td>\n",
       "      <td>0.075626</td>\n",
       "      <td>0.004905</td>\n",
       "      <td>0.008146</td>\n",
       "      <td>0.004834</td>\n",
       "      <td>0.004921</td>\n",
       "      <td>0.008523</td>\n",
       "      <td>970.769</td>\n",
       "      <td>919.974</td>\n",
       "      <td>75.268</td>\n",
       "      <td>25.989</td>\n",
       "      <td>electra_large</td>\n",
       "      <td>mistral</td>\n",
       "      <td>electra_large_mistral</td>\n",
       "      <td>electra</td>\n",
       "      <td>electra_mistral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phi</td>\n",
       "      <td>0.955619</td>\n",
       "      <td>0.932033</td>\n",
       "      <td>0.982984</td>\n",
       "      <td>0.956811</td>\n",
       "      <td>0.071784</td>\n",
       "      <td>0.004458</td>\n",
       "      <td>0.007439</td>\n",
       "      <td>0.004227</td>\n",
       "      <td>0.004445</td>\n",
       "      <td>0.007775</td>\n",
       "      <td>979.794</td>\n",
       "      <td>923.799</td>\n",
       "      <td>71.443</td>\n",
       "      <td>16.964</td>\n",
       "      <td>roberta_large</td>\n",
       "      <td>mistral</td>\n",
       "      <td>roberta_large_mistral</td>\n",
       "      <td>roberta</td>\n",
       "      <td>roberta_mistral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset  accuracy  precision    recall  f1_score   fp_rate  std_accuracy  \\\n",
       "0     phi  0.947539   0.921121  0.978991  0.949152  0.083968      0.004890   \n",
       "1     phi  0.964984   0.957048  0.973710  0.965290  0.043752      0.004102   \n",
       "2     phi  0.945348   0.942504  0.948649  0.945541  0.057955      0.005259   \n",
       "3     phi  0.949168   0.928045  0.973925  0.950408  0.075626      0.004905   \n",
       "4     phi  0.955619   0.932033  0.982984  0.956811  0.071784      0.004458   \n",
       "\n",
       "   std_precision  std_recall  std_f1_score  std_fp_rate       TP       TN  \\\n",
       "0       0.008095    0.004428      0.004867     0.008634  975.819  911.679   \n",
       "1       0.006376    0.005173      0.004190     0.006385  970.558  951.691   \n",
       "2       0.007493    0.007078      0.005370     0.007521  945.572  937.561   \n",
       "3       0.008146    0.004834      0.004921     0.008523  970.769  919.974   \n",
       "4       0.007439    0.004227      0.004445     0.007775  979.794  923.799   \n",
       "\n",
       "       FP      FN        base_detector trained_on_dataset  \\\n",
       "0  83.563  20.939        roberta_large              gemma   \n",
       "1  43.551  26.200        electra_large              gemma   \n",
       "2  57.681  51.186  distil_roberta-base              gemma   \n",
       "3  75.268  25.989        electra_large            mistral   \n",
       "4  71.443  16.964        roberta_large            mistral   \n",
       "\n",
       "                    detector detector_short_name    detector_name  \n",
       "0        roberta_large_gemma             roberta    roberta_gemma  \n",
       "1        electra_large_gemma             electra    electra_gemma  \n",
       "2  distil_roberta-base_gemma              distil     distil_gemma  \n",
       "3      electra_large_mistral             electra  electra_mistral  \n",
       "4      roberta_large_mistral             roberta  roberta_mistral  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freeze_base_df = freeze_base_df.sort_values(by=\"trained_on_dataset\")\n",
    "dataset_order = [\"phi\", \"gemma\", \"mistral\", \"round_robin\", \"gemma_chat\", \"zephyr\", \"llama3\"]\n",
    "freeze_base_df = freeze_base_df.set_index(\"dataset\").loc[dataset_order].reset_index()\n",
    "detector_name_to_short_name = {\"distil_roberta-base\": \"distil\", \"roberta_large\": \"roberta\", \"electra_large\": \"electra\"}\n",
    "freeze_base_df[\"detector_short_name\"] = freeze_base_df[\"base_detector\"].apply(lambda x: detector_name_to_short_name[x])\n",
    "# set detector_name as f\"{detector_short_name}_{trained_on_dataset}\"\n",
    "freeze_base_df[\"detector_name\"] = freeze_base_df[\"detector_short_name\"] + \"_\" + freeze_base_df[\"trained_on_dataset\"]\n",
    "freeze_base_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>fp_rate</th>\n",
       "      <th>std_accuracy</th>\n",
       "      <th>std_precision</th>\n",
       "      <th>std_recall</th>\n",
       "      <th>std_f1_score</th>\n",
       "      <th>std_fp_rate</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>base_detector</th>\n",
       "      <th>trained_on_dataset</th>\n",
       "      <th>detector</th>\n",
       "      <th>detector_short_name</th>\n",
       "      <th>detector_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>phi</td>\n",
       "      <td>0.947539</td>\n",
       "      <td>0.921121</td>\n",
       "      <td>0.978991</td>\n",
       "      <td>0.949152</td>\n",
       "      <td>0.083968</td>\n",
       "      <td>0.004890</td>\n",
       "      <td>0.008095</td>\n",
       "      <td>0.004428</td>\n",
       "      <td>0.004867</td>\n",
       "      <td>0.008634</td>\n",
       "      <td>975.819</td>\n",
       "      <td>911.679</td>\n",
       "      <td>83.563</td>\n",
       "      <td>20.939</td>\n",
       "      <td>roberta_large</td>\n",
       "      <td>gemma</td>\n",
       "      <td>roberta_large_gemma</td>\n",
       "      <td>roberta</td>\n",
       "      <td>roberta_gemma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>phi</td>\n",
       "      <td>0.964984</td>\n",
       "      <td>0.957048</td>\n",
       "      <td>0.973710</td>\n",
       "      <td>0.965290</td>\n",
       "      <td>0.043752</td>\n",
       "      <td>0.004102</td>\n",
       "      <td>0.006376</td>\n",
       "      <td>0.005173</td>\n",
       "      <td>0.004190</td>\n",
       "      <td>0.006385</td>\n",
       "      <td>970.558</td>\n",
       "      <td>951.691</td>\n",
       "      <td>43.551</td>\n",
       "      <td>26.200</td>\n",
       "      <td>electra_large</td>\n",
       "      <td>gemma</td>\n",
       "      <td>electra_large_gemma</td>\n",
       "      <td>electra</td>\n",
       "      <td>electra_gemma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>phi</td>\n",
       "      <td>0.945348</td>\n",
       "      <td>0.942504</td>\n",
       "      <td>0.948649</td>\n",
       "      <td>0.945541</td>\n",
       "      <td>0.057955</td>\n",
       "      <td>0.005259</td>\n",
       "      <td>0.007493</td>\n",
       "      <td>0.007078</td>\n",
       "      <td>0.005370</td>\n",
       "      <td>0.007521</td>\n",
       "      <td>945.572</td>\n",
       "      <td>937.561</td>\n",
       "      <td>57.681</td>\n",
       "      <td>51.186</td>\n",
       "      <td>distil_roberta-base</td>\n",
       "      <td>gemma</td>\n",
       "      <td>distil_roberta-base_gemma</td>\n",
       "      <td>distil</td>\n",
       "      <td>distil_gemma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>phi</td>\n",
       "      <td>0.949168</td>\n",
       "      <td>0.928045</td>\n",
       "      <td>0.973925</td>\n",
       "      <td>0.950408</td>\n",
       "      <td>0.075626</td>\n",
       "      <td>0.004905</td>\n",
       "      <td>0.008146</td>\n",
       "      <td>0.004834</td>\n",
       "      <td>0.004921</td>\n",
       "      <td>0.008523</td>\n",
       "      <td>970.769</td>\n",
       "      <td>919.974</td>\n",
       "      <td>75.268</td>\n",
       "      <td>25.989</td>\n",
       "      <td>electra_large</td>\n",
       "      <td>mistral</td>\n",
       "      <td>electra_large_mistral</td>\n",
       "      <td>electra</td>\n",
       "      <td>electra_mistral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phi</td>\n",
       "      <td>0.955619</td>\n",
       "      <td>0.932033</td>\n",
       "      <td>0.982984</td>\n",
       "      <td>0.956811</td>\n",
       "      <td>0.071784</td>\n",
       "      <td>0.004458</td>\n",
       "      <td>0.007439</td>\n",
       "      <td>0.004227</td>\n",
       "      <td>0.004445</td>\n",
       "      <td>0.007775</td>\n",
       "      <td>979.794</td>\n",
       "      <td>923.799</td>\n",
       "      <td>71.443</td>\n",
       "      <td>16.964</td>\n",
       "      <td>roberta_large</td>\n",
       "      <td>mistral</td>\n",
       "      <td>roberta_large_mistral</td>\n",
       "      <td>roberta</td>\n",
       "      <td>roberta_mistral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>phi</td>\n",
       "      <td>0.957894</td>\n",
       "      <td>0.949887</td>\n",
       "      <td>0.966854</td>\n",
       "      <td>0.958275</td>\n",
       "      <td>0.051074</td>\n",
       "      <td>0.004367</td>\n",
       "      <td>0.006684</td>\n",
       "      <td>0.005739</td>\n",
       "      <td>0.004449</td>\n",
       "      <td>0.006730</td>\n",
       "      <td>963.719</td>\n",
       "      <td>944.406</td>\n",
       "      <td>50.836</td>\n",
       "      <td>33.039</td>\n",
       "      <td>distil_roberta-base</td>\n",
       "      <td>mistral</td>\n",
       "      <td>distil_roberta-base_mistral</td>\n",
       "      <td>distil</td>\n",
       "      <td>distil_mistral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>phi</td>\n",
       "      <td>0.966063</td>\n",
       "      <td>0.940545</td>\n",
       "      <td>0.995082</td>\n",
       "      <td>0.967030</td>\n",
       "      <td>0.063007</td>\n",
       "      <td>0.003887</td>\n",
       "      <td>0.007039</td>\n",
       "      <td>0.002170</td>\n",
       "      <td>0.003831</td>\n",
       "      <td>0.007519</td>\n",
       "      <td>991.857</td>\n",
       "      <td>932.541</td>\n",
       "      <td>62.701</td>\n",
       "      <td>4.901</td>\n",
       "      <td>roberta_large</td>\n",
       "      <td>phi</td>\n",
       "      <td>roberta_large_phi</td>\n",
       "      <td>roberta</td>\n",
       "      <td>roberta_phi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>phi</td>\n",
       "      <td>0.981562</td>\n",
       "      <td>0.969922</td>\n",
       "      <td>0.993972</td>\n",
       "      <td>0.981791</td>\n",
       "      <td>0.030866</td>\n",
       "      <td>0.002999</td>\n",
       "      <td>0.005423</td>\n",
       "      <td>0.002324</td>\n",
       "      <td>0.002999</td>\n",
       "      <td>0.005537</td>\n",
       "      <td>990.751</td>\n",
       "      <td>964.520</td>\n",
       "      <td>30.722</td>\n",
       "      <td>6.007</td>\n",
       "      <td>electra_large</td>\n",
       "      <td>phi</td>\n",
       "      <td>electra_large_phi</td>\n",
       "      <td>electra</td>\n",
       "      <td>electra_phi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>phi</td>\n",
       "      <td>0.967521</td>\n",
       "      <td>0.951754</td>\n",
       "      <td>0.985017</td>\n",
       "      <td>0.968085</td>\n",
       "      <td>0.050003</td>\n",
       "      <td>0.004080</td>\n",
       "      <td>0.006826</td>\n",
       "      <td>0.003688</td>\n",
       "      <td>0.004088</td>\n",
       "      <td>0.007035</td>\n",
       "      <td>981.827</td>\n",
       "      <td>945.474</td>\n",
       "      <td>49.768</td>\n",
       "      <td>14.931</td>\n",
       "      <td>distil_roberta-base</td>\n",
       "      <td>phi</td>\n",
       "      <td>distil_roberta-base_phi</td>\n",
       "      <td>distil</td>\n",
       "      <td>distil_phi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>phi</td>\n",
       "      <td>0.953032</td>\n",
       "      <td>0.929037</td>\n",
       "      <td>0.981073</td>\n",
       "      <td>0.954327</td>\n",
       "      <td>0.075061</td>\n",
       "      <td>0.004568</td>\n",
       "      <td>0.007543</td>\n",
       "      <td>0.004232</td>\n",
       "      <td>0.004533</td>\n",
       "      <td>0.008043</td>\n",
       "      <td>977.893</td>\n",
       "      <td>920.547</td>\n",
       "      <td>74.695</td>\n",
       "      <td>18.865</td>\n",
       "      <td>roberta_large</td>\n",
       "      <td>round_robin</td>\n",
       "      <td>roberta_large_round_robin</td>\n",
       "      <td>roberta</td>\n",
       "      <td>roberta_round_robin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>phi</td>\n",
       "      <td>0.957482</td>\n",
       "      <td>0.942297</td>\n",
       "      <td>0.974712</td>\n",
       "      <td>0.958211</td>\n",
       "      <td>0.059773</td>\n",
       "      <td>0.004435</td>\n",
       "      <td>0.007205</td>\n",
       "      <td>0.004967</td>\n",
       "      <td>0.004479</td>\n",
       "      <td>0.007393</td>\n",
       "      <td>971.554</td>\n",
       "      <td>935.751</td>\n",
       "      <td>59.491</td>\n",
       "      <td>25.204</td>\n",
       "      <td>electra_large</td>\n",
       "      <td>round_robin</td>\n",
       "      <td>electra_large_round_robin</td>\n",
       "      <td>electra</td>\n",
       "      <td>electra_round_robin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>phi</td>\n",
       "      <td>0.930762</td>\n",
       "      <td>0.893671</td>\n",
       "      <td>0.977991</td>\n",
       "      <td>0.933903</td>\n",
       "      <td>0.116543</td>\n",
       "      <td>0.005741</td>\n",
       "      <td>0.009296</td>\n",
       "      <td>0.004673</td>\n",
       "      <td>0.005643</td>\n",
       "      <td>0.010180</td>\n",
       "      <td>974.819</td>\n",
       "      <td>879.258</td>\n",
       "      <td>115.984</td>\n",
       "      <td>21.939</td>\n",
       "      <td>distil_roberta-base</td>\n",
       "      <td>round_robin</td>\n",
       "      <td>distil_roberta-base_round_robin</td>\n",
       "      <td>distil</td>\n",
       "      <td>distil_round_robin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gemma</td>\n",
       "      <td>0.952513</td>\n",
       "      <td>0.942543</td>\n",
       "      <td>0.963793</td>\n",
       "      <td>0.953027</td>\n",
       "      <td>0.058784</td>\n",
       "      <td>0.004798</td>\n",
       "      <td>0.007323</td>\n",
       "      <td>0.006022</td>\n",
       "      <td>0.004851</td>\n",
       "      <td>0.007605</td>\n",
       "      <td>953.327</td>\n",
       "      <td>930.743</td>\n",
       "      <td>58.121</td>\n",
       "      <td>35.809</td>\n",
       "      <td>distil_roberta-base</td>\n",
       "      <td>gemma</td>\n",
       "      <td>distil_roberta-base_gemma</td>\n",
       "      <td>distil</td>\n",
       "      <td>distil_gemma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gemma</td>\n",
       "      <td>0.951368</td>\n",
       "      <td>0.922319</td>\n",
       "      <td>0.985778</td>\n",
       "      <td>0.952972</td>\n",
       "      <td>0.083054</td>\n",
       "      <td>0.004832</td>\n",
       "      <td>0.008055</td>\n",
       "      <td>0.003891</td>\n",
       "      <td>0.004753</td>\n",
       "      <td>0.008681</td>\n",
       "      <td>975.065</td>\n",
       "      <td>906.741</td>\n",
       "      <td>82.123</td>\n",
       "      <td>14.071</td>\n",
       "      <td>roberta_large</td>\n",
       "      <td>gemma</td>\n",
       "      <td>roberta_large_gemma</td>\n",
       "      <td>roberta</td>\n",
       "      <td>roberta_gemma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>gemma</td>\n",
       "      <td>0.975026</td>\n",
       "      <td>0.956852</td>\n",
       "      <td>0.994925</td>\n",
       "      <td>0.975506</td>\n",
       "      <td>0.044888</td>\n",
       "      <td>0.003414</td>\n",
       "      <td>0.006106</td>\n",
       "      <td>0.002258</td>\n",
       "      <td>0.003380</td>\n",
       "      <td>0.006421</td>\n",
       "      <td>984.117</td>\n",
       "      <td>944.484</td>\n",
       "      <td>44.380</td>\n",
       "      <td>5.019</td>\n",
       "      <td>electra_large</td>\n",
       "      <td>gemma</td>\n",
       "      <td>electra_large_gemma</td>\n",
       "      <td>electra</td>\n",
       "      <td>electra_gemma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>gemma</td>\n",
       "      <td>0.959543</td>\n",
       "      <td>0.932407</td>\n",
       "      <td>0.990939</td>\n",
       "      <td>0.960764</td>\n",
       "      <td>0.071863</td>\n",
       "      <td>0.004375</td>\n",
       "      <td>0.007672</td>\n",
       "      <td>0.002963</td>\n",
       "      <td>0.004308</td>\n",
       "      <td>0.008201</td>\n",
       "      <td>980.171</td>\n",
       "      <td>917.806</td>\n",
       "      <td>71.058</td>\n",
       "      <td>8.965</td>\n",
       "      <td>roberta_large</td>\n",
       "      <td>mistral</td>\n",
       "      <td>roberta_large_mistral</td>\n",
       "      <td>roberta</td>\n",
       "      <td>roberta_mistral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>gemma</td>\n",
       "      <td>0.954805</td>\n",
       "      <td>0.928293</td>\n",
       "      <td>0.985772</td>\n",
       "      <td>0.956149</td>\n",
       "      <td>0.076179</td>\n",
       "      <td>0.004555</td>\n",
       "      <td>0.007816</td>\n",
       "      <td>0.003809</td>\n",
       "      <td>0.004515</td>\n",
       "      <td>0.008377</td>\n",
       "      <td>975.064</td>\n",
       "      <td>913.541</td>\n",
       "      <td>75.323</td>\n",
       "      <td>14.072</td>\n",
       "      <td>electra_large</td>\n",
       "      <td>mistral</td>\n",
       "      <td>electra_large_mistral</td>\n",
       "      <td>electra</td>\n",
       "      <td>electra_mistral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>gemma</td>\n",
       "      <td>0.958012</td>\n",
       "      <td>0.949179</td>\n",
       "      <td>0.967847</td>\n",
       "      <td>0.958403</td>\n",
       "      <td>0.051832</td>\n",
       "      <td>0.004444</td>\n",
       "      <td>0.006629</td>\n",
       "      <td>0.005803</td>\n",
       "      <td>0.004535</td>\n",
       "      <td>0.006729</td>\n",
       "      <td>957.337</td>\n",
       "      <td>937.611</td>\n",
       "      <td>51.253</td>\n",
       "      <td>31.799</td>\n",
       "      <td>distil_roberta-base</td>\n",
       "      <td>mistral</td>\n",
       "      <td>distil_roberta-base_mistral</td>\n",
       "      <td>distil</td>\n",
       "      <td>distil_mistral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>gemma</td>\n",
       "      <td>0.951827</td>\n",
       "      <td>0.937996</td>\n",
       "      <td>0.967640</td>\n",
       "      <td>0.952564</td>\n",
       "      <td>0.063987</td>\n",
       "      <td>0.004728</td>\n",
       "      <td>0.007582</td>\n",
       "      <td>0.005537</td>\n",
       "      <td>0.004731</td>\n",
       "      <td>0.007863</td>\n",
       "      <td>957.121</td>\n",
       "      <td>925.592</td>\n",
       "      <td>63.272</td>\n",
       "      <td>32.015</td>\n",
       "      <td>roberta_large</td>\n",
       "      <td>phi</td>\n",
       "      <td>roberta_large_phi</td>\n",
       "      <td>roberta</td>\n",
       "      <td>roberta_phi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>gemma</td>\n",
       "      <td>0.961902</td>\n",
       "      <td>0.967984</td>\n",
       "      <td>0.955425</td>\n",
       "      <td>0.961644</td>\n",
       "      <td>0.031624</td>\n",
       "      <td>0.004359</td>\n",
       "      <td>0.005742</td>\n",
       "      <td>0.006709</td>\n",
       "      <td>0.004436</td>\n",
       "      <td>0.005764</td>\n",
       "      <td>945.044</td>\n",
       "      <td>957.599</td>\n",
       "      <td>31.265</td>\n",
       "      <td>44.092</td>\n",
       "      <td>electra_large</td>\n",
       "      <td>phi</td>\n",
       "      <td>electra_large_phi</td>\n",
       "      <td>electra</td>\n",
       "      <td>electra_phi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset  accuracy  precision    recall  f1_score   fp_rate  std_accuracy  \\\n",
       "0      phi  0.947539   0.921121  0.978991  0.949152  0.083968      0.004890   \n",
       "1      phi  0.964984   0.957048  0.973710  0.965290  0.043752      0.004102   \n",
       "2      phi  0.945348   0.942504  0.948649  0.945541  0.057955      0.005259   \n",
       "3      phi  0.949168   0.928045  0.973925  0.950408  0.075626      0.004905   \n",
       "4      phi  0.955619   0.932033  0.982984  0.956811  0.071784      0.004458   \n",
       "5      phi  0.957894   0.949887  0.966854  0.958275  0.051074      0.004367   \n",
       "6      phi  0.966063   0.940545  0.995082  0.967030  0.063007      0.003887   \n",
       "7      phi  0.981562   0.969922  0.993972  0.981791  0.030866      0.002999   \n",
       "8      phi  0.967521   0.951754  0.985017  0.968085  0.050003      0.004080   \n",
       "9      phi  0.953032   0.929037  0.981073  0.954327  0.075061      0.004568   \n",
       "10     phi  0.957482   0.942297  0.974712  0.958211  0.059773      0.004435   \n",
       "11     phi  0.930762   0.893671  0.977991  0.933903  0.116543      0.005741   \n",
       "12   gemma  0.952513   0.942543  0.963793  0.953027  0.058784      0.004798   \n",
       "13   gemma  0.951368   0.922319  0.985778  0.952972  0.083054      0.004832   \n",
       "14   gemma  0.975026   0.956852  0.994925  0.975506  0.044888      0.003414   \n",
       "15   gemma  0.959543   0.932407  0.990939  0.960764  0.071863      0.004375   \n",
       "16   gemma  0.954805   0.928293  0.985772  0.956149  0.076179      0.004555   \n",
       "17   gemma  0.958012   0.949179  0.967847  0.958403  0.051832      0.004444   \n",
       "18   gemma  0.951827   0.937996  0.967640  0.952564  0.063987      0.004728   \n",
       "19   gemma  0.961902   0.967984  0.955425  0.961644  0.031624      0.004359   \n",
       "\n",
       "    std_precision  std_recall  std_f1_score  std_fp_rate       TP       TN  \\\n",
       "0        0.008095    0.004428      0.004867     0.008634  975.819  911.679   \n",
       "1        0.006376    0.005173      0.004190     0.006385  970.558  951.691   \n",
       "2        0.007493    0.007078      0.005370     0.007521  945.572  937.561   \n",
       "3        0.008146    0.004834      0.004921     0.008523  970.769  919.974   \n",
       "4        0.007439    0.004227      0.004445     0.007775  979.794  923.799   \n",
       "5        0.006684    0.005739      0.004449     0.006730  963.719  944.406   \n",
       "6        0.007039    0.002170      0.003831     0.007519  991.857  932.541   \n",
       "7        0.005423    0.002324      0.002999     0.005537  990.751  964.520   \n",
       "8        0.006826    0.003688      0.004088     0.007035  981.827  945.474   \n",
       "9        0.007543    0.004232      0.004533     0.008043  977.893  920.547   \n",
       "10       0.007205    0.004967      0.004479     0.007393  971.554  935.751   \n",
       "11       0.009296    0.004673      0.005643     0.010180  974.819  879.258   \n",
       "12       0.007323    0.006022      0.004851     0.007605  953.327  930.743   \n",
       "13       0.008055    0.003891      0.004753     0.008681  975.065  906.741   \n",
       "14       0.006106    0.002258      0.003380     0.006421  984.117  944.484   \n",
       "15       0.007672    0.002963      0.004308     0.008201  980.171  917.806   \n",
       "16       0.007816    0.003809      0.004515     0.008377  975.064  913.541   \n",
       "17       0.006629    0.005803      0.004535     0.006729  957.337  937.611   \n",
       "18       0.007582    0.005537      0.004731     0.007863  957.121  925.592   \n",
       "19       0.005742    0.006709      0.004436     0.005764  945.044  957.599   \n",
       "\n",
       "         FP      FN        base_detector trained_on_dataset  \\\n",
       "0    83.563  20.939        roberta_large              gemma   \n",
       "1    43.551  26.200        electra_large              gemma   \n",
       "2    57.681  51.186  distil_roberta-base              gemma   \n",
       "3    75.268  25.989        electra_large            mistral   \n",
       "4    71.443  16.964        roberta_large            mistral   \n",
       "5    50.836  33.039  distil_roberta-base            mistral   \n",
       "6    62.701   4.901        roberta_large                phi   \n",
       "7    30.722   6.007        electra_large                phi   \n",
       "8    49.768  14.931  distil_roberta-base                phi   \n",
       "9    74.695  18.865        roberta_large        round_robin   \n",
       "10   59.491  25.204        electra_large        round_robin   \n",
       "11  115.984  21.939  distil_roberta-base        round_robin   \n",
       "12   58.121  35.809  distil_roberta-base              gemma   \n",
       "13   82.123  14.071        roberta_large              gemma   \n",
       "14   44.380   5.019        electra_large              gemma   \n",
       "15   71.058   8.965        roberta_large            mistral   \n",
       "16   75.323  14.072        electra_large            mistral   \n",
       "17   51.253  31.799  distil_roberta-base            mistral   \n",
       "18   63.272  32.015        roberta_large                phi   \n",
       "19   31.265  44.092        electra_large                phi   \n",
       "\n",
       "                           detector detector_short_name        detector_name  \n",
       "0               roberta_large_gemma             roberta        roberta_gemma  \n",
       "1               electra_large_gemma             electra        electra_gemma  \n",
       "2         distil_roberta-base_gemma              distil         distil_gemma  \n",
       "3             electra_large_mistral             electra      electra_mistral  \n",
       "4             roberta_large_mistral             roberta      roberta_mistral  \n",
       "5       distil_roberta-base_mistral              distil       distil_mistral  \n",
       "6                 roberta_large_phi             roberta          roberta_phi  \n",
       "7                 electra_large_phi             electra          electra_phi  \n",
       "8           distil_roberta-base_phi              distil           distil_phi  \n",
       "9         roberta_large_round_robin             roberta  roberta_round_robin  \n",
       "10        electra_large_round_robin             electra  electra_round_robin  \n",
       "11  distil_roberta-base_round_robin              distil   distil_round_robin  \n",
       "12        distil_roberta-base_gemma              distil         distil_gemma  \n",
       "13              roberta_large_gemma             roberta        roberta_gemma  \n",
       "14              electra_large_gemma             electra        electra_gemma  \n",
       "15            roberta_large_mistral             roberta      roberta_mistral  \n",
       "16            electra_large_mistral             electra      electra_mistral  \n",
       "17      distil_roberta-base_mistral              distil       distil_mistral  \n",
       "18                roberta_large_phi             roberta          roberta_phi  \n",
       "19                electra_large_phi             electra          electra_phi  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freeze_base_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No cross model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-10c16cc3254a4d499557812d7747549b.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-10c16cc3254a4d499557812d7747549b.vega-embed details,\n",
       "  #altair-viz-10c16cc3254a4d499557812d7747549b.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-10c16cc3254a4d499557812d7747549b\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-10c16cc3254a4d499557812d7747549b\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-10c16cc3254a4d499557812d7747549b\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}, \"axis\": {\"labelFontSize\": 12, \"titleFontSize\": 12}, \"numberFormat\": \"0.2f\"}, \"data\": {\"name\": \"data-3c28a08c98880b1871a8f9ec4015831f\"}, \"facet\": {\"column\": {\"field\": \"detector_short_name\", \"title\": \"Detector\", \"type\": \"nominal\"}}, \"spec\": {\"layer\": [{\"mark\": {\"type\": \"rect\"}, \"encoding\": {\"color\": {\"field\": \"accuracy\", \"scale\": {\"scheme\": \"redyellowgreen\", \"domain\": [0.9, 1]}, \"type\": \"quantitative\"}, \"y\": {\"field\": \"dataset\", \"sort\": null, \"type\": \"nominal\"}}}, {\"mark\": {\"type\": \"text\", \"baseline\": \"middle\"}, \"encoding\": {\"color\": {\"condition\": {\"test\": \"(datum.accuracy > 0.5)\", \"value\": \"black\"}, \"value\": \"white\"}, \"text\": {\"field\": \"accuracy\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"dataset\", \"sort\": null, \"type\": \"nominal\"}}}], \"height\": 200, \"width\": 100}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-3c28a08c98880b1871a8f9ec4015831f\": [{\"dataset\": \"phi\", \"accuracy\": 0.9660632530120481, \"precision\": 0.9405451308417265, \"recall\": 0.9950818120753957, \"f1_score\": 0.9670302513930251, \"fp_rate\": 0.06300741602998862, \"std_accuracy\": 0.0038867741631004567, \"std_precision\": 0.007038721995395062, \"std_recall\": 0.002169757441829515, \"std_f1_score\": 0.0038308675318055765, \"std_fp_rate\": 0.007519162066533573, \"TP\": 991.857, \"TN\": 932.541, \"FP\": 62.701, \"FN\": 4.901, \"base_detector\": \"roberta_large\", \"trained_on_dataset\": \"phi\", \"detector\": \"roberta_large_phi\", \"detector_short_name\": \"roberta\", \"detector_name\": \"roberta_phi\"}, {\"dataset\": \"phi\", \"accuracy\": 0.9815617469879517, \"precision\": 0.9699223175166503, \"recall\": 0.9939716864590309, \"f1_score\": 0.9817907091715893, \"fp_rate\": 0.030866135466608557, \"std_accuracy\": 0.0029985288548792896, \"std_precision\": 0.005423118989129087, \"std_recall\": 0.002323886431912503, \"std_f1_score\": 0.002999208546486437, \"std_fp_rate\": 0.005536642614635546, \"TP\": 990.751, \"TN\": 964.52, \"FP\": 30.722, \"FN\": 6.007, \"base_detector\": \"electra_large\", \"trained_on_dataset\": \"phi\", \"detector\": \"electra_large_phi\", \"detector_short_name\": \"electra\", \"detector_name\": \"electra_phi\"}, {\"dataset\": \"phi\", \"accuracy\": 0.9675205823293174, \"precision\": 0.9517539545439512, \"recall\": 0.9850170739403075, \"f1_score\": 0.9680851252403114, \"fp_rate\": 0.05000300311979682, \"std_accuracy\": 0.004080445272076245, \"std_precision\": 0.0068255766707990325, \"std_recall\": 0.0036884749467968755, \"std_f1_score\": 0.00408750126449766, \"std_fp_rate\": 0.007034525932971776, \"TP\": 981.827, \"TN\": 945.474, \"FP\": 49.768, \"FN\": 14.931, \"base_detector\": \"distil_roberta-base\", \"trained_on_dataset\": \"phi\", \"detector\": \"distil_roberta-base_phi\", \"detector_short_name\": \"distil\", \"detector_name\": \"distil_phi\"}, {\"dataset\": \"gemma\", \"accuracy\": 0.9525126390293226, \"precision\": 0.9425428103473336, \"recall\": 0.963793366499752, \"f1_score\": 0.9530268171723422, \"fp_rate\": 0.0587839594926001, \"std_accuracy\": 0.004798334865180853, \"std_precision\": 0.0073228232459383825, \"std_recall\": 0.006022373094434596, \"std_f1_score\": 0.004850572318805919, \"std_fp_rate\": 0.0076053018856143, \"TP\": 953.327, \"TN\": 930.743, \"FP\": 58.121, \"FN\": 35.809, \"base_detector\": \"distil_roberta-base\", \"trained_on_dataset\": \"gemma\", \"detector\": \"distil_roberta-base_gemma\", \"detector_short_name\": \"distil\", \"detector_name\": \"distil_gemma\"}, {\"dataset\": \"gemma\", \"accuracy\": 0.9513680485338726, \"precision\": 0.9223194602171797, \"recall\": 0.985777511341087, \"f1_score\": 0.9529722329814656, \"fp_rate\": 0.08305410266312216, \"std_accuracy\": 0.004831968557932591, \"std_precision\": 0.008054509710016488, \"std_recall\": 0.003890605025301686, \"std_f1_score\": 0.004752599831961776, \"std_fp_rate\": 0.008681149001761763, \"TP\": 975.065, \"TN\": 906.741, \"FP\": 82.123, \"FN\": 14.071, \"base_detector\": \"roberta_large\", \"trained_on_dataset\": \"gemma\", \"detector\": \"roberta_large_gemma\", \"detector_short_name\": \"roberta\", \"detector_name\": \"roberta_gemma\"}, {\"dataset\": \"gemma\", \"accuracy\": 0.975025783619818, \"precision\": 0.9568523026449045, \"recall\": 0.9949245048029123, \"f1_score\": 0.9755060666167228, \"fp_rate\": 0.044887854899021855, \"std_accuracy\": 0.003413784702772843, \"std_precision\": 0.006105619897832036, \"std_recall\": 0.0022580704815399442, \"std_f1_score\": 0.003379584711432612, \"std_fp_rate\": 0.0064210156348912355, \"TP\": 984.117, \"TN\": 944.484, \"FP\": 44.38, \"FN\": 5.019, \"base_detector\": \"electra_large\", \"trained_on_dataset\": \"gemma\", \"detector\": \"electra_large_gemma\", \"detector_short_name\": \"electra\", \"detector_name\": \"electra_gemma\"}, {\"dataset\": \"mistral\", \"accuracy\": 0.9569011156186612, \"precision\": 0.930915164749734, \"recall\": 0.9869243024629213, \"f1_score\": 0.9580838077648952, \"fp_rate\": 0.07304540921893546, \"std_accuracy\": 0.004540534055839497, \"std_precision\": 0.00757087383661532, \"std_recall\": 0.0036297397704722215, \"std_f1_score\": 0.004468095261171358, \"std_fp_rate\": 0.008148941590125374, \"TP\": 971.684, \"TN\": 915.325, \"FP\": 72.116, \"FN\": 12.875, \"base_detector\": \"roberta_large\", \"trained_on_dataset\": \"mistral\", \"detector\": \"roberta_large_mistral\", \"detector_short_name\": \"roberta\", \"detector_name\": \"roberta_mistral\"}, {\"dataset\": \"mistral\", \"accuracy\": 0.9523387423935091, \"precision\": 0.9270682496452086, \"recall\": 0.9817749370668684, \"f1_score\": 0.9536154042821406, \"fp_rate\": 0.07701144660861974, \"std_accuracy\": 0.004724791083896401, \"std_precision\": 0.008021898597786785, \"std_recall\": 0.004272811661679837, \"std_f1_score\": 0.004712327753593076, \"std_fp_rate\": 0.008458654735810908, \"TP\": 966.615, \"TN\": 911.397, \"FP\": 76.044, \"FN\": 17.944, \"base_detector\": \"electra_large\", \"trained_on_dataset\": \"mistral\", \"detector\": \"electra_large_mistral\", \"detector_short_name\": \"electra\", \"detector_name\": \"electra_mistral\"}, {\"dataset\": \"mistral\", \"accuracy\": 0.9508012170385396, \"precision\": 0.9484219124733808, \"recall\": 0.9533115470494711, \"f1_score\": 0.950837043057522, \"fp_rate\": 0.05170717442342293, \"std_accuracy\": 0.004733429897045389, \"std_precision\": 0.006813692409842317, \"std_recall\": 0.006645064368282299, \"std_f1_score\": 0.0048021627915285255, \"std_fp_rate\": 0.006951303107203725, \"TP\": 938.589, \"TN\": 936.391, \"FP\": 51.05, \"FN\": 45.97, \"base_detector\": \"distil_roberta-base\", \"trained_on_dataset\": \"mistral\", \"detector\": \"distil_roberta-base_mistral\", \"detector_short_name\": \"distil\", \"detector_name\": \"distil_mistral\"}, {\"dataset\": \"round_robin\", \"accuracy\": 0.9869999999999998, \"precision\": 1.0, \"recall\": 0.9727229981471938, \"f1_score\": 0.985973448838837, \"fp_rate\": 0.0, \"std_accuracy\": 0.012943466820498021, \"std_precision\": 0.0, \"std_recall\": 0.02747800302972646, \"std_f1_score\": 0.014323385035362566, \"std_fp_rate\": 0.0, \"TP\": 35.079, \"TN\": 38.946, \"FP\": 0.0, \"FN\": 0.975, \"base_detector\": \"electra_large\", \"trained_on_dataset\": \"round_robin\", \"detector\": \"electra_large_round_robin\", \"detector_short_name\": \"electra\", \"detector_name\": \"electra_round_robin\"}, {\"dataset\": \"round_robin\", \"accuracy\": 0.9736933333333332, \"precision\": 1.0, \"recall\": 0.9451254772190496, \"f1_score\": 0.9713896914185441, \"fp_rate\": 0.0, \"std_accuracy\": 0.01839937680104049, \"std_precision\": 0.0, \"std_recall\": 0.03804535060304146, \"std_f1_score\": 0.02040714419542946, \"std_fp_rate\": 0.0, \"TP\": 34.081, \"TN\": 38.946, \"FP\": 0.0, \"FN\": 1.973, \"base_detector\": \"distil_roberta-base\", \"trained_on_dataset\": \"round_robin\", \"detector\": \"distil_roberta-base_round_robin\", \"detector_short_name\": \"distil\", \"detector_name\": \"distil_round_robin\"}, {\"dataset\": \"round_robin\", \"accuracy\": 0.90556, \"precision\": 0.8517346401994311, \"recall\": 0.9727229981471938, \"f1_score\": 0.9071265993953029, \"fp_rate\": 0.1567456703932303, \"std_accuracy\": 0.033978060895557625, \"std_precision\": 0.0560452099125148, \"std_recall\": 0.02747800302972646, \"std_f1_score\": 0.035394193478223944, \"std_fp_rate\": 0.0592947704148532, \"TP\": 35.079, \"TN\": 32.838, \"FP\": 6.108, \"FN\": 0.975, \"base_detector\": \"roberta_large\", \"trained_on_dataset\": \"round_robin\", \"detector\": \"roberta_large_round_robin\", \"detector_short_name\": \"roberta\", \"detector_name\": \"roberta_round_robin\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.FacetChart(...)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only keep entries where trained_on_dataset == dataset\n",
    "no_cross_model_df = freeze_base_df[freeze_base_df[\"trained_on_dataset\"] == freeze_base_df[\"dataset\"]]\n",
    "\n",
    "heatmap = alt.Chart(no_cross_model_df).mark_rect().encode(\n",
    "    alt.Y('dataset:N', sort=None),\n",
    "    #alt.Y('detector_short_name:N', sort=None, title=\"Detector\"),\n",
    "    alt.Color('accuracy:Q').scale(scheme='redyellowgreen', domain=(0.90, 1)),\n",
    "    #alt.Row(\"trained_on_dataset:N\", title=\"Dataset used for training\"),\n",
    ").properties(\n",
    "    width=100,\n",
    "    height=200\n",
    ")\n",
    "\n",
    "heatmap_text = alt.Chart(no_cross_model_df).mark_text(baseline='middle').encode(\n",
    "    #alt.X('dataset:N', sort=None, title=\"Dataset used for training and testing\"),\n",
    "    alt.Y('dataset:N', sort=None),\n",
    "    #alt.Y('detector_short_name:N', sort=None, title=\"Detector\"),\n",
    "    text='accuracy:Q',\n",
    "    color=alt.condition(\n",
    "        alt.datum.accuracy > 0.5,\n",
    "        alt.value('black'),\n",
    "        alt.value('white')\n",
    "    )\n",
    ").properties(\n",
    "    width=100,\n",
    "    height=200\n",
    ")\n",
    "\n",
    "chart = alt.layer(heatmap, heatmap_text).facet(\n",
    "    column=alt.Column(\"detector_short_name:N\", title=\"Detector\")\n",
    ").configure(\n",
    "    numberFormat='0.2f'\n",
    ").configure_axis(\n",
    "    labelFontSize=12,\n",
    "    titleFontSize=12\n",
    ")\n",
    "chart.save(\"notebooks/plots/heatmap_no_cross_llm.png\")\n",
    "chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-9acaffdc07bb40f3ad5e1f106adb831e.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-9acaffdc07bb40f3ad5e1f106adb831e.vega-embed details,\n",
       "  #altair-viz-9acaffdc07bb40f3ad5e1f106adb831e.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-9acaffdc07bb40f3ad5e1f106adb831e\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-9acaffdc07bb40f3ad5e1f106adb831e\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-9acaffdc07bb40f3ad5e1f106adb831e\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}, \"axis\": {\"labelFontSize\": 18, \"titleFontSize\": 18}, \"header\": {\"labelFontSize\": 18, \"titleFontSize\": 18}, \"legend\": {\"labelFontSize\": 18, \"titleFontSize\": 18, \"titleLimit\": 0}}, \"data\": {\"name\": \"data-3c28a08c98880b1871a8f9ec4015831f\"}, \"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"detector_short_name\", \"title\": \"Detector\", \"type\": \"nominal\"}, \"column\": {\"field\": \"dataset\", \"title\": \"Train and Test dataset\", \"type\": \"nominal\"}, \"x\": {\"field\": \"detector_short_name\", \"sort\": null, \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"accuracy\", \"scale\": {\"clamp\": true, \"domain\": [0.85, 1]}, \"type\": \"quantitative\"}}, \"height\": 200, \"width\": 100, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-3c28a08c98880b1871a8f9ec4015831f\": [{\"dataset\": \"phi\", \"accuracy\": 0.9660632530120481, \"precision\": 0.9405451308417265, \"recall\": 0.9950818120753957, \"f1_score\": 0.9670302513930251, \"fp_rate\": 0.06300741602998862, \"std_accuracy\": 0.0038867741631004567, \"std_precision\": 0.007038721995395062, \"std_recall\": 0.002169757441829515, \"std_f1_score\": 0.0038308675318055765, \"std_fp_rate\": 0.007519162066533573, \"TP\": 991.857, \"TN\": 932.541, \"FP\": 62.701, \"FN\": 4.901, \"base_detector\": \"roberta_large\", \"trained_on_dataset\": \"phi\", \"detector\": \"roberta_large_phi\", \"detector_short_name\": \"roberta\", \"detector_name\": \"roberta_phi\"}, {\"dataset\": \"phi\", \"accuracy\": 0.9815617469879517, \"precision\": 0.9699223175166503, \"recall\": 0.9939716864590309, \"f1_score\": 0.9817907091715893, \"fp_rate\": 0.030866135466608557, \"std_accuracy\": 0.0029985288548792896, \"std_precision\": 0.005423118989129087, \"std_recall\": 0.002323886431912503, \"std_f1_score\": 0.002999208546486437, \"std_fp_rate\": 0.005536642614635546, \"TP\": 990.751, \"TN\": 964.52, \"FP\": 30.722, \"FN\": 6.007, \"base_detector\": \"electra_large\", \"trained_on_dataset\": \"phi\", \"detector\": \"electra_large_phi\", \"detector_short_name\": \"electra\", \"detector_name\": \"electra_phi\"}, {\"dataset\": \"phi\", \"accuracy\": 0.9675205823293174, \"precision\": 0.9517539545439512, \"recall\": 0.9850170739403075, \"f1_score\": 0.9680851252403114, \"fp_rate\": 0.05000300311979682, \"std_accuracy\": 0.004080445272076245, \"std_precision\": 0.0068255766707990325, \"std_recall\": 0.0036884749467968755, \"std_f1_score\": 0.00408750126449766, \"std_fp_rate\": 0.007034525932971776, \"TP\": 981.827, \"TN\": 945.474, \"FP\": 49.768, \"FN\": 14.931, \"base_detector\": \"distil_roberta-base\", \"trained_on_dataset\": \"phi\", \"detector\": \"distil_roberta-base_phi\", \"detector_short_name\": \"distil\", \"detector_name\": \"distil_phi\"}, {\"dataset\": \"gemma\", \"accuracy\": 0.9525126390293226, \"precision\": 0.9425428103473336, \"recall\": 0.963793366499752, \"f1_score\": 0.9530268171723422, \"fp_rate\": 0.0587839594926001, \"std_accuracy\": 0.004798334865180853, \"std_precision\": 0.0073228232459383825, \"std_recall\": 0.006022373094434596, \"std_f1_score\": 0.004850572318805919, \"std_fp_rate\": 0.0076053018856143, \"TP\": 953.327, \"TN\": 930.743, \"FP\": 58.121, \"FN\": 35.809, \"base_detector\": \"distil_roberta-base\", \"trained_on_dataset\": \"gemma\", \"detector\": \"distil_roberta-base_gemma\", \"detector_short_name\": \"distil\", \"detector_name\": \"distil_gemma\"}, {\"dataset\": \"gemma\", \"accuracy\": 0.9513680485338726, \"precision\": 0.9223194602171797, \"recall\": 0.985777511341087, \"f1_score\": 0.9529722329814656, \"fp_rate\": 0.08305410266312216, \"std_accuracy\": 0.004831968557932591, \"std_precision\": 0.008054509710016488, \"std_recall\": 0.003890605025301686, \"std_f1_score\": 0.004752599831961776, \"std_fp_rate\": 0.008681149001761763, \"TP\": 975.065, \"TN\": 906.741, \"FP\": 82.123, \"FN\": 14.071, \"base_detector\": \"roberta_large\", \"trained_on_dataset\": \"gemma\", \"detector\": \"roberta_large_gemma\", \"detector_short_name\": \"roberta\", \"detector_name\": \"roberta_gemma\"}, {\"dataset\": \"gemma\", \"accuracy\": 0.975025783619818, \"precision\": 0.9568523026449045, \"recall\": 0.9949245048029123, \"f1_score\": 0.9755060666167228, \"fp_rate\": 0.044887854899021855, \"std_accuracy\": 0.003413784702772843, \"std_precision\": 0.006105619897832036, \"std_recall\": 0.0022580704815399442, \"std_f1_score\": 0.003379584711432612, \"std_fp_rate\": 0.0064210156348912355, \"TP\": 984.117, \"TN\": 944.484, \"FP\": 44.38, \"FN\": 5.019, \"base_detector\": \"electra_large\", \"trained_on_dataset\": \"gemma\", \"detector\": \"electra_large_gemma\", \"detector_short_name\": \"electra\", \"detector_name\": \"electra_gemma\"}, {\"dataset\": \"mistral\", \"accuracy\": 0.9569011156186612, \"precision\": 0.930915164749734, \"recall\": 0.9869243024629213, \"f1_score\": 0.9580838077648952, \"fp_rate\": 0.07304540921893546, \"std_accuracy\": 0.004540534055839497, \"std_precision\": 0.00757087383661532, \"std_recall\": 0.0036297397704722215, \"std_f1_score\": 0.004468095261171358, \"std_fp_rate\": 0.008148941590125374, \"TP\": 971.684, \"TN\": 915.325, \"FP\": 72.116, \"FN\": 12.875, \"base_detector\": \"roberta_large\", \"trained_on_dataset\": \"mistral\", \"detector\": \"roberta_large_mistral\", \"detector_short_name\": \"roberta\", \"detector_name\": \"roberta_mistral\"}, {\"dataset\": \"mistral\", \"accuracy\": 0.9523387423935091, \"precision\": 0.9270682496452086, \"recall\": 0.9817749370668684, \"f1_score\": 0.9536154042821406, \"fp_rate\": 0.07701144660861974, \"std_accuracy\": 0.004724791083896401, \"std_precision\": 0.008021898597786785, \"std_recall\": 0.004272811661679837, \"std_f1_score\": 0.004712327753593076, \"std_fp_rate\": 0.008458654735810908, \"TP\": 966.615, \"TN\": 911.397, \"FP\": 76.044, \"FN\": 17.944, \"base_detector\": \"electra_large\", \"trained_on_dataset\": \"mistral\", \"detector\": \"electra_large_mistral\", \"detector_short_name\": \"electra\", \"detector_name\": \"electra_mistral\"}, {\"dataset\": \"mistral\", \"accuracy\": 0.9508012170385396, \"precision\": 0.9484219124733808, \"recall\": 0.9533115470494711, \"f1_score\": 0.950837043057522, \"fp_rate\": 0.05170717442342293, \"std_accuracy\": 0.004733429897045389, \"std_precision\": 0.006813692409842317, \"std_recall\": 0.006645064368282299, \"std_f1_score\": 0.0048021627915285255, \"std_fp_rate\": 0.006951303107203725, \"TP\": 938.589, \"TN\": 936.391, \"FP\": 51.05, \"FN\": 45.97, \"base_detector\": \"distil_roberta-base\", \"trained_on_dataset\": \"mistral\", \"detector\": \"distil_roberta-base_mistral\", \"detector_short_name\": \"distil\", \"detector_name\": \"distil_mistral\"}, {\"dataset\": \"round_robin\", \"accuracy\": 0.9869999999999998, \"precision\": 1.0, \"recall\": 0.9727229981471938, \"f1_score\": 0.985973448838837, \"fp_rate\": 0.0, \"std_accuracy\": 0.012943466820498021, \"std_precision\": 0.0, \"std_recall\": 0.02747800302972646, \"std_f1_score\": 0.014323385035362566, \"std_fp_rate\": 0.0, \"TP\": 35.079, \"TN\": 38.946, \"FP\": 0.0, \"FN\": 0.975, \"base_detector\": \"electra_large\", \"trained_on_dataset\": \"round_robin\", \"detector\": \"electra_large_round_robin\", \"detector_short_name\": \"electra\", \"detector_name\": \"electra_round_robin\"}, {\"dataset\": \"round_robin\", \"accuracy\": 0.9736933333333332, \"precision\": 1.0, \"recall\": 0.9451254772190496, \"f1_score\": 0.9713896914185441, \"fp_rate\": 0.0, \"std_accuracy\": 0.01839937680104049, \"std_precision\": 0.0, \"std_recall\": 0.03804535060304146, \"std_f1_score\": 0.02040714419542946, \"std_fp_rate\": 0.0, \"TP\": 34.081, \"TN\": 38.946, \"FP\": 0.0, \"FN\": 1.973, \"base_detector\": \"distil_roberta-base\", \"trained_on_dataset\": \"round_robin\", \"detector\": \"distil_roberta-base_round_robin\", \"detector_short_name\": \"distil\", \"detector_name\": \"distil_round_robin\"}, {\"dataset\": \"round_robin\", \"accuracy\": 0.90556, \"precision\": 0.8517346401994311, \"recall\": 0.9727229981471938, \"f1_score\": 0.9071265993953029, \"fp_rate\": 0.1567456703932303, \"std_accuracy\": 0.033978060895557625, \"std_precision\": 0.0560452099125148, \"std_recall\": 0.02747800302972646, \"std_f1_score\": 0.035394193478223944, \"std_fp_rate\": 0.0592947704148532, \"TP\": 35.079, \"TN\": 32.838, \"FP\": 6.108, \"FN\": 0.975, \"base_detector\": \"roberta_large\", \"trained_on_dataset\": \"round_robin\", \"detector\": \"roberta_large_round_robin\", \"detector_short_name\": \"roberta\", \"detector_name\": \"roberta_round_robin\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# same as above but with bar chart\n",
    "bar_chart = alt.Chart(no_cross_model_df).mark_bar().encode(\n",
    "    #alt.X('detector_short_name:N', sort=None, title=\"Detector\"),\n",
    "    alt.X('detector_short_name:N', sort=None, title=None),\n",
    "    alt.Y('accuracy:Q').scale(alt.Scale(domain=(0.85, 1), clamp=True)),\n",
    "    #alt.Y('accuracy:Q'),\n",
    "    alt.Color(\"detector_short_name:N\", title=\"Detector\"),\n",
    "    column=alt.Column(\"dataset:N\", title=\"Train and Test dataset\")\n",
    ").properties(\n",
    "    width=100,\n",
    "    height=200,  \n",
    ").configure_axis(\n",
    "    labelFontSize=18,\n",
    "    titleFontSize=18,\n",
    ").configure_legend(\n",
    "    labelFontSize=18,\n",
    "    titleFontSize=18,\n",
    "    titleLimit=0\n",
    ").configure_header(\n",
    "    titleFontSize=18,\n",
    "    labelFontSize=18\n",
    ")\n",
    "bar_chart.save(\"notebooks/plots/heatmap_no_cross_llm_bar.png\")\n",
    "bar_chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-1f7695fe7efa4e04a699cac4f6ed024d.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-1f7695fe7efa4e04a699cac4f6ed024d.vega-embed details,\n",
       "  #altair-viz-1f7695fe7efa4e04a699cac4f6ed024d.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-1f7695fe7efa4e04a699cac4f6ed024d\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-1f7695fe7efa4e04a699cac4f6ed024d\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-1f7695fe7efa4e04a699cac4f6ed024d\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}, \"axis\": {\"labelFontSize\": 18, \"titleFontSize\": 18}, \"header\": {\"labelFontSize\": 18, \"titleFontSize\": 18}, \"legend\": {\"labelFontSize\": 18, \"titleFontSize\": 18, \"titleLimit\": 0}, \"numberFormat\": \"0.2f\"}, \"data\": {\"name\": \"data-c70d952cf842f2408146f0b6d57e7183\"}, \"facet\": {\"column\": {\"field\": \"detector_short_name\", \"title\": \"Detector\", \"type\": \"nominal\"}}, \"spec\": {\"layer\": [{\"mark\": {\"type\": \"rect\"}, \"encoding\": {\"color\": {\"field\": \"accuracy\", \"scale\": {\"scheme\": \"redyellowgreen\", \"domain\": [0.85, 1]}, \"type\": \"quantitative\"}, \"x\": {\"field\": \"dataset\", \"sort\": \"x\", \"title\": \"Tested on\", \"type\": \"nominal\"}, \"y\": {\"field\": \"trained_on_dataset\", \"sort\": \"y\", \"title\": \"Trained on\", \"type\": \"nominal\"}}}, {\"mark\": {\"type\": \"text\", \"baseline\": \"middle\"}, \"encoding\": {\"color\": {\"condition\": {\"test\": \"(datum.accuracy > 0.5)\", \"value\": \"black\"}, \"value\": \"white\"}, \"text\": {\"field\": \"accuracy\", \"type\": \"quantitative\"}, \"x\": {\"field\": \"dataset\", \"sort\": \"x\", \"title\": \"Tested on\", \"type\": \"nominal\"}, \"y\": {\"field\": \"trained_on_dataset\", \"sort\": \"y\", \"title\": \"Trained on\", \"type\": \"nominal\"}}}], \"height\": 300, \"width\": 300}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-c70d952cf842f2408146f0b6d57e7183\": [{\"dataset\": \"phi\", \"accuracy\": 0.964984437751004, \"precision\": 0.9570475571577994, \"recall\": 0.9737103962261067, \"f1_score\": 0.9652901292340491, \"fp_rate\": 0.04375174856287695, \"std_accuracy\": 0.0041021459407157065, \"std_precision\": 0.006375742096564536, \"std_recall\": 0.005172833326934814, \"std_f1_score\": 0.00418956708031596, \"std_fp_rate\": 0.006384688203406251, \"TP\": 970.558, \"TN\": 951.691, \"FP\": 43.551, \"FN\": 26.2, \"base_detector\": \"electra_large\", \"trained_on_dataset\": \"gemma\", \"detector\": \"electra_large_gemma\", \"detector_short_name\": \"electra\", \"detector_name\": \"electra_gemma\"}, {\"dataset\": \"phi\", \"accuracy\": 0.9491681726907629, \"precision\": 0.9280453208311245, \"recall\": 0.9739248258759978, \"f1_score\": 0.9504082139730308, \"fp_rate\": 0.07562617920727764, \"std_accuracy\": 0.004905390462442591, \"std_precision\": 0.008145924177671893, \"std_recall\": 0.004833715870089688, \"std_f1_score\": 0.004920651706485915, \"std_fp_rate\": 0.008523238839251952, \"TP\": 970.769, \"TN\": 919.974, \"FP\": 75.268, \"FN\": 25.989, \"base_detector\": \"electra_large\", \"trained_on_dataset\": \"mistral\", \"detector\": \"electra_large_mistral\", \"detector_short_name\": \"electra\", \"detector_name\": \"electra_mistral\"}, {\"dataset\": \"phi\", \"accuracy\": 0.9815617469879517, \"precision\": 0.9699223175166503, \"recall\": 0.9939716864590309, \"f1_score\": 0.9817907091715893, \"fp_rate\": 0.030866135466608557, \"std_accuracy\": 0.0029985288548792896, \"std_precision\": 0.005423118989129087, \"std_recall\": 0.002323886431912503, \"std_f1_score\": 0.002999208546486437, \"std_fp_rate\": 0.005536642614635546, \"TP\": 990.751, \"TN\": 964.52, \"FP\": 30.722, \"FN\": 6.007, \"base_detector\": \"electra_large\", \"trained_on_dataset\": \"phi\", \"detector\": \"electra_large_phi\", \"detector_short_name\": \"electra\", \"detector_name\": \"electra_phi\"}, {\"dataset\": \"phi\", \"accuracy\": 0.9574824297188754, \"precision\": 0.9422971653089905, \"recall\": 0.9747123920781413, \"f1_score\": 0.9582109079765843, \"fp_rate\": 0.059773060106851295, \"std_accuracy\": 0.004435375910198219, \"std_precision\": 0.007204543061996155, \"std_recall\": 0.0049671968250730595, \"std_f1_score\": 0.004479037091727788, \"std_fp_rate\": 0.0073933809552230315, \"TP\": 971.554, \"TN\": 935.751, \"FP\": 59.491, \"FN\": 25.204, \"base_detector\": \"electra_large\", \"trained_on_dataset\": \"round_robin\", \"detector\": \"electra_large_round_robin\", \"detector_short_name\": \"electra\", \"detector_name\": \"electra_round_robin\"}, {\"dataset\": \"gemma\", \"accuracy\": 0.975025783619818, \"precision\": 0.9568523026449045, \"recall\": 0.9949245048029123, \"f1_score\": 0.9755060666167228, \"fp_rate\": 0.044887854899021855, \"std_accuracy\": 0.003413784702772843, \"std_precision\": 0.006105619897832036, \"std_recall\": 0.0022580704815399442, \"std_f1_score\": 0.003379584711432612, \"std_fp_rate\": 0.0064210156348912355, \"TP\": 984.117, \"TN\": 944.484, \"FP\": 44.38, \"FN\": 5.019, \"base_detector\": \"electra_large\", \"trained_on_dataset\": \"gemma\", \"detector\": \"electra_large_gemma\", \"detector_short_name\": \"electra\", \"detector_name\": \"electra_gemma\"}, {\"dataset\": \"gemma\", \"accuracy\": 0.9548053589484328, \"precision\": 0.9282932152291479, \"recall\": 0.9857716311327744, \"f1_score\": 0.956148857206474, \"fp_rate\": 0.07617864586063716, \"std_accuracy\": 0.0045545134556007815, \"std_precision\": 0.007815751808183854, \"std_recall\": 0.0038089995414624066, \"std_f1_score\": 0.004514810025236076, \"std_fp_rate\": 0.008377452784502772, \"TP\": 975.064, \"TN\": 913.541, \"FP\": 75.323, \"FN\": 14.072, \"base_detector\": \"electra_large\", \"trained_on_dataset\": \"mistral\", \"detector\": \"electra_large_mistral\", \"detector_short_name\": \"electra\", \"detector_name\": \"electra_mistral\"}, {\"dataset\": \"gemma\", \"accuracy\": 0.9619024266936299, \"precision\": 0.9679844937537939, \"recall\": 0.9554253775605509, \"f1_score\": 0.9616437170445721, \"fp_rate\": 0.03162369378592626, \"std_accuracy\": 0.004359026623409581, \"std_precision\": 0.005741512740782832, \"std_recall\": 0.006708837765283757, \"std_f1_score\": 0.004435547409166117, \"std_fp_rate\": 0.005764404385010786, \"TP\": 945.044, \"TN\": 957.599, \"FP\": 31.265, \"FN\": 44.092, \"base_detector\": \"electra_large\", \"trained_on_dataset\": \"phi\", \"detector\": \"electra_large_phi\", \"detector_short_name\": \"electra\", \"detector_name\": \"electra_phi\"}, {\"dataset\": \"gemma\", \"accuracy\": 0.9568316481294237, \"precision\": 0.941223880419857, \"recall\": 0.974536436124574, \"f1_score\": 0.9575703266501087, \"fp_rate\": 0.06088196077031715, \"std_accuracy\": 0.004430032417625509, \"std_precision\": 0.0071873453555642685, \"std_recall\": 0.004970519718887778, \"std_f1_score\": 0.00442496182411392, \"std_fp_rate\": 0.007512672802393535, \"TP\": 963.947, \"TN\": 928.666, \"FP\": 60.198, \"FN\": 25.189, \"base_detector\": \"electra_large\", \"trained_on_dataset\": \"round_robin\", \"detector\": \"electra_large_round_robin\", \"detector_short_name\": \"electra\", \"detector_name\": \"electra_round_robin\"}, {\"dataset\": \"mistral\", \"accuracy\": 0.9568711967545639, \"precision\": 0.9554211886780044, \"recall\": 0.9583276382076572, \"f1_score\": 0.9568509764669371, \"fp_rate\": 0.04458938524840513, \"std_accuracy\": 0.004533579167416097, \"std_precision\": 0.006257567401625294, \"std_recall\": 0.006694139879739922, \"std_f1_score\": 0.004654710470221831, \"std_fp_rate\": 0.00631235338130139, \"TP\": 943.534, \"TN\": 943.416, \"FP\": 44.025, \"FN\": 41.025, \"base_detector\": \"electra_large\", \"trained_on_dataset\": \"gemma\", \"detector\": \"electra_large_gemma\", \"detector_short_name\": \"electra\", \"detector_name\": \"electra_gemma\"}, {\"dataset\": \"mistral\", \"accuracy\": 0.9523387423935091, \"precision\": 0.9270682496452086, \"recall\": 0.9817749370668684, \"f1_score\": 0.9536154042821406, \"fp_rate\": 0.07701144660861974, \"std_accuracy\": 0.004724791083896401, \"std_precision\": 0.008021898597786785, \"std_recall\": 0.004272811661679837, \"std_f1_score\": 0.004712327753593076, \"std_fp_rate\": 0.008458654735810908, \"TP\": 966.615, \"TN\": 911.397, \"FP\": 76.044, \"FN\": 17.944, \"base_detector\": \"electra_large\", \"trained_on_dataset\": \"mistral\", \"detector\": \"electra_large_mistral\", \"detector_short_name\": \"electra\", \"detector_name\": \"electra_mistral\"}, {\"dataset\": \"mistral\", \"accuracy\": 0.9484097363083164, \"precision\": 0.9672293772145313, \"recall\": 0.9281198244131114, \"f1_score\": 0.9472458609884016, \"fp_rate\": 0.031359097792010716, \"std_accuracy\": 0.004904264735662196, \"std_precision\": 0.005617943559116753, \"std_recall\": 0.008123789782077824, \"std_f1_score\": 0.005102128500655935, \"std_fp_rate\": 0.005417793861988032, \"TP\": 913.785, \"TN\": 956.479, \"FP\": 30.962, \"FN\": 70.774, \"base_detector\": \"electra_large\", \"trained_on_dataset\": \"phi\", \"detector\": \"electra_large_phi\", \"detector_short_name\": \"electra\", \"detector_name\": \"electra_phi\"}, {\"dataset\": \"mistral\", \"accuracy\": 0.945370182555781, \"precision\": 0.9398831871644243, \"recall\": 0.9514343159074624, \"f1_score\": 0.9455964458825724, \"fp_rate\": 0.060677807358744874, \"std_accuracy\": 0.00519223967537568, \"std_precision\": 0.00754460773759259, \"std_recall\": 0.007135369910959652, \"std_f1_score\": 0.005333523012710208, \"std_fp_rate\": 0.007612819137487468, \"TP\": 936.745, \"TN\": 927.525, \"FP\": 59.916, \"FN\": 47.814, \"base_detector\": \"electra_large\", \"trained_on_dataset\": \"round_robin\", \"detector\": \"electra_large_round_robin\", \"detector_short_name\": \"electra\", \"detector_name\": \"electra_round_robin\"}, {\"dataset\": \"round_robin\", \"accuracy\": 0.9869999999999998, \"precision\": 1.0, \"recall\": 0.9727229981471938, \"f1_score\": 0.985973448838837, \"fp_rate\": 0.0, \"std_accuracy\": 0.012943466820498021, \"std_precision\": 0.0, \"std_recall\": 0.02747800302972646, \"std_f1_score\": 0.014323385035362566, \"std_fp_rate\": 0.0, \"TP\": 35.079, \"TN\": 38.946, \"FP\": 0.0, \"FN\": 0.975, \"base_detector\": \"electra_large\", \"trained_on_dataset\": \"gemma\", \"detector\": \"electra_large_gemma\", \"detector_short_name\": \"electra\", \"detector_name\": \"electra_gemma\"}, {\"dataset\": \"round_robin\", \"accuracy\": 0.9322533333333334, \"precision\": 0.8952471757304545, \"recall\": 0.9727229981471938, \"f1_score\": 0.9314904834248824, \"fp_rate\": 0.10528634857754997, \"std_accuracy\": 0.02898103287784386, \"std_precision\": 0.050295605073879125, \"std_recall\": 0.02747800302972646, \"std_f1_score\": 0.031113396878935256, \"std_fp_rate\": 0.04973599365024823, \"TP\": 35.079, \"TN\": 34.84, \"FP\": 4.106, \"FN\": 0.975, \"base_detector\": \"electra_large\", \"trained_on_dataset\": \"mistral\", \"detector\": \"electra_large_mistral\", \"detector_short_name\": \"electra\", \"detector_name\": \"electra_mistral\"}, {\"dataset\": \"round_robin\", \"accuracy\": 0.9605466666666667, \"precision\": 1.0, \"recall\": 0.9177954592916513, \"f1_score\": 0.9565508036808451, \"fp_rate\": 0.0, \"std_accuracy\": 0.021930471951145974, \"std_precision\": 0.0, \"std_recall\": 0.045110845054220354, \"std_f1_score\": 0.024889552999598417, \"std_fp_rate\": 0.0, \"TP\": 33.095, \"TN\": 38.946, \"FP\": 0.0, \"FN\": 2.959, \"base_detector\": \"electra_large\", \"trained_on_dataset\": \"phi\", \"detector\": \"electra_large_phi\", \"detector_short_name\": \"electra\", \"detector_name\": \"electra_phi\"}, {\"dataset\": \"round_robin\", \"accuracy\": 0.9869999999999998, \"precision\": 1.0, \"recall\": 0.9727229981471938, \"f1_score\": 0.985973448838837, \"fp_rate\": 0.0, \"std_accuracy\": 0.012943466820498021, \"std_precision\": 0.0, \"std_recall\": 0.02747800302972646, \"std_f1_score\": 0.014323385035362566, \"std_fp_rate\": 0.0, \"TP\": 35.079, \"TN\": 38.946, \"FP\": 0.0, \"FN\": 0.975, \"base_detector\": \"electra_large\", \"trained_on_dataset\": \"round_robin\", \"detector\": \"electra_large_round_robin\", \"detector_short_name\": \"electra\", \"detector_name\": \"electra_round_robin\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.FacetChart(...)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_models = [\"gemma_chat\", \"zephyr\", \"llama3\"]\n",
    "no_chat_df = freeze_base_df[freeze_base_df[\"dataset\"].apply(lambda x: x not in chat_models)]\n",
    "# select electra only\n",
    "no_chat_df = no_chat_df[no_chat_df[\"detector_short_name\"] == \"electra\"]\n",
    "\n",
    "heatmap = alt.Chart(no_chat_df).mark_rect().encode(\n",
    "    alt.X('dataset:N', sort=\"x\", title=\"Tested on\"),\n",
    "    alt.Y('trained_on_dataset:N', sort=\"y\", title=\"Trained on\"),\n",
    "    alt.Color('accuracy:Q').scale(scheme='redyellowgreen', domain=[0.85, 1]),\n",
    "    #alt.Row(\"trained_on_dataset:N\", title=\"Dataset used for training\"),\n",
    ").properties(\n",
    "    width=300,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "heatmap_text = alt.Chart(no_chat_df).mark_text(baseline='middle').encode(\n",
    "    alt.X('dataset:N', sort=\"x\", title=\"Tested on\"),\n",
    "    alt.Y('trained_on_dataset:N', sort=\"y\", title=\"Trained on\"),\n",
    "    text='accuracy:Q',\n",
    "    color=alt.condition(\n",
    "        alt.datum.accuracy > 0.5,\n",
    "        alt.value('black'),\n",
    "        alt.value('white')\n",
    "    )\n",
    ").properties(\n",
    "    width=300,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "heatmap_cross = alt.layer(heatmap, heatmap_text).facet(\n",
    "    #column=alt.Column(\"trained_on_dataset:N\", title=\"Dataset used for training\")\n",
    "    column=alt.Column(\"detector_short_name:N\", title=\"Detector\")\n",
    ").configure(\n",
    "    numberFormat='0.2f'\n",
    ").configure_axis(\n",
    "    labelFontSize=18,\n",
    "    titleFontSize=18\n",
    ").configure_legend(\n",
    "    labelFontSize=18,\n",
    "    titleFontSize=18,\n",
    "    titleLimit=0\n",
    ").configure_header(\n",
    "    titleFontSize=18,\n",
    "    labelFontSize=18\n",
    ")\n",
    "\n",
    "heatmap_cross.save(\"notebooks/plots/heatmap_cross_llm.png\")\n",
    "heatmap_cross"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat Models only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-adc86b4d89b24a8499fdb82ccd58089e.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-adc86b4d89b24a8499fdb82ccd58089e.vega-embed details,\n",
       "  #altair-viz-adc86b4d89b24a8499fdb82ccd58089e.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-adc86b4d89b24a8499fdb82ccd58089e\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-adc86b4d89b24a8499fdb82ccd58089e\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-adc86b4d89b24a8499fdb82ccd58089e\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}, \"axis\": {\"labelFontSize\": 18, \"titleFontSize\": 18}, \"header\": {\"labelFontSize\": 18, \"titleFontSize\": 18}, \"legend\": {\"labelFontSize\": 18, \"titleFontSize\": 18, \"titleLimit\": 0}, \"numberFormat\": \"0.2f\"}, \"data\": {\"name\": \"data-81aba521e48763a2bc0be19a0ed6b093\"}, \"facet\": {\"column\": {\"field\": \"detector_short_name\", \"title\": \"Detector\", \"type\": \"nominal\"}}, \"spec\": {\"layer\": [{\"mark\": {\"type\": \"rect\"}, \"encoding\": {\"color\": {\"field\": \"accuracy\", \"scale\": {\"scheme\": \"redyellowgreen\", \"domain\": [0.85, 1]}, \"type\": \"quantitative\"}, \"x\": {\"field\": \"dataset\", \"sort\": \"x\", \"title\": \"Tested on\", \"type\": \"nominal\"}, \"y\": {\"field\": \"trained_on_dataset\", \"sort\": null, \"title\": \"Trained on\", \"type\": \"nominal\"}}}, {\"mark\": {\"type\": \"text\", \"baseline\": \"middle\"}, \"encoding\": {\"color\": {\"condition\": {\"test\": \"(datum.accuracy > 0.5)\", \"value\": \"black\"}, \"value\": \"white\"}, \"text\": {\"field\": \"accuracy\", \"type\": \"quantitative\"}, \"x\": {\"field\": \"dataset\", \"sort\": \"x\", \"title\": \"Tested on\", \"type\": \"nominal\"}, \"y\": {\"field\": \"trained_on_dataset\", \"sort\": null, \"title\": \"Trained on\", \"type\": \"nominal\"}}}], \"height\": 300, \"width\": 300}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-81aba521e48763a2bc0be19a0ed6b093\": [{\"dataset\": \"gemma_chat\", \"accuracy\": 0.9451325301204819, \"precision\": 0.9550689509089968, \"recall\": 0.9342877090149889, \"f1_score\": 0.9445378912952413, \"fp_rate\": 0.04400920455212902, \"std_accuracy\": 0.004961312237608764, \"std_precision\": 0.006564066371587951, \"std_recall\": 0.007766158562597565, \"std_f1_score\": 0.0052298136108433115, \"std_fp_rate\": 0.0063451503445432975, \"TP\": 931.267, \"TN\": 951.437, \"FP\": 43.805, \"FN\": 65.491, \"base_detector\": \"electra_large\", \"trained_on_dataset\": \"gemma\", \"detector\": \"electra_large_gemma\", \"detector_short_name\": \"electra\", \"detector_name\": \"electra_gemma\"}, {\"dataset\": \"gemma_chat\", \"accuracy\": 0.9399553212851406, \"precision\": 0.9266937493649462, \"recall\": 0.9555795630870014, \"f1_score\": 0.9408873726686859, \"fp_rate\": 0.07569905379858567, \"std_accuracy\": 0.0052859829368834006, \"std_precision\": 0.008341763263583761, \"std_recall\": 0.0063210527629096016, \"std_f1_score\": 0.0054365179251107225, \"std_fp_rate\": 0.008534678232913442, \"TP\": 952.493, \"TN\": 919.898, \"FP\": 75.344, \"FN\": 44.265, \"base_detector\": \"electra_large\", \"trained_on_dataset\": \"mistral\", \"detector\": \"electra_large_mistral\", \"detector_short_name\": \"electra\", \"detector_name\": \"electra_mistral\"}, {\"dataset\": \"gemma_chat\", \"accuracy\": 0.9709573293172691, \"precision\": 0.9691946462560532, \"recall\": 0.9728783020871583, \"f1_score\": 0.9710187982240472, \"fp_rate\": 0.030969102782918076, \"std_accuracy\": 0.003671302190344219, \"std_precision\": 0.005410608053811436, \"std_recall\": 0.00510084042328094, \"std_f1_score\": 0.003728675306979292, \"std_fp_rate\": 0.005438857219069897, \"TP\": 969.727, \"TN\": 964.42, \"FP\": 30.822, \"FN\": 27.031, \"base_detector\": \"electra_large\", \"trained_on_dataset\": \"phi\", \"detector\": \"electra_large_phi\", \"detector_short_name\": \"electra\", \"detector_name\": \"electra_phi\"}, {\"dataset\": \"gemma_chat\", \"accuracy\": 0.958031124497992, \"precision\": 0.9422508624368712, \"recall\": 0.9759247995924198, \"f1_score\": 0.9587743499823767, \"fp_rate\": 0.05989975552585564, \"std_accuracy\": 0.00432011662419556, \"std_precision\": 0.006984825414470697, \"std_recall\": 0.00475031182882228, \"std_f1_score\": 0.0043886831473779996, \"std_fp_rate\": 0.007191671304907559, \"TP\": 972.77, \"TN\": 935.628, \"FP\": 59.614, \"FN\": 23.988, \"base_detector\": \"electra_large\", \"trained_on_dataset\": \"round_robin\", \"detector\": \"electra_large_round_robin\", \"detector_short_name\": \"electra\", \"detector_name\": \"electra_round_robin\"}, {\"dataset\": \"zephyr\", \"accuracy\": 0.9437953646127757, \"precision\": 0.9605647401159545, \"recall\": 0.9255965308379238, \"f1_score\": 0.9427253300690637, \"fp_rate\": 0.03801294188956683, \"std_accuracy\": 0.005590341224609518, \"std_precision\": 0.006528663174149375, \"std_recall\": 0.009068680309251889, \"std_f1_score\": 0.005855518038513521, \"std_fp_rate\": 0.006345438059292869, \"TP\": 818.766, \"TN\": 850.808, \"FP\": 33.614, \"FN\": 65.812, \"base_detector\": \"electra_large\", \"trained_on_dataset\": \"gemma\", \"detector\": \"electra_large_gemma\", \"detector_short_name\": \"electra\", \"detector_name\": \"electra_gemma\"}, {\"dataset\": \"zephyr\", \"accuracy\": 0.9504279253815715, \"precision\": 0.9368883335042968, \"recall\": 0.9659332656844656, \"f1_score\": 0.9511623600426292, \"fp_rate\": 0.06509061173794156, \"std_accuracy\": 0.005020369257726371, \"std_precision\": 0.007943241841364421, \"std_recall\": 0.006166227136814958, \"std_f1_score\": 0.005073943622719155, \"std_fp_rate\": 0.008285511337043966, \"TP\": 854.446, \"TN\": 826.861, \"FP\": 57.561, \"FN\": 30.132, \"base_detector\": \"electra_large\", \"trained_on_dataset\": \"mistral\", \"detector\": \"electra_large_mistral\", \"detector_short_name\": \"electra\", \"detector_name\": \"electra_mistral\"}, {\"dataset\": \"zephyr\", \"accuracy\": 0.9355234595816845, \"precision\": 0.9719276361598592, \"recall\": 0.8969630974817383, \"f1_score\": 0.9329063378624849, \"fp_rate\": 0.025902071023388124, \"std_accuracy\": 0.005808638467255264, \"std_precision\": 0.005666064909303002, \"std_recall\": 0.010125833530887725, \"std_f1_score\": 0.0062269140640237135, \"std_fp_rate\": 0.005181039249814744, \"TP\": 793.43, \"TN\": 861.511, \"FP\": 22.911, \"FN\": 91.148, \"base_detector\": \"electra_large\", \"trained_on_dataset\": \"phi\", \"detector\": \"electra_large_phi\", \"detector_short_name\": \"electra\", \"detector_name\": \"electra_phi\"}, {\"dataset\": \"zephyr\", \"accuracy\": 0.9322984737139627, \"precision\": 0.9453668107295055, \"recall\": 0.9176479237037432, \"f1_score\": 0.9312639771122903, \"fp_rate\": 0.053048936675997596, \"std_accuracy\": 0.006097400612297059, \"std_precision\": 0.0077147114839492305, \"std_recall\": 0.009400793322908016, \"std_f1_score\": 0.006328942863134792, \"std_fp_rate\": 0.007561889343761211, \"TP\": 811.726, \"TN\": 837.51, \"FP\": 46.912, \"FN\": 72.852, \"base_detector\": \"electra_large\", \"trained_on_dataset\": \"round_robin\", \"detector\": \"electra_large_round_robin\", \"detector_short_name\": \"electra\", \"detector_name\": \"electra_round_robin\"}, {\"dataset\": \"llama3\", \"accuracy\": 0.9585833333333332, \"precision\": 0.956269925008076, \"recall\": 0.9611768598649177, \"f1_score\": 0.9586977890902838, \"fp_rate\": 0.04400920455212902, \"std_accuracy\": 0.0044647115534664885, \"std_precision\": 0.0064000665919887, \"std_recall\": 0.006156430307209931, \"std_f1_score\": 0.004578584899974279, \"std_fp_rate\": 0.0063451503445432975, \"TP\": 958.061, \"TN\": 951.437, \"FP\": 43.805, \"FN\": 38.697, \"base_detector\": \"electra_large\", \"trained_on_dataset\": \"gemma\", \"detector\": \"electra_large_gemma\", \"detector_short_name\": \"electra\", \"detector_name\": \"electra_gemma\"}, {\"dataset\": \"llama3\", \"accuracy\": 0.9562590361445784, \"precision\": 0.9289405026013601, \"recall\": 0.9881746584515326, \"f1_score\": 0.9576215468202542, \"fp_rate\": 0.07569905379858567, \"std_accuracy\": 0.004639612876635071, \"std_precision\": 0.008089193816457082, \"std_recall\": 0.003442801584560057, \"std_f1_score\": 0.004607622108226641, \"std_fp_rate\": 0.008534678232913442, \"TP\": 984.97, \"TN\": 919.898, \"FP\": 75.344, \"FN\": 11.788, \"base_detector\": \"electra_large\", \"trained_on_dataset\": \"mistral\", \"detector\": \"electra_large_mistral\", \"detector_short_name\": \"electra\", \"detector_name\": \"electra_mistral\"}, {\"dataset\": \"llama3\", \"accuracy\": 0.9735717871485944, \"precision\": 0.9693537886469469, \"recall\": 0.9781083127769746, \"f1_score\": 0.9736984891789178, \"fp_rate\": 0.030969102782918076, \"std_accuracy\": 0.0035887421538543106, \"std_precision\": 0.005384823561409833, \"std_recall\": 0.004702756656184701, \"std_f1_score\": 0.0036159508216130794, \"std_fp_rate\": 0.005438857219069897, \"TP\": 974.935, \"TN\": 964.42, \"FP\": 30.822, \"FN\": 21.823, \"base_detector\": \"electra_large\", \"trained_on_dataset\": \"phi\", \"detector\": \"electra_large_phi\", \"detector_short_name\": \"electra\", \"detector_name\": \"electra_phi\"}, {\"dataset\": \"llama3\", \"accuracy\": 0.9624814257028113, \"precision\": 0.9427448910487845, \"recall\": 0.98482941914206, \"f1_score\": 0.9633108533065683, \"fp_rate\": 0.05989975552585564, \"std_accuracy\": 0.004015996202987654, \"std_precision\": 0.006911699488924311, \"std_recall\": 0.003824532154671989, \"std_f1_score\": 0.004010382122109825, \"std_fp_rate\": 0.007191671304907559, \"TP\": 981.635, \"TN\": 935.628, \"FP\": 59.614, \"FN\": 15.123, \"base_detector\": \"electra_large\", \"trained_on_dataset\": \"round_robin\", \"detector\": \"electra_large_round_robin\", \"detector_short_name\": \"electra\", \"detector_name\": \"electra_round_robin\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.FacetChart(...)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_models = [\"gemma_chat\", \"zephyr\", \"llama3\"]\n",
    "chat_only_df = freeze_base_df[freeze_base_df[\"dataset\"].apply(lambda x: x in chat_models)]\n",
    "#chat_only_phi_df = chat_only_df[chat_only_df[\"trained_on_dataset\"] == \"phi\"]\n",
    "chat_only_electra_df = chat_only_df[chat_only_df[\"detector_short_name\"] == \"electra\"]\n",
    "\n",
    "heatmap = alt.Chart(chat_only_electra_df).mark_rect().encode(\n",
    "    alt.X('dataset:N', sort=\"x\", title=\"Tested on\"),\n",
    "    alt.Y('trained_on_dataset:N', sort=None, title=\"Trained on\"),\n",
    "    alt.Color('accuracy:Q').scale(scheme='redyellowgreen', domain=[0.85, 1]),\n",
    "    #alt.Row(\"trained_on_dataset:N\", title=\"Dataset used for training\"),\n",
    ").properties(\n",
    "    width=300,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "heatmap_text = alt.Chart(chat_only_electra_df).mark_text(baseline='middle').encode(\n",
    "    alt.X('dataset:N', sort=\"x\", title=\"Tested on\"),\n",
    "    alt.Y('trained_on_dataset:N', sort=None, title=\"Trained on\"),\n",
    "    text='accuracy:Q',\n",
    "    color=alt.condition(\n",
    "        alt.datum.accuracy > 0.5,\n",
    "        alt.value('black'),\n",
    "        alt.value('white')\n",
    "    )\n",
    ").properties(\n",
    "    width=300,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "chart = alt.layer(heatmap, heatmap_text).facet(\n",
    "    column=alt.Column(\"detector_short_name:N\", title=\"Detector\")\n",
    ").configure(\n",
    "    numberFormat='0.2f'\n",
    ").configure_axis(\n",
    "    labelFontSize=18,\n",
    "    titleFontSize=18\n",
    ").configure_legend(\n",
    "    labelFontSize=18,\n",
    "    titleFontSize=18,\n",
    "    titleLimit=0\n",
    ").configure_header(\n",
    "    titleFontSize=18,\n",
    "    labelFontSize=18\n",
    ")\n",
    "\n",
    "chart.save(\"notebooks/plots/heatmap_chat_only.png\")\n",
    "chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero shot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_detect_gpt_results = {\"fast_detect_gpt\": {\"07_05_0942\" : \"phi\", \"07_05_0949\" : \"gemma\", \"07_05_0956\" : \"mistral\", \"07_05_1003\" : \"round_robin\",\n",
    "                           \"07_05_1007\": \"gemma_chat\", \"07_05_1014\" : \"zephyr\", \"07_05_1020\" : \"llama3\"}}\n",
    "roberta_open_ai_results = {\"roberta_base_open_ai\": {\"06_05_1716\" : \"phi\", \"06_05_1718\" : \"gemma\", \"06_05_1719\" : \"mistral\", \"06_05_1721\" : \"round_robin\",\n",
    "                           \"06_05_1723\": \"gemma_chat\", \"06_05_1724\" : \"zephyr\", \"06_05_1726\" : \"llama3\"}}\n",
    "freeze_base_df = create_df_from_test_logs(\"full_finetuning\", trained_on_models, dataset_names)\n",
    "\n",
    "freeze_base_df = add_test_logs_to_results_df(freeze_base_df, fast_detect_gpt_results)\n",
    "freeze_base_df = add_test_logs_to_results_df(freeze_base_df, roberta_open_ai_results)\n",
    "\n",
    "# create detector_short_name column for the new detectors\n",
    "detector_name_to_short_name = {\"distil_roberta-base\": \"distil\", \"roberta_large\": \"roberta\", \"electra_large\": \"electra\", \"fast_detect_gpt\": \"fast_detect_gpt\", \"roberta_base_open_ai\": \"roberta_open_ai\"}\n",
    "freeze_base_df[\"detector_short_name\"] = freeze_base_df[\"base_detector\"].apply(lambda x: detector_name_to_short_name[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-b1a77501be3c498f803e1da14d98b33d.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-b1a77501be3c498f803e1da14d98b33d.vega-embed details,\n",
       "  #altair-viz-b1a77501be3c498f803e1da14d98b33d.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-b1a77501be3c498f803e1da14d98b33d\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-b1a77501be3c498f803e1da14d98b33d\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-b1a77501be3c498f803e1da14d98b33d\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}, \"axis\": {\"labelFontSize\": 12, \"titleFontSize\": 12}, \"numberFormat\": \"0.2f\"}, \"layer\": [{\"mark\": {\"type\": \"rect\"}, \"encoding\": {\"color\": {\"field\": \"accuracy\", \"scale\": {\"scheme\": \"redyellowgreen\"}, \"type\": \"quantitative\"}, \"x\": {\"field\": \"dataset\", \"sort\": \"x\", \"title\": \"Testing on\", \"type\": \"nominal\"}, \"y\": {\"field\": \"detector_short_name\", \"sort\": null, \"title\": \"Detector\", \"type\": \"nominal\"}}}, {\"mark\": {\"type\": \"text\", \"baseline\": \"middle\"}, \"encoding\": {\"color\": {\"condition\": {\"test\": \"(datum.accuracy > 0.5)\", \"value\": \"black\"}, \"value\": \"white\"}, \"text\": {\"field\": \"accuracy\", \"type\": \"quantitative\"}, \"x\": {\"field\": \"dataset\", \"sort\": \"x\", \"title\": \"Testing on\", \"type\": \"nominal\"}, \"y\": {\"field\": \"detector_short_name\", \"sort\": null, \"title\": \"Detector\", \"type\": \"nominal\"}}}], \"data\": {\"name\": \"data-32b29b2f068a547f726c67a91a5a704f\"}, \"height\": 200, \"width\": 200, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-32b29b2f068a547f726c67a91a5a704f\": [{\"accuracy\": 0.9477781124497993, \"precision\": 0.9208514922744839, \"recall\": 0.9798132850206415, \"f1_score\": 0.9493950385234539, \"fp_rate\": 0.08429144026261454, \"std_accuracy\": 0.004922426799885628, \"std_precision\": 0.008089814703987322, \"std_recall\": 0.0046295724270142185, \"std_f1_score\": 0.004894366073138051, \"std_fp_rate\": 0.008669388891613242, \"TP\": 976.292, \"TN\": 911.682, \"FP\": 83.914, \"FN\": 20.112, \"base_detector\": \"fast_detect_gpt\", \"trained_on_dataset\": \"z\", \"detector\": \"fast_detect_gpt\", \"dataset\": \"phi\", \"detector_short_name\": \"fast_detect_gpt\"}, {\"accuracy\": 0.9488614762386248, \"precision\": 0.921052796220481, \"recall\": 0.9818918747970609, \"f1_score\": 0.9504764791141807, \"fp_rate\": 0.08417442702711132, \"std_accuracy\": 0.005005078489596477, \"std_precision\": 0.00841633246702827, \"std_recall\": 0.004225337720472797, \"std_f1_score\": 0.004991231915100721, \"std_fp_rate\": 0.00888054972195826, \"TP\": 971.197, \"TN\": 905.651, \"FP\": 83.243, \"FN\": 17.909, \"base_detector\": \"fast_detect_gpt\", \"trained_on_dataset\": \"z\", \"detector\": \"fast_detect_gpt\", \"dataset\": \"gemma\", \"detector_short_name\": \"fast_detect_gpt\"}, {\"accuracy\": 0.9297981744421907, \"precision\": 0.917700725789643, \"recall\": 0.9444540767564479, \"f1_score\": 0.9308533331524023, \"fp_rate\": 0.08489040124618771, \"std_accuracy\": 0.005636750324354281, \"std_precision\": 0.008411963255492774, \"std_recall\": 0.007132439970871381, \"std_f1_score\": 0.00562574304387361, \"std_fp_rate\": 0.008903205240582199, \"TP\": 932.129, \"TN\": 901.433, \"FP\": 83.608, \"FN\": 54.83, \"base_detector\": \"fast_detect_gpt\", \"trained_on_dataset\": \"z\", \"detector\": \"fast_detect_gpt\", \"dataset\": \"mistral\", \"detector_short_name\": \"fast_detect_gpt\"}, {\"accuracy\": 0.9866933333333333, \"precision\": 0.9728209053910888, \"recall\": 1.0, \"f1_score\": 0.9860237415765236, \"fp_rate\": 0.02536178284285077, \"std_accuracy\": 0.013544960522480507, \"std_precision\": 0.027470028373192415, \"std_recall\": 0.0, \"std_f1_score\": 0.014329773334523217, \"std_fp_rate\": 0.025866060260362762, \"TP\": 35.751, \"TN\": 38.251, \"FP\": 0.998, \"FN\": 0.0, \"base_detector\": \"fast_detect_gpt\", \"trained_on_dataset\": \"z\", \"detector\": \"fast_detect_gpt\", \"dataset\": \"round_robin\", \"detector_short_name\": \"fast_detect_gpt\"}, {\"accuracy\": 0.9428217871485943, \"precision\": 0.9200264575373627, \"recall\": 0.969905462185622, \"f1_score\": 0.9442826795920609, \"fp_rate\": 0.08424520526362574, \"std_accuracy\": 0.005020451768386409, \"std_precision\": 0.008198260108708054, \"std_recall\": 0.005362109233605745, \"std_f1_score\": 0.005097771289700382, \"std_fp_rate\": 0.008475849468308467, \"TP\": 965.721, \"TN\": 912.38, \"FP\": 83.938, \"FN\": 29.961, \"base_detector\": \"fast_detect_gpt\", \"trained_on_dataset\": \"z\", \"detector\": \"fast_detect_gpt\", \"dataset\": \"gemma_chat\", \"detector_short_name\": \"fast_detect_gpt\"}, {\"accuracy\": 0.9151232334652345, \"precision\": 0.9128440135376916, \"recall\": 0.9177728251041829, \"f1_score\": 0.9152566153338648, \"fp_rate\": 0.08752817165224709, \"std_accuracy\": 0.0066497891432981595, \"std_precision\": 0.009550439501023675, \"std_recall\": 0.00939536666721598, \"std_f1_score\": 0.006959143847618827, \"std_fp_rate\": 0.009584871707885575, \"TP\": 811.326, \"TN\": 807.527, \"FP\": 77.461, \"FN\": 72.686, \"base_detector\": \"fast_detect_gpt\", \"trained_on_dataset\": \"z\", \"detector\": \"fast_detect_gpt\", \"dataset\": \"zephyr\", \"detector_short_name\": \"fast_detect_gpt\"}, {\"accuracy\": 0.9509211847389558, \"precision\": 0.9213027717397361, \"recall\": 0.9860849691204533, \"f1_score\": 0.9525723404412723, \"fp_rate\": 0.08425500499232305, \"std_accuracy\": 0.004881928742239332, \"std_precision\": 0.008235837332407675, \"std_recall\": 0.0037555655491333766, \"std_f1_score\": 0.004846615937916802, \"std_fp_rate\": 0.0087583777162562, \"TP\": 982.3, \"TN\": 911.935, \"FP\": 83.906, \"FN\": 13.859, \"base_detector\": \"fast_detect_gpt\", \"trained_on_dataset\": \"z\", \"detector\": \"fast_detect_gpt\", \"dataset\": \"llama3\", \"detector_short_name\": \"fast_detect_gpt\"}, {\"accuracy\": 0.8559643574297188, \"precision\": 0.820084552630729, \"recall\": 0.9117611809003839, \"f1_score\": 0.8634341577264033, \"fp_rate\": 0.19971947270955817, \"std_accuracy\": 0.008035115518263095, \"std_precision\": 0.012020233972825064, \"std_recall\": 0.008990573027287469, \"std_f1_score\": 0.008056271651704857, \"std_fp_rate\": 0.013126541963769294, \"TP\": 907.409, \"TN\": 797.672, \"FP\": 199.086, \"FN\": 87.833, \"base_detector\": \"roberta_base_open_ai\", \"trained_on_dataset\": \"z\", \"detector\": \"roberta_base_open_ai\", \"dataset\": \"phi\", \"detector_short_name\": \"roberta_open_ai\"}, {\"accuracy\": 0.8389954499494439, \"precision\": 0.7963927064518835, \"recall\": 0.9107840979350804, \"f1_score\": 0.8497005829642301, \"fp_rate\": 0.23279170080355452, \"std_accuracy\": 0.00843155564509402, \"std_precision\": 0.011802823229072439, \"std_recall\": 0.009170951786959173, \"std_f1_score\": 0.008469417348832728, \"std_fp_rate\": 0.013343701353416415, \"TP\": 900.646, \"TN\": 758.887, \"FP\": 230.249, \"FN\": 88.218, \"base_detector\": \"roberta_base_open_ai\", \"trained_on_dataset\": \"z\", \"detector\": \"roberta_base_open_ai\", \"dataset\": \"gemma\", \"detector_short_name\": \"roberta_open_ai\"}, {\"accuracy\": 0.7785831643002029, \"precision\": 0.7199871314445668, \"recall\": 0.9128657337594812, \"f1_score\": 0.8049578783040565, \"fp_rate\": 0.3560671063710648, \"std_accuracy\": 0.009646172051887702, \"std_precision\": 0.013105627888776675, \"std_recall\": 0.00913518414572279, \"std_f1_score\": 0.009328135117423343, \"std_fp_rate\": 0.015768918225673573, \"TP\": 901.393, \"TN\": 633.973, \"FP\": 350.586, \"FN\": 86.048, \"base_detector\": \"roberta_base_open_ai\", \"trained_on_dataset\": \"z\", \"detector\": \"roberta_base_open_ai\", \"dataset\": \"mistral\", \"detector_short_name\": \"roberta_open_ai\"}, {\"accuracy\": 0.8402133333333334, \"precision\": 0.7647796882444668, \"recall\": 1.0, \"f1_score\": 0.8654904379353626, \"fp_rate\": 0.3327259271192883, \"std_accuracy\": 0.04134568417622328, \"std_precision\": 0.05775187494968978, \"std_recall\": 0.0, \"std_f1_score\": 0.037433215965674005, \"std_fp_rate\": 0.07862180250845129, \"TP\": 38.946, \"TN\": 24.07, \"FP\": 11.984, \"FN\": 0.0, \"base_detector\": \"roberta_base_open_ai\", \"trained_on_dataset\": \"z\", \"detector\": \"roberta_base_open_ai\", \"dataset\": \"round_robin\", \"detector_short_name\": \"roberta_open_ai\"}, {\"accuracy\": 0.7958368473895582, \"precision\": 0.7399187507283521, \"recall\": 0.9118946545897535, \"f1_score\": 0.816886386600537, \"fp_rate\": 0.3200331128320067, \"std_accuracy\": 0.009095143610862938, \"std_precision\": 0.012622631118547575, \"std_recall\": 0.008910821580216163, \"std_f1_score\": 0.008972551803522591, \"std_fp_rate\": 0.014647830447862845, \"TP\": 907.55, \"TN\": 677.757, \"FP\": 319.001, \"FN\": 87.692, \"base_detector\": \"roberta_base_open_ai\", \"trained_on_dataset\": \"z\", \"detector\": \"roberta_base_open_ai\", \"dataset\": \"gemma_chat\", \"detector_short_name\": \"roberta_open_ai\"}, {\"accuracy\": 0.6628439796495195, \"precision\": 0.6083516603322492, \"recall\": 0.9140770797461191, \"f1_score\": 0.7304275183053497, \"fp_rate\": 0.5883563766291604, \"std_accuracy\": 0.011060812662856016, \"std_precision\": 0.013430291275361037, \"std_recall\": 0.009450928149170389, \"std_f1_score\": 0.010659328475456269, \"std_fp_rate\": 0.01620882421323861, \"TP\": 808.43, \"TN\": 364.141, \"FP\": 520.437, \"FN\": 75.992, \"base_detector\": \"roberta_base_open_ai\", \"trained_on_dataset\": \"z\", \"detector\": \"roberta_base_open_ai\", \"dataset\": \"zephyr\", \"detector_short_name\": \"roberta_open_ai\"}, {\"accuracy\": 0.7785893574297189, \"precision\": 0.7197655063892987, \"recall\": 0.9118946545897535, \"f1_score\": 0.8044476580362421, \"fp_rate\": 0.35451524482388447, \"std_accuracy\": 0.009444764494343266, \"std_precision\": 0.012707052869791307, \"std_recall\": 0.008910821580216163, \"std_f1_score\": 0.00912926593608254, \"std_fp_rate\": 0.015553201999168608, \"TP\": 907.55, \"TN\": 643.4, \"FP\": 353.358, \"FN\": 87.692, \"base_detector\": \"roberta_base_open_ai\", \"trained_on_dataset\": \"z\", \"detector\": \"roberta_base_open_ai\", \"dataset\": \"llama3\", \"detector_short_name\": \"roberta_open_ai\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_shot_detectors = [\"fast_detect_gpt\", \"roberta_base_open_ai\"]\n",
    "zero_shot_only_only_df = freeze_base_df[freeze_base_df[\"detector\"].apply(lambda x: x in zero_shot_detectors)]\n",
    "\n",
    "heatmap = alt.Chart(zero_shot_only_only_df).mark_rect().encode(\n",
    "    alt.X('dataset:N', sort=\"x\", title=\"Testing on\"),\n",
    "    alt.Y('detector_short_name:N', sort=None, title=\"Detector\"),\n",
    "    alt.Color('accuracy:Q').scale(scheme='redyellowgreen'),\n",
    "    #alt.Row(\"trained_on_dataset:N\", title=\"Dataset used for training\"),\n",
    ").properties(\n",
    "    width=200,\n",
    "    height=200\n",
    ")\n",
    "\n",
    "heatmap_text = alt.Chart(zero_shot_only_only_df).mark_text(baseline='middle').encode(\n",
    "    alt.X('dataset:N', sort=\"x\", title=\"Testing on\"),\n",
    "    alt.Y('detector_short_name:N', sort=None, title=\"Detector\"),\n",
    "    text='accuracy:Q',\n",
    "    color=alt.condition(\n",
    "        alt.datum.accuracy > 0.5,\n",
    "        alt.value('black'),\n",
    "        alt.value('white')\n",
    "    )\n",
    ").properties(\n",
    "    width=200,\n",
    "    height=200\n",
    ")\n",
    "\n",
    "chart = alt.layer(heatmap, heatmap_text).configure(\n",
    "    numberFormat='0.2f'\n",
    ").configure_axis(\n",
    "    labelFontSize=12,\n",
    "    titleFontSize=12\n",
    ")\n",
    "\n",
    "chart.save(\"notebooks/plots/heatmap_zero_shot.png\")\n",
    "chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-404361880e974517b5001dee0e29ff1e.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-404361880e974517b5001dee0e29ff1e.vega-embed details,\n",
       "  #altair-viz-404361880e974517b5001dee0e29ff1e.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-404361880e974517b5001dee0e29ff1e\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-404361880e974517b5001dee0e29ff1e\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-404361880e974517b5001dee0e29ff1e\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}, \"axis\": {\"labelFontSize\": 12, \"titleFontSize\": 12}, \"numberFormat\": \"0.2f\"}, \"data\": {\"name\": \"data-32b29b2f068a547f726c67a91a5a704f\"}, \"facet\": {\"column\": {\"field\": \"detector_short_name\", \"title\": \"Detector\", \"type\": \"nominal\"}}, \"spec\": {\"layer\": [{\"mark\": {\"type\": \"rect\"}, \"encoding\": {\"color\": {\"field\": \"accuracy\", \"scale\": {\"scheme\": \"redyellowgreen\"}, \"type\": \"quantitative\"}, \"x\": {\"field\": \"dataset\", \"sort\": \"x\", \"title\": \"Testing on\", \"type\": \"nominal\"}}}, {\"mark\": {\"type\": \"text\", \"baseline\": \"middle\"}, \"encoding\": {\"color\": {\"condition\": {\"test\": \"(datum.accuracy > 0.5)\", \"value\": \"black\"}, \"value\": \"white\"}, \"text\": {\"field\": \"accuracy\", \"type\": \"quantitative\"}, \"x\": {\"field\": \"dataset\", \"sort\": \"x\", \"title\": \"Testing on\", \"type\": \"nominal\"}}}], \"height\": 100, \"width\": 200}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-32b29b2f068a547f726c67a91a5a704f\": [{\"accuracy\": 0.9477781124497993, \"precision\": 0.9208514922744839, \"recall\": 0.9798132850206415, \"f1_score\": 0.9493950385234539, \"fp_rate\": 0.08429144026261454, \"std_accuracy\": 0.004922426799885628, \"std_precision\": 0.008089814703987322, \"std_recall\": 0.0046295724270142185, \"std_f1_score\": 0.004894366073138051, \"std_fp_rate\": 0.008669388891613242, \"TP\": 976.292, \"TN\": 911.682, \"FP\": 83.914, \"FN\": 20.112, \"base_detector\": \"fast_detect_gpt\", \"trained_on_dataset\": \"z\", \"detector\": \"fast_detect_gpt\", \"dataset\": \"phi\", \"detector_short_name\": \"fast_detect_gpt\"}, {\"accuracy\": 0.9488614762386248, \"precision\": 0.921052796220481, \"recall\": 0.9818918747970609, \"f1_score\": 0.9504764791141807, \"fp_rate\": 0.08417442702711132, \"std_accuracy\": 0.005005078489596477, \"std_precision\": 0.00841633246702827, \"std_recall\": 0.004225337720472797, \"std_f1_score\": 0.004991231915100721, \"std_fp_rate\": 0.00888054972195826, \"TP\": 971.197, \"TN\": 905.651, \"FP\": 83.243, \"FN\": 17.909, \"base_detector\": \"fast_detect_gpt\", \"trained_on_dataset\": \"z\", \"detector\": \"fast_detect_gpt\", \"dataset\": \"gemma\", \"detector_short_name\": \"fast_detect_gpt\"}, {\"accuracy\": 0.9297981744421907, \"precision\": 0.917700725789643, \"recall\": 0.9444540767564479, \"f1_score\": 0.9308533331524023, \"fp_rate\": 0.08489040124618771, \"std_accuracy\": 0.005636750324354281, \"std_precision\": 0.008411963255492774, \"std_recall\": 0.007132439970871381, \"std_f1_score\": 0.00562574304387361, \"std_fp_rate\": 0.008903205240582199, \"TP\": 932.129, \"TN\": 901.433, \"FP\": 83.608, \"FN\": 54.83, \"base_detector\": \"fast_detect_gpt\", \"trained_on_dataset\": \"z\", \"detector\": \"fast_detect_gpt\", \"dataset\": \"mistral\", \"detector_short_name\": \"fast_detect_gpt\"}, {\"accuracy\": 0.9866933333333333, \"precision\": 0.9728209053910888, \"recall\": 1.0, \"f1_score\": 0.9860237415765236, \"fp_rate\": 0.02536178284285077, \"std_accuracy\": 0.013544960522480507, \"std_precision\": 0.027470028373192415, \"std_recall\": 0.0, \"std_f1_score\": 0.014329773334523217, \"std_fp_rate\": 0.025866060260362762, \"TP\": 35.751, \"TN\": 38.251, \"FP\": 0.998, \"FN\": 0.0, \"base_detector\": \"fast_detect_gpt\", \"trained_on_dataset\": \"z\", \"detector\": \"fast_detect_gpt\", \"dataset\": \"round_robin\", \"detector_short_name\": \"fast_detect_gpt\"}, {\"accuracy\": 0.9428217871485943, \"precision\": 0.9200264575373627, \"recall\": 0.969905462185622, \"f1_score\": 0.9442826795920609, \"fp_rate\": 0.08424520526362574, \"std_accuracy\": 0.005020451768386409, \"std_precision\": 0.008198260108708054, \"std_recall\": 0.005362109233605745, \"std_f1_score\": 0.005097771289700382, \"std_fp_rate\": 0.008475849468308467, \"TP\": 965.721, \"TN\": 912.38, \"FP\": 83.938, \"FN\": 29.961, \"base_detector\": \"fast_detect_gpt\", \"trained_on_dataset\": \"z\", \"detector\": \"fast_detect_gpt\", \"dataset\": \"gemma_chat\", \"detector_short_name\": \"fast_detect_gpt\"}, {\"accuracy\": 0.9151232334652345, \"precision\": 0.9128440135376916, \"recall\": 0.9177728251041829, \"f1_score\": 0.9152566153338648, \"fp_rate\": 0.08752817165224709, \"std_accuracy\": 0.0066497891432981595, \"std_precision\": 0.009550439501023675, \"std_recall\": 0.00939536666721598, \"std_f1_score\": 0.006959143847618827, \"std_fp_rate\": 0.009584871707885575, \"TP\": 811.326, \"TN\": 807.527, \"FP\": 77.461, \"FN\": 72.686, \"base_detector\": \"fast_detect_gpt\", \"trained_on_dataset\": \"z\", \"detector\": \"fast_detect_gpt\", \"dataset\": \"zephyr\", \"detector_short_name\": \"fast_detect_gpt\"}, {\"accuracy\": 0.9509211847389558, \"precision\": 0.9213027717397361, \"recall\": 0.9860849691204533, \"f1_score\": 0.9525723404412723, \"fp_rate\": 0.08425500499232305, \"std_accuracy\": 0.004881928742239332, \"std_precision\": 0.008235837332407675, \"std_recall\": 0.0037555655491333766, \"std_f1_score\": 0.004846615937916802, \"std_fp_rate\": 0.0087583777162562, \"TP\": 982.3, \"TN\": 911.935, \"FP\": 83.906, \"FN\": 13.859, \"base_detector\": \"fast_detect_gpt\", \"trained_on_dataset\": \"z\", \"detector\": \"fast_detect_gpt\", \"dataset\": \"llama3\", \"detector_short_name\": \"fast_detect_gpt\"}, {\"accuracy\": 0.8559643574297188, \"precision\": 0.820084552630729, \"recall\": 0.9117611809003839, \"f1_score\": 0.8634341577264033, \"fp_rate\": 0.19971947270955817, \"std_accuracy\": 0.008035115518263095, \"std_precision\": 0.012020233972825064, \"std_recall\": 0.008990573027287469, \"std_f1_score\": 0.008056271651704857, \"std_fp_rate\": 0.013126541963769294, \"TP\": 907.409, \"TN\": 797.672, \"FP\": 199.086, \"FN\": 87.833, \"base_detector\": \"roberta_base_open_ai\", \"trained_on_dataset\": \"z\", \"detector\": \"roberta_base_open_ai\", \"dataset\": \"phi\", \"detector_short_name\": \"roberta_open_ai\"}, {\"accuracy\": 0.8389954499494439, \"precision\": 0.7963927064518835, \"recall\": 0.9107840979350804, \"f1_score\": 0.8497005829642301, \"fp_rate\": 0.23279170080355452, \"std_accuracy\": 0.00843155564509402, \"std_precision\": 0.011802823229072439, \"std_recall\": 0.009170951786959173, \"std_f1_score\": 0.008469417348832728, \"std_fp_rate\": 0.013343701353416415, \"TP\": 900.646, \"TN\": 758.887, \"FP\": 230.249, \"FN\": 88.218, \"base_detector\": \"roberta_base_open_ai\", \"trained_on_dataset\": \"z\", \"detector\": \"roberta_base_open_ai\", \"dataset\": \"gemma\", \"detector_short_name\": \"roberta_open_ai\"}, {\"accuracy\": 0.7785831643002029, \"precision\": 0.7199871314445668, \"recall\": 0.9128657337594812, \"f1_score\": 0.8049578783040565, \"fp_rate\": 0.3560671063710648, \"std_accuracy\": 0.009646172051887702, \"std_precision\": 0.013105627888776675, \"std_recall\": 0.00913518414572279, \"std_f1_score\": 0.009328135117423343, \"std_fp_rate\": 0.015768918225673573, \"TP\": 901.393, \"TN\": 633.973, \"FP\": 350.586, \"FN\": 86.048, \"base_detector\": \"roberta_base_open_ai\", \"trained_on_dataset\": \"z\", \"detector\": \"roberta_base_open_ai\", \"dataset\": \"mistral\", \"detector_short_name\": \"roberta_open_ai\"}, {\"accuracy\": 0.8402133333333334, \"precision\": 0.7647796882444668, \"recall\": 1.0, \"f1_score\": 0.8654904379353626, \"fp_rate\": 0.3327259271192883, \"std_accuracy\": 0.04134568417622328, \"std_precision\": 0.05775187494968978, \"std_recall\": 0.0, \"std_f1_score\": 0.037433215965674005, \"std_fp_rate\": 0.07862180250845129, \"TP\": 38.946, \"TN\": 24.07, \"FP\": 11.984, \"FN\": 0.0, \"base_detector\": \"roberta_base_open_ai\", \"trained_on_dataset\": \"z\", \"detector\": \"roberta_base_open_ai\", \"dataset\": \"round_robin\", \"detector_short_name\": \"roberta_open_ai\"}, {\"accuracy\": 0.7958368473895582, \"precision\": 0.7399187507283521, \"recall\": 0.9118946545897535, \"f1_score\": 0.816886386600537, \"fp_rate\": 0.3200331128320067, \"std_accuracy\": 0.009095143610862938, \"std_precision\": 0.012622631118547575, \"std_recall\": 0.008910821580216163, \"std_f1_score\": 0.008972551803522591, \"std_fp_rate\": 0.014647830447862845, \"TP\": 907.55, \"TN\": 677.757, \"FP\": 319.001, \"FN\": 87.692, \"base_detector\": \"roberta_base_open_ai\", \"trained_on_dataset\": \"z\", \"detector\": \"roberta_base_open_ai\", \"dataset\": \"gemma_chat\", \"detector_short_name\": \"roberta_open_ai\"}, {\"accuracy\": 0.6628439796495195, \"precision\": 0.6083516603322492, \"recall\": 0.9140770797461191, \"f1_score\": 0.7304275183053497, \"fp_rate\": 0.5883563766291604, \"std_accuracy\": 0.011060812662856016, \"std_precision\": 0.013430291275361037, \"std_recall\": 0.009450928149170389, \"std_f1_score\": 0.010659328475456269, \"std_fp_rate\": 0.01620882421323861, \"TP\": 808.43, \"TN\": 364.141, \"FP\": 520.437, \"FN\": 75.992, \"base_detector\": \"roberta_base_open_ai\", \"trained_on_dataset\": \"z\", \"detector\": \"roberta_base_open_ai\", \"dataset\": \"zephyr\", \"detector_short_name\": \"roberta_open_ai\"}, {\"accuracy\": 0.7785893574297189, \"precision\": 0.7197655063892987, \"recall\": 0.9118946545897535, \"f1_score\": 0.8044476580362421, \"fp_rate\": 0.35451524482388447, \"std_accuracy\": 0.009444764494343266, \"std_precision\": 0.012707052869791307, \"std_recall\": 0.008910821580216163, \"std_f1_score\": 0.00912926593608254, \"std_fp_rate\": 0.015553201999168608, \"TP\": 907.55, \"TN\": 643.4, \"FP\": 353.358, \"FN\": 87.692, \"base_detector\": \"roberta_base_open_ai\", \"trained_on_dataset\": \"z\", \"detector\": \"roberta_base_open_ai\", \"dataset\": \"llama3\", \"detector_short_name\": \"roberta_open_ai\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.FacetChart(...)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_shot_detectors = [\"fast_detect_gpt\", \"roberta_base_open_ai\"]\n",
    "zero_shot_only_only_df = freeze_base_df[freeze_base_df[\"detector\"].apply(lambda x: x in zero_shot_detectors)]\n",
    "\n",
    "heatmap = alt.Chart(zero_shot_only_only_df).mark_rect().encode(\n",
    "    alt.X('dataset:N', sort=\"x\", title=\"Testing on\"),\n",
    "    #alt.Y('detector_short_name:N', sort=None, title=\"Detector\"),\n",
    "    alt.Color('accuracy:Q').scale(scheme='redyellowgreen'),\n",
    "    #alt.Row(\"trained_on_dataset:N\", title=\"Dataset used for training\"),\n",
    ").properties(\n",
    "    width=200,\n",
    "    height=100\n",
    ")\n",
    "\n",
    "heatmap_text = alt.Chart(zero_shot_only_only_df).mark_text(baseline='middle').encode(\n",
    "    alt.X('dataset:N', sort=\"x\", title=\"Testing on\"),\n",
    "    #alt.Y('detector_short_name:N', sort=None, title=\"Detector\"),\n",
    "    text='accuracy:Q',\n",
    "    color=alt.condition(\n",
    "        alt.datum.accuracy > 0.5,\n",
    "        alt.value('black'),\n",
    "        alt.value('white')\n",
    "    )\n",
    ").properties(\n",
    "    width=200,\n",
    "    height=100\n",
    ")\n",
    "\n",
    "chart = alt.layer(heatmap, heatmap_text).facet(\n",
    "    column=alt.Column(\"detector_short_name:N\", title=\"Detector\")\n",
    ").configure(\n",
    "    numberFormat='0.2f'\n",
    ").configure_axis(\n",
    "    labelFontSize=12,\n",
    "    titleFontSize=12\n",
    ")\n",
    "\n",
    "chart.save(\"notebooks/plots/heatmap_zero_shot.png\")\n",
    "chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-127ac573b2334268a1250e4007824144.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-127ac573b2334268a1250e4007824144.vega-embed details,\n",
       "  #altair-viz-127ac573b2334268a1250e4007824144.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-127ac573b2334268a1250e4007824144\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-127ac573b2334268a1250e4007824144\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-127ac573b2334268a1250e4007824144\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}, \"axis\": {\"labelFontSize\": 18, \"titleFontSize\": 18}, \"header\": {\"labelFontSize\": 18, \"titleFontSize\": 18}, \"legend\": {\"labelFontSize\": 18, \"titleFontSize\": 18, \"titleLimit\": 0}}, \"data\": {\"name\": \"data-e9828c730ce7d3d39f6d580a71c88ff4\"}, \"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"detector_short_name\", \"title\": \"Detector\", \"type\": \"nominal\"}, \"column\": {\"field\": \"dataset\", \"title\": \"Test dataset\", \"type\": \"nominal\"}, \"x\": {\"field\": \"detector_short_name\", \"sort\": null, \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"accuracy\", \"scale\": {\"clamp\": true, \"domain\": [0.6, 1]}, \"type\": \"quantitative\"}}, \"height\": 200, \"width\": 100, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-e9828c730ce7d3d39f6d580a71c88ff4\": [{\"accuracy\": 0.9709573293172691, \"precision\": 0.9691946462560532, \"recall\": 0.9728783020871583, \"f1_score\": 0.9710187982240472, \"fp_rate\": 0.030969102782918076, \"std_accuracy\": 0.003671302190344219, \"std_precision\": 0.005410608053811436, \"std_recall\": 0.00510084042328094, \"std_f1_score\": 0.003728675306979292, \"std_fp_rate\": 0.005438857219069897, \"TP\": 969.727, \"TN\": 964.42, \"FP\": 30.822, \"FN\": 27.031, \"base_detector\": \"electra_large\", \"trained_on_dataset\": \"phi\", \"detector\": \"electra_large_phi\", \"dataset\": \"gemma_chat\", \"detector_short_name\": \"electra\"}, {\"accuracy\": 0.9735717871485944, \"precision\": 0.9693537886469469, \"recall\": 0.9781083127769746, \"f1_score\": 0.9736984891789178, \"fp_rate\": 0.030969102782918076, \"std_accuracy\": 0.0035887421538543106, \"std_precision\": 0.005384823561409833, \"std_recall\": 0.004702756656184701, \"std_f1_score\": 0.0036159508216130794, \"std_fp_rate\": 0.005438857219069897, \"TP\": 974.935, \"TN\": 964.42, \"FP\": 30.822, \"FN\": 21.823, \"base_detector\": \"electra_large\", \"trained_on_dataset\": \"phi\", \"detector\": \"electra_large_phi\", \"dataset\": \"llama3\", \"detector_short_name\": \"electra\"}, {\"accuracy\": 0.9355234595816845, \"precision\": 0.9719276361598592, \"recall\": 0.8969630974817383, \"f1_score\": 0.9329063378624849, \"fp_rate\": 0.025902071023388124, \"std_accuracy\": 0.005808638467255264, \"std_precision\": 0.005666064909303002, \"std_recall\": 0.010125833530887725, \"std_f1_score\": 0.0062269140640237135, \"std_fp_rate\": 0.005181039249814744, \"TP\": 793.43, \"TN\": 861.511, \"FP\": 22.911, \"FN\": 91.148, \"base_detector\": \"electra_large\", \"trained_on_dataset\": \"phi\", \"detector\": \"electra_large_phi\", \"dataset\": \"zephyr\", \"detector_short_name\": \"electra\"}, {\"accuracy\": 0.9428217871485943, \"precision\": 0.9200264575373627, \"recall\": 0.969905462185622, \"f1_score\": 0.9442826795920609, \"fp_rate\": 0.08424520526362574, \"std_accuracy\": 0.005020451768386409, \"std_precision\": 0.008198260108708054, \"std_recall\": 0.005362109233605745, \"std_f1_score\": 0.005097771289700382, \"std_fp_rate\": 0.008475849468308467, \"TP\": 965.721, \"TN\": 912.38, \"FP\": 83.938, \"FN\": 29.961, \"base_detector\": \"fast_detect_gpt\", \"trained_on_dataset\": \"z\", \"detector\": \"fast_detect_gpt\", \"dataset\": \"gemma_chat\", \"detector_short_name\": \"fast_detect_gpt\"}, {\"accuracy\": 0.9151232334652345, \"precision\": 0.9128440135376916, \"recall\": 0.9177728251041829, \"f1_score\": 0.9152566153338648, \"fp_rate\": 0.08752817165224709, \"std_accuracy\": 0.0066497891432981595, \"std_precision\": 0.009550439501023675, \"std_recall\": 0.00939536666721598, \"std_f1_score\": 0.006959143847618827, \"std_fp_rate\": 0.009584871707885575, \"TP\": 811.326, \"TN\": 807.527, \"FP\": 77.461, \"FN\": 72.686, \"base_detector\": \"fast_detect_gpt\", \"trained_on_dataset\": \"z\", \"detector\": \"fast_detect_gpt\", \"dataset\": \"zephyr\", \"detector_short_name\": \"fast_detect_gpt\"}, {\"accuracy\": 0.9509211847389558, \"precision\": 0.9213027717397361, \"recall\": 0.9860849691204533, \"f1_score\": 0.9525723404412723, \"fp_rate\": 0.08425500499232305, \"std_accuracy\": 0.004881928742239332, \"std_precision\": 0.008235837332407675, \"std_recall\": 0.0037555655491333766, \"std_f1_score\": 0.004846615937916802, \"std_fp_rate\": 0.0087583777162562, \"TP\": 982.3, \"TN\": 911.935, \"FP\": 83.906, \"FN\": 13.859, \"base_detector\": \"fast_detect_gpt\", \"trained_on_dataset\": \"z\", \"detector\": \"fast_detect_gpt\", \"dataset\": \"llama3\", \"detector_short_name\": \"fast_detect_gpt\"}, {\"accuracy\": 0.7958368473895582, \"precision\": 0.7399187507283521, \"recall\": 0.9118946545897535, \"f1_score\": 0.816886386600537, \"fp_rate\": 0.3200331128320067, \"std_accuracy\": 0.009095143610862938, \"std_precision\": 0.012622631118547575, \"std_recall\": 0.008910821580216163, \"std_f1_score\": 0.008972551803522591, \"std_fp_rate\": 0.014647830447862845, \"TP\": 907.55, \"TN\": 677.757, \"FP\": 319.001, \"FN\": 87.692, \"base_detector\": \"roberta_base_open_ai\", \"trained_on_dataset\": \"z\", \"detector\": \"roberta_base_open_ai\", \"dataset\": \"gemma_chat\", \"detector_short_name\": \"roberta_open_ai\"}, {\"accuracy\": 0.6628439796495195, \"precision\": 0.6083516603322492, \"recall\": 0.9140770797461191, \"f1_score\": 0.7304275183053497, \"fp_rate\": 0.5883563766291604, \"std_accuracy\": 0.011060812662856016, \"std_precision\": 0.013430291275361037, \"std_recall\": 0.009450928149170389, \"std_f1_score\": 0.010659328475456269, \"std_fp_rate\": 0.01620882421323861, \"TP\": 808.43, \"TN\": 364.141, \"FP\": 520.437, \"FN\": 75.992, \"base_detector\": \"roberta_base_open_ai\", \"trained_on_dataset\": \"z\", \"detector\": \"roberta_base_open_ai\", \"dataset\": \"zephyr\", \"detector_short_name\": \"roberta_open_ai\"}, {\"accuracy\": 0.7785893574297189, \"precision\": 0.7197655063892987, \"recall\": 0.9118946545897535, \"f1_score\": 0.8044476580362421, \"fp_rate\": 0.35451524482388447, \"std_accuracy\": 0.009444764494343266, \"std_precision\": 0.012707052869791307, \"std_recall\": 0.008910821580216163, \"std_f1_score\": 0.00912926593608254, \"std_fp_rate\": 0.015553201999168608, \"TP\": 907.55, \"TN\": 643.4, \"FP\": 353.358, \"FN\": 87.692, \"base_detector\": \"roberta_base_open_ai\", \"trained_on_dataset\": \"z\", \"detector\": \"roberta_base_open_ai\", \"dataset\": \"llama3\", \"detector_short_name\": \"roberta_open_ai\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_shot_detectors_and_best_trained = [\"fast_detect_gpt\", \"roberta_base_open_ai\", \"electra_large_phi\"]\n",
    "zero_shot_only_only_df = freeze_base_df[freeze_base_df[\"detector\"].apply(lambda x: x in zero_shot_detectors_and_best_trained)]\n",
    "\n",
    "# only keep chat datasets\n",
    "chat_models = [\"gemma_chat\", \"zephyr\", \"llama3\"]\n",
    "zero_shot_only_only_df = zero_shot_only_only_df[zero_shot_only_only_df[\"dataset\"].apply(lambda x: x in chat_models)]\n",
    "\n",
    "\n",
    "# same as above but with bar chart\n",
    "bar_chart = alt.Chart(zero_shot_only_only_df).mark_bar().encode(\n",
    "    alt.X('detector_short_name:N', sort=None, title=None),\n",
    "    alt.Y('accuracy:Q').scale(alt.Scale(domain=(0.6, 1), clamp=True)),\n",
    "    #alt.Y('accuracy:Q'),\n",
    "    alt.Color(\"detector_short_name:N\", title=\"Detector\"),\n",
    "    column=alt.Column(\"dataset:N\", title=\"Test dataset\")\n",
    ").properties(\n",
    "    width=100,\n",
    "    height=200,  \n",
    ").configure_axis(\n",
    "    labelFontSize=18,\n",
    "    titleFontSize=18,\n",
    ").configure_legend(\n",
    "    labelFontSize=18,\n",
    "    titleFontSize=18,\n",
    "    titleLimit=0\n",
    ").configure_header(\n",
    "    titleFontSize=18,\n",
    "    labelFontSize=18\n",
    ")\n",
    "bar_chart.save(\"notebooks/plots/heatmap_zero_shot_bar.png\")\n",
    "bar_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-3f751a174e6d4fa7b807a88ba5adc343.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-3f751a174e6d4fa7b807a88ba5adc343.vega-embed details,\n",
       "  #altair-viz-3f751a174e6d4fa7b807a88ba5adc343.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-3f751a174e6d4fa7b807a88ba5adc343\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-3f751a174e6d4fa7b807a88ba5adc343\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-3f751a174e6d4fa7b807a88ba5adc343\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"vconcat\": [{\"hconcat\": [{\"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"detector_short_name\", \"title\": \"Detector\", \"type\": \"nominal\"}, \"column\": {\"field\": \"dataset\", \"title\": null, \"type\": \"nominal\"}, \"x\": {\"field\": \"detector_short_name\", \"sort\": null, \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"accuracy\", \"scale\": {\"clamp\": true, \"domain\": [0.6, 1]}, \"type\": \"quantitative\"}}, \"height\": 100, \"transform\": [{\"filter\": \"(datum.dataset === 'gemma')\"}], \"width\": 100}, {\"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"detector_short_name\", \"title\": \"Detector\", \"type\": \"nominal\"}, \"column\": {\"field\": \"dataset\", \"title\": null, \"type\": \"nominal\"}, \"x\": {\"field\": \"detector_short_name\", \"sort\": null, \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"accuracy\", \"scale\": {\"clamp\": true, \"domain\": [0.6, 1]}, \"type\": \"quantitative\"}}, \"height\": 100, \"transform\": [{\"filter\": \"(datum.dataset === 'gemma_chat')\"}], \"width\": 100}, {\"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"detector_short_name\", \"title\": \"Detector\", \"type\": \"nominal\"}, \"column\": {\"field\": \"dataset\", \"title\": null, \"type\": \"nominal\"}, \"x\": {\"field\": \"detector_short_name\", \"sort\": null, \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"accuracy\", \"scale\": {\"clamp\": true, \"domain\": [0.6, 1]}, \"type\": \"quantitative\"}}, \"height\": 100, \"transform\": [{\"filter\": \"(datum.dataset === 'llama3')\"}], \"width\": 100}, {\"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"detector_short_name\", \"title\": \"Detector\", \"type\": \"nominal\"}, \"column\": {\"field\": \"dataset\", \"title\": null, \"type\": \"nominal\"}, \"x\": {\"field\": \"detector_short_name\", \"sort\": null, \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"accuracy\", \"scale\": {\"clamp\": true, \"domain\": [0.6, 1]}, \"type\": \"quantitative\"}}, \"height\": 100, \"transform\": [{\"filter\": \"(datum.dataset === 'mistral')\"}], \"width\": 100}]}, {\"hconcat\": [{\"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"detector_short_name\", \"title\": \"Detector\", \"type\": \"nominal\"}, \"column\": {\"field\": \"dataset\", \"title\": null, \"type\": \"nominal\"}, \"x\": {\"field\": \"detector_short_name\", \"sort\": null, \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"accuracy\", \"scale\": {\"clamp\": true, \"domain\": [0.6, 1]}, \"type\": \"quantitative\"}}, \"height\": 100, \"transform\": [{\"filter\": \"(datum.dataset === 'phi')\"}], \"width\": 100}, {\"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"detector_short_name\", \"title\": \"Detector\", \"type\": \"nominal\"}, \"column\": {\"field\": \"dataset\", \"title\": null, \"type\": \"nominal\"}, \"x\": {\"field\": \"detector_short_name\", \"sort\": null, \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"accuracy\", \"scale\": {\"clamp\": true, \"domain\": [0.6, 1]}, \"type\": \"quantitative\"}}, \"height\": 100, \"transform\": [{\"filter\": \"(datum.dataset === 'round_robin')\"}], \"width\": 100}, {\"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"detector_short_name\", \"title\": \"Detector\", \"type\": \"nominal\"}, \"column\": {\"field\": \"dataset\", \"title\": null, \"type\": \"nominal\"}, \"x\": {\"field\": \"detector_short_name\", \"sort\": null, \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"accuracy\", \"scale\": {\"clamp\": true, \"domain\": [0.6, 1]}, \"type\": \"quantitative\"}}, \"height\": 100, \"transform\": [{\"filter\": \"(datum.dataset === 'zephyr')\"}], \"width\": 100}]}], \"data\": {\"name\": \"data-f3200f23e2302859923897379d72ddb0\"}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-f3200f23e2302859923897379d72ddb0\": [{\"accuracy\": 0.9619024266936299, \"precision\": 0.9679844937537939, \"recall\": 0.9554253775605509, \"f1_score\": 0.9616437170445721, \"fp_rate\": 0.03162369378592626, \"std_accuracy\": 0.004359026623409581, \"std_precision\": 0.005741512740782832, \"std_recall\": 0.006708837765283757, \"std_f1_score\": 0.004435547409166117, \"std_fp_rate\": 0.005764404385010786, \"TP\": 945.044, \"TN\": 957.599, \"FP\": 31.265, \"FN\": 44.092, \"base_detector\": \"electra_large\", \"trained_on_dataset\": \"phi\", \"detector\": \"electra_large_phi\", \"dataset\": \"gemma\", \"detector_short_name\": \"electra\"}, {\"accuracy\": 0.9709573293172691, \"precision\": 0.9691946462560532, \"recall\": 0.9728783020871583, \"f1_score\": 0.9710187982240472, \"fp_rate\": 0.030969102782918076, \"std_accuracy\": 0.003671302190344219, \"std_precision\": 0.005410608053811436, \"std_recall\": 0.00510084042328094, \"std_f1_score\": 0.003728675306979292, \"std_fp_rate\": 0.005438857219069897, \"TP\": 969.727, \"TN\": 964.42, \"FP\": 30.822, \"FN\": 27.031, \"base_detector\": \"electra_large\", \"trained_on_dataset\": \"phi\", \"detector\": \"electra_large_phi\", \"dataset\": \"gemma_chat\", \"detector_short_name\": \"electra\"}, {\"accuracy\": 0.9735717871485944, \"precision\": 0.9693537886469469, \"recall\": 0.9781083127769746, \"f1_score\": 0.9736984891789178, \"fp_rate\": 0.030969102782918076, \"std_accuracy\": 0.0035887421538543106, \"std_precision\": 0.005384823561409833, \"std_recall\": 0.004702756656184701, \"std_f1_score\": 0.0036159508216130794, \"std_fp_rate\": 0.005438857219069897, \"TP\": 974.935, \"TN\": 964.42, \"FP\": 30.822, \"FN\": 21.823, \"base_detector\": \"electra_large\", \"trained_on_dataset\": \"phi\", \"detector\": \"electra_large_phi\", \"dataset\": \"llama3\", \"detector_short_name\": \"electra\"}, {\"accuracy\": 0.9484097363083164, \"precision\": 0.9672293772145313, \"recall\": 0.9281198244131114, \"f1_score\": 0.9472458609884016, \"fp_rate\": 0.031359097792010716, \"std_accuracy\": 0.004904264735662196, \"std_precision\": 0.005617943559116753, \"std_recall\": 0.008123789782077824, \"std_f1_score\": 0.005102128500655935, \"std_fp_rate\": 0.005417793861988032, \"TP\": 913.785, \"TN\": 956.479, \"FP\": 30.962, \"FN\": 70.774, \"base_detector\": \"electra_large\", \"trained_on_dataset\": \"phi\", \"detector\": \"electra_large_phi\", \"dataset\": \"mistral\", \"detector_short_name\": \"electra\"}, {\"accuracy\": 0.9815617469879517, \"precision\": 0.9699223175166503, \"recall\": 0.9939716864590309, \"f1_score\": 0.9817907091715893, \"fp_rate\": 0.030866135466608557, \"std_accuracy\": 0.0029985288548792896, \"std_precision\": 0.005423118989129087, \"std_recall\": 0.002323886431912503, \"std_f1_score\": 0.002999208546486437, \"std_fp_rate\": 0.005536642614635546, \"TP\": 990.751, \"TN\": 964.52, \"FP\": 30.722, \"FN\": 6.007, \"base_detector\": \"electra_large\", \"trained_on_dataset\": \"phi\", \"detector\": \"electra_large_phi\", \"dataset\": \"phi\", \"detector_short_name\": \"electra\"}, {\"accuracy\": 0.9605466666666667, \"precision\": 1.0, \"recall\": 0.9177954592916513, \"f1_score\": 0.9565508036808451, \"fp_rate\": 0.0, \"std_accuracy\": 0.021930471951145974, \"std_precision\": 0.0, \"std_recall\": 0.045110845054220354, \"std_f1_score\": 0.024889552999598417, \"std_fp_rate\": 0.0, \"TP\": 33.095, \"TN\": 38.946, \"FP\": 0.0, \"FN\": 2.959, \"base_detector\": \"electra_large\", \"trained_on_dataset\": \"phi\", \"detector\": \"electra_large_phi\", \"dataset\": \"round_robin\", \"detector_short_name\": \"electra\"}, {\"accuracy\": 0.9355234595816845, \"precision\": 0.9719276361598592, \"recall\": 0.8969630974817383, \"f1_score\": 0.9329063378624849, \"fp_rate\": 0.025902071023388124, \"std_accuracy\": 0.005808638467255264, \"std_precision\": 0.005666064909303002, \"std_recall\": 0.010125833530887725, \"std_f1_score\": 0.0062269140640237135, \"std_fp_rate\": 0.005181039249814744, \"TP\": 793.43, \"TN\": 861.511, \"FP\": 22.911, \"FN\": 91.148, \"base_detector\": \"electra_large\", \"trained_on_dataset\": \"phi\", \"detector\": \"electra_large_phi\", \"dataset\": \"zephyr\", \"detector_short_name\": \"electra\"}, {\"accuracy\": 0.9477781124497993, \"precision\": 0.9208514922744839, \"recall\": 0.9798132850206415, \"f1_score\": 0.9493950385234539, \"fp_rate\": 0.08429144026261454, \"std_accuracy\": 0.004922426799885628, \"std_precision\": 0.008089814703987322, \"std_recall\": 0.0046295724270142185, \"std_f1_score\": 0.004894366073138051, \"std_fp_rate\": 0.008669388891613242, \"TP\": 976.292, \"TN\": 911.682, \"FP\": 83.914, \"FN\": 20.112, \"base_detector\": \"fast_detect_gpt\", \"trained_on_dataset\": \"z\", \"detector\": \"fast_detect_gpt\", \"dataset\": \"phi\", \"detector_short_name\": \"fast_detect_gpt\"}, {\"accuracy\": 0.9488614762386248, \"precision\": 0.921052796220481, \"recall\": 0.9818918747970609, \"f1_score\": 0.9504764791141807, \"fp_rate\": 0.08417442702711132, \"std_accuracy\": 0.005005078489596477, \"std_precision\": 0.00841633246702827, \"std_recall\": 0.004225337720472797, \"std_f1_score\": 0.004991231915100721, \"std_fp_rate\": 0.00888054972195826, \"TP\": 971.197, \"TN\": 905.651, \"FP\": 83.243, \"FN\": 17.909, \"base_detector\": \"fast_detect_gpt\", \"trained_on_dataset\": \"z\", \"detector\": \"fast_detect_gpt\", \"dataset\": \"gemma\", \"detector_short_name\": \"fast_detect_gpt\"}, {\"accuracy\": 0.9297981744421907, \"precision\": 0.917700725789643, \"recall\": 0.9444540767564479, \"f1_score\": 0.9308533331524023, \"fp_rate\": 0.08489040124618771, \"std_accuracy\": 0.005636750324354281, \"std_precision\": 0.008411963255492774, \"std_recall\": 0.007132439970871381, \"std_f1_score\": 0.00562574304387361, \"std_fp_rate\": 0.008903205240582199, \"TP\": 932.129, \"TN\": 901.433, \"FP\": 83.608, \"FN\": 54.83, \"base_detector\": \"fast_detect_gpt\", \"trained_on_dataset\": \"z\", \"detector\": \"fast_detect_gpt\", \"dataset\": \"mistral\", \"detector_short_name\": \"fast_detect_gpt\"}, {\"accuracy\": 0.9866933333333333, \"precision\": 0.9728209053910888, \"recall\": 1.0, \"f1_score\": 0.9860237415765236, \"fp_rate\": 0.02536178284285077, \"std_accuracy\": 0.013544960522480507, \"std_precision\": 0.027470028373192415, \"std_recall\": 0.0, \"std_f1_score\": 0.014329773334523217, \"std_fp_rate\": 0.025866060260362762, \"TP\": 35.751, \"TN\": 38.251, \"FP\": 0.998, \"FN\": 0.0, \"base_detector\": \"fast_detect_gpt\", \"trained_on_dataset\": \"z\", \"detector\": \"fast_detect_gpt\", \"dataset\": \"round_robin\", \"detector_short_name\": \"fast_detect_gpt\"}, {\"accuracy\": 0.9428217871485943, \"precision\": 0.9200264575373627, \"recall\": 0.969905462185622, \"f1_score\": 0.9442826795920609, \"fp_rate\": 0.08424520526362574, \"std_accuracy\": 0.005020451768386409, \"std_precision\": 0.008198260108708054, \"std_recall\": 0.005362109233605745, \"std_f1_score\": 0.005097771289700382, \"std_fp_rate\": 0.008475849468308467, \"TP\": 965.721, \"TN\": 912.38, \"FP\": 83.938, \"FN\": 29.961, \"base_detector\": \"fast_detect_gpt\", \"trained_on_dataset\": \"z\", \"detector\": \"fast_detect_gpt\", \"dataset\": \"gemma_chat\", \"detector_short_name\": \"fast_detect_gpt\"}, {\"accuracy\": 0.9151232334652345, \"precision\": 0.9128440135376916, \"recall\": 0.9177728251041829, \"f1_score\": 0.9152566153338648, \"fp_rate\": 0.08752817165224709, \"std_accuracy\": 0.0066497891432981595, \"std_precision\": 0.009550439501023675, \"std_recall\": 0.00939536666721598, \"std_f1_score\": 0.006959143847618827, \"std_fp_rate\": 0.009584871707885575, \"TP\": 811.326, \"TN\": 807.527, \"FP\": 77.461, \"FN\": 72.686, \"base_detector\": \"fast_detect_gpt\", \"trained_on_dataset\": \"z\", \"detector\": \"fast_detect_gpt\", \"dataset\": \"zephyr\", \"detector_short_name\": \"fast_detect_gpt\"}, {\"accuracy\": 0.9509211847389558, \"precision\": 0.9213027717397361, \"recall\": 0.9860849691204533, \"f1_score\": 0.9525723404412723, \"fp_rate\": 0.08425500499232305, \"std_accuracy\": 0.004881928742239332, \"std_precision\": 0.008235837332407675, \"std_recall\": 0.0037555655491333766, \"std_f1_score\": 0.004846615937916802, \"std_fp_rate\": 0.0087583777162562, \"TP\": 982.3, \"TN\": 911.935, \"FP\": 83.906, \"FN\": 13.859, \"base_detector\": \"fast_detect_gpt\", \"trained_on_dataset\": \"z\", \"detector\": \"fast_detect_gpt\", \"dataset\": \"llama3\", \"detector_short_name\": \"fast_detect_gpt\"}, {\"accuracy\": 0.8559643574297188, \"precision\": 0.820084552630729, \"recall\": 0.9117611809003839, \"f1_score\": 0.8634341577264033, \"fp_rate\": 0.19971947270955817, \"std_accuracy\": 0.008035115518263095, \"std_precision\": 0.012020233972825064, \"std_recall\": 0.008990573027287469, \"std_f1_score\": 0.008056271651704857, \"std_fp_rate\": 0.013126541963769294, \"TP\": 907.409, \"TN\": 797.672, \"FP\": 199.086, \"FN\": 87.833, \"base_detector\": \"roberta_base_open_ai\", \"trained_on_dataset\": \"z\", \"detector\": \"roberta_base_open_ai\", \"dataset\": \"phi\", \"detector_short_name\": \"roberta_open_ai\"}, {\"accuracy\": 0.8389954499494439, \"precision\": 0.7963927064518835, \"recall\": 0.9107840979350804, \"f1_score\": 0.8497005829642301, \"fp_rate\": 0.23279170080355452, \"std_accuracy\": 0.00843155564509402, \"std_precision\": 0.011802823229072439, \"std_recall\": 0.009170951786959173, \"std_f1_score\": 0.008469417348832728, \"std_fp_rate\": 0.013343701353416415, \"TP\": 900.646, \"TN\": 758.887, \"FP\": 230.249, \"FN\": 88.218, \"base_detector\": \"roberta_base_open_ai\", \"trained_on_dataset\": \"z\", \"detector\": \"roberta_base_open_ai\", \"dataset\": \"gemma\", \"detector_short_name\": \"roberta_open_ai\"}, {\"accuracy\": 0.7785831643002029, \"precision\": 0.7199871314445668, \"recall\": 0.9128657337594812, \"f1_score\": 0.8049578783040565, \"fp_rate\": 0.3560671063710648, \"std_accuracy\": 0.009646172051887702, \"std_precision\": 0.013105627888776675, \"std_recall\": 0.00913518414572279, \"std_f1_score\": 0.009328135117423343, \"std_fp_rate\": 0.015768918225673573, \"TP\": 901.393, \"TN\": 633.973, \"FP\": 350.586, \"FN\": 86.048, \"base_detector\": \"roberta_base_open_ai\", \"trained_on_dataset\": \"z\", \"detector\": \"roberta_base_open_ai\", \"dataset\": \"mistral\", \"detector_short_name\": \"roberta_open_ai\"}, {\"accuracy\": 0.8402133333333334, \"precision\": 0.7647796882444668, \"recall\": 1.0, \"f1_score\": 0.8654904379353626, \"fp_rate\": 0.3327259271192883, \"std_accuracy\": 0.04134568417622328, \"std_precision\": 0.05775187494968978, \"std_recall\": 0.0, \"std_f1_score\": 0.037433215965674005, \"std_fp_rate\": 0.07862180250845129, \"TP\": 38.946, \"TN\": 24.07, \"FP\": 11.984, \"FN\": 0.0, \"base_detector\": \"roberta_base_open_ai\", \"trained_on_dataset\": \"z\", \"detector\": \"roberta_base_open_ai\", \"dataset\": \"round_robin\", \"detector_short_name\": \"roberta_open_ai\"}, {\"accuracy\": 0.7958368473895582, \"precision\": 0.7399187507283521, \"recall\": 0.9118946545897535, \"f1_score\": 0.816886386600537, \"fp_rate\": 0.3200331128320067, \"std_accuracy\": 0.009095143610862938, \"std_precision\": 0.012622631118547575, \"std_recall\": 0.008910821580216163, \"std_f1_score\": 0.008972551803522591, \"std_fp_rate\": 0.014647830447862845, \"TP\": 907.55, \"TN\": 677.757, \"FP\": 319.001, \"FN\": 87.692, \"base_detector\": \"roberta_base_open_ai\", \"trained_on_dataset\": \"z\", \"detector\": \"roberta_base_open_ai\", \"dataset\": \"gemma_chat\", \"detector_short_name\": \"roberta_open_ai\"}, {\"accuracy\": 0.6628439796495195, \"precision\": 0.6083516603322492, \"recall\": 0.9140770797461191, \"f1_score\": 0.7304275183053497, \"fp_rate\": 0.5883563766291604, \"std_accuracy\": 0.011060812662856016, \"std_precision\": 0.013430291275361037, \"std_recall\": 0.009450928149170389, \"std_f1_score\": 0.010659328475456269, \"std_fp_rate\": 0.01620882421323861, \"TP\": 808.43, \"TN\": 364.141, \"FP\": 520.437, \"FN\": 75.992, \"base_detector\": \"roberta_base_open_ai\", \"trained_on_dataset\": \"z\", \"detector\": \"roberta_base_open_ai\", \"dataset\": \"zephyr\", \"detector_short_name\": \"roberta_open_ai\"}, {\"accuracy\": 0.7785893574297189, \"precision\": 0.7197655063892987, \"recall\": 0.9118946545897535, \"f1_score\": 0.8044476580362421, \"fp_rate\": 0.35451524482388447, \"std_accuracy\": 0.009444764494343266, \"std_precision\": 0.012707052869791307, \"std_recall\": 0.008910821580216163, \"std_f1_score\": 0.00912926593608254, \"std_fp_rate\": 0.015553201999168608, \"TP\": 907.55, \"TN\": 643.4, \"FP\": 353.358, \"FN\": 87.692, \"base_detector\": \"roberta_base_open_ai\", \"trained_on_dataset\": \"z\", \"detector\": \"roberta_base_open_ai\", \"dataset\": \"llama3\", \"detector_short_name\": \"roberta_open_ai\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.VConcatChart(...)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_shot_detectors_and_best_trained = [\"fast_detect_gpt\", \"roberta_base_open_ai\", \"electra_large_phi\"]\n",
    "zero_shot_only_only_df = freeze_base_df[freeze_base_df[\"detector\"].apply(lambda x: x in zero_shot_detectors_and_best_trained)]\n",
    "\n",
    "# same as above but with bar chart\n",
    "bar_chart = alt.Chart(zero_shot_only_only_df).mark_bar().encode(\n",
    "    alt.X('detector_short_name:N', sort=None, title=None),\n",
    "    alt.Y('accuracy:Q').scale(alt.Scale(domain=(0.6, 1), clamp=True)),\n",
    "    #alt.Y('accuracy:Q'),\n",
    "    alt.Color(\"detector_short_name:N\", title=\"Detector\"),\n",
    "    column=alt.Column(\"dataset:N\", title=None)\n",
    ").properties(\n",
    "    width=100,\n",
    "    height=100,  \n",
    ")\n",
    "\n",
    "# spread the char into two rows\n",
    "grid_chart = alt.vconcat()\n",
    "nb_rows = 2\n",
    "nb_dataset_per_row = 4\n",
    "\n",
    "datasets = zero_shot_only_only_df[\"dataset\"].unique()\n",
    "for i in range(nb_rows):\n",
    "    row = alt.hconcat()\n",
    "    for j in range(nb_dataset_per_row):\n",
    "        if i*nb_dataset_per_row + j >= len(datasets):\n",
    "            break\n",
    "        row |= bar_chart.transform_filter(\n",
    "            alt.datum.dataset == datasets[i*nb_dataset_per_row + j]\n",
    "        )\n",
    "    grid_chart &= row\n",
    "\n",
    "grid_chart.configure_axis(\n",
    "    labelFontSize=12,\n",
    "    titleFontSize=12,\n",
    ").configure_legend(\n",
    "    labelFontSize=12,\n",
    "    titleFontSize=12,\n",
    "    titleLimit=0\n",
    ").configure_header(\n",
    "    titleFontSize=12,\n",
    "    labelFontSize=12\n",
    ")\n",
    "grid_chart.save(\"notebooks/plots/heatmap_zero_shot_bar.png\")\n",
    "\n",
    "grid_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-6abbfae6884448dfa5815f8f9ab2bd38.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-6abbfae6884448dfa5815f8f9ab2bd38.vega-embed details,\n",
       "  #altair-viz-6abbfae6884448dfa5815f8f9ab2bd38.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-6abbfae6884448dfa5815f8f9ab2bd38\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-6abbfae6884448dfa5815f8f9ab2bd38\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-6abbfae6884448dfa5815f8f9ab2bd38\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"vconcat\": [{\"hconcat\": [{\"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"detector_short_name\", \"title\": \"Detector\", \"type\": \"nominal\"}, \"column\": {\"field\": \"dataset\", \"title\": null, \"type\": \"nominal\"}, \"x\": {\"field\": \"detector_short_name\", \"sort\": null, \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"accuracy\", \"scale\": {\"clamp\": true, \"domain\": [0.6, 1]}, \"type\": \"quantitative\"}}, \"height\": 100, \"transform\": [{\"filter\": \"(datum.dataset === 'gemma_chat')\"}], \"width\": 100}, {\"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"detector_short_name\", \"title\": \"Detector\", \"type\": \"nominal\"}, \"column\": {\"field\": \"dataset\", \"title\": null, \"type\": \"nominal\"}, \"x\": {\"field\": \"detector_short_name\", \"sort\": null, \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"accuracy\", \"scale\": {\"clamp\": true, \"domain\": [0.6, 1]}, \"type\": \"quantitative\"}}, \"height\": 100, \"transform\": [{\"filter\": \"(datum.dataset === 'zephyr')\"}], \"width\": 100}, {\"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"detector_short_name\", \"title\": \"Detector\", \"type\": \"nominal\"}, \"column\": {\"field\": \"dataset\", \"title\": null, \"type\": \"nominal\"}, \"x\": {\"field\": \"detector_short_name\", \"sort\": null, \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"accuracy\", \"scale\": {\"clamp\": true, \"domain\": [0.6, 1]}, \"type\": \"quantitative\"}}, \"height\": 100, \"transform\": [{\"filter\": \"(datum.dataset === 'llama3')\"}], \"width\": 100}]}], \"data\": {\"name\": \"data-f3200f23e2302859923897379d72ddb0\"}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-f3200f23e2302859923897379d72ddb0\": [{\"accuracy\": 0.9619024266936299, \"precision\": 0.9679844937537939, \"recall\": 0.9554253775605509, \"f1_score\": 0.9616437170445721, \"fp_rate\": 0.03162369378592626, \"std_accuracy\": 0.004359026623409581, \"std_precision\": 0.005741512740782832, \"std_recall\": 0.006708837765283757, \"std_f1_score\": 0.004435547409166117, \"std_fp_rate\": 0.005764404385010786, \"TP\": 945.044, \"TN\": 957.599, \"FP\": 31.265, \"FN\": 44.092, \"base_detector\": \"electra_large\", \"trained_on_dataset\": \"phi\", \"detector\": \"electra_large_phi\", \"dataset\": \"gemma\", \"detector_short_name\": \"electra\"}, {\"accuracy\": 0.9709573293172691, \"precision\": 0.9691946462560532, \"recall\": 0.9728783020871583, \"f1_score\": 0.9710187982240472, \"fp_rate\": 0.030969102782918076, \"std_accuracy\": 0.003671302190344219, \"std_precision\": 0.005410608053811436, \"std_recall\": 0.00510084042328094, \"std_f1_score\": 0.003728675306979292, \"std_fp_rate\": 0.005438857219069897, \"TP\": 969.727, \"TN\": 964.42, \"FP\": 30.822, \"FN\": 27.031, \"base_detector\": \"electra_large\", \"trained_on_dataset\": \"phi\", \"detector\": \"electra_large_phi\", \"dataset\": \"gemma_chat\", \"detector_short_name\": \"electra\"}, {\"accuracy\": 0.9735717871485944, \"precision\": 0.9693537886469469, \"recall\": 0.9781083127769746, \"f1_score\": 0.9736984891789178, \"fp_rate\": 0.030969102782918076, \"std_accuracy\": 0.0035887421538543106, \"std_precision\": 0.005384823561409833, \"std_recall\": 0.004702756656184701, \"std_f1_score\": 0.0036159508216130794, \"std_fp_rate\": 0.005438857219069897, \"TP\": 974.935, \"TN\": 964.42, \"FP\": 30.822, \"FN\": 21.823, \"base_detector\": \"electra_large\", \"trained_on_dataset\": \"phi\", \"detector\": \"electra_large_phi\", \"dataset\": \"llama3\", \"detector_short_name\": \"electra\"}, {\"accuracy\": 0.9484097363083164, \"precision\": 0.9672293772145313, \"recall\": 0.9281198244131114, \"f1_score\": 0.9472458609884016, \"fp_rate\": 0.031359097792010716, \"std_accuracy\": 0.004904264735662196, \"std_precision\": 0.005617943559116753, \"std_recall\": 0.008123789782077824, \"std_f1_score\": 0.005102128500655935, \"std_fp_rate\": 0.005417793861988032, \"TP\": 913.785, \"TN\": 956.479, \"FP\": 30.962, \"FN\": 70.774, \"base_detector\": \"electra_large\", \"trained_on_dataset\": \"phi\", \"detector\": \"electra_large_phi\", \"dataset\": \"mistral\", \"detector_short_name\": \"electra\"}, {\"accuracy\": 0.9815617469879517, \"precision\": 0.9699223175166503, \"recall\": 0.9939716864590309, \"f1_score\": 0.9817907091715893, \"fp_rate\": 0.030866135466608557, \"std_accuracy\": 0.0029985288548792896, \"std_precision\": 0.005423118989129087, \"std_recall\": 0.002323886431912503, \"std_f1_score\": 0.002999208546486437, \"std_fp_rate\": 0.005536642614635546, \"TP\": 990.751, \"TN\": 964.52, \"FP\": 30.722, \"FN\": 6.007, \"base_detector\": \"electra_large\", \"trained_on_dataset\": \"phi\", \"detector\": \"electra_large_phi\", \"dataset\": \"phi\", \"detector_short_name\": \"electra\"}, {\"accuracy\": 0.9605466666666667, \"precision\": 1.0, \"recall\": 0.9177954592916513, \"f1_score\": 0.9565508036808451, \"fp_rate\": 0.0, \"std_accuracy\": 0.021930471951145974, \"std_precision\": 0.0, \"std_recall\": 0.045110845054220354, \"std_f1_score\": 0.024889552999598417, \"std_fp_rate\": 0.0, \"TP\": 33.095, \"TN\": 38.946, \"FP\": 0.0, \"FN\": 2.959, \"base_detector\": \"electra_large\", \"trained_on_dataset\": \"phi\", \"detector\": \"electra_large_phi\", \"dataset\": \"round_robin\", \"detector_short_name\": \"electra\"}, {\"accuracy\": 0.9355234595816845, \"precision\": 0.9719276361598592, \"recall\": 0.8969630974817383, \"f1_score\": 0.9329063378624849, \"fp_rate\": 0.025902071023388124, \"std_accuracy\": 0.005808638467255264, \"std_precision\": 0.005666064909303002, \"std_recall\": 0.010125833530887725, \"std_f1_score\": 0.0062269140640237135, \"std_fp_rate\": 0.005181039249814744, \"TP\": 793.43, \"TN\": 861.511, \"FP\": 22.911, \"FN\": 91.148, \"base_detector\": \"electra_large\", \"trained_on_dataset\": \"phi\", \"detector\": \"electra_large_phi\", \"dataset\": \"zephyr\", \"detector_short_name\": \"electra\"}, {\"accuracy\": 0.9477781124497993, \"precision\": 0.9208514922744839, \"recall\": 0.9798132850206415, \"f1_score\": 0.9493950385234539, \"fp_rate\": 0.08429144026261454, \"std_accuracy\": 0.004922426799885628, \"std_precision\": 0.008089814703987322, \"std_recall\": 0.0046295724270142185, \"std_f1_score\": 0.004894366073138051, \"std_fp_rate\": 0.008669388891613242, \"TP\": 976.292, \"TN\": 911.682, \"FP\": 83.914, \"FN\": 20.112, \"base_detector\": \"fast_detect_gpt\", \"trained_on_dataset\": \"z\", \"detector\": \"fast_detect_gpt\", \"dataset\": \"phi\", \"detector_short_name\": \"fast_detect_gpt\"}, {\"accuracy\": 0.9488614762386248, \"precision\": 0.921052796220481, \"recall\": 0.9818918747970609, \"f1_score\": 0.9504764791141807, \"fp_rate\": 0.08417442702711132, \"std_accuracy\": 0.005005078489596477, \"std_precision\": 0.00841633246702827, \"std_recall\": 0.004225337720472797, \"std_f1_score\": 0.004991231915100721, \"std_fp_rate\": 0.00888054972195826, \"TP\": 971.197, \"TN\": 905.651, \"FP\": 83.243, \"FN\": 17.909, \"base_detector\": \"fast_detect_gpt\", \"trained_on_dataset\": \"z\", \"detector\": \"fast_detect_gpt\", \"dataset\": \"gemma\", \"detector_short_name\": \"fast_detect_gpt\"}, {\"accuracy\": 0.9297981744421907, \"precision\": 0.917700725789643, \"recall\": 0.9444540767564479, \"f1_score\": 0.9308533331524023, \"fp_rate\": 0.08489040124618771, \"std_accuracy\": 0.005636750324354281, \"std_precision\": 0.008411963255492774, \"std_recall\": 0.007132439970871381, \"std_f1_score\": 0.00562574304387361, \"std_fp_rate\": 0.008903205240582199, \"TP\": 932.129, \"TN\": 901.433, \"FP\": 83.608, \"FN\": 54.83, \"base_detector\": \"fast_detect_gpt\", \"trained_on_dataset\": \"z\", \"detector\": \"fast_detect_gpt\", \"dataset\": \"mistral\", \"detector_short_name\": \"fast_detect_gpt\"}, {\"accuracy\": 0.9866933333333333, \"precision\": 0.9728209053910888, \"recall\": 1.0, \"f1_score\": 0.9860237415765236, \"fp_rate\": 0.02536178284285077, \"std_accuracy\": 0.013544960522480507, \"std_precision\": 0.027470028373192415, \"std_recall\": 0.0, \"std_f1_score\": 0.014329773334523217, \"std_fp_rate\": 0.025866060260362762, \"TP\": 35.751, \"TN\": 38.251, \"FP\": 0.998, \"FN\": 0.0, \"base_detector\": \"fast_detect_gpt\", \"trained_on_dataset\": \"z\", \"detector\": \"fast_detect_gpt\", \"dataset\": \"round_robin\", \"detector_short_name\": \"fast_detect_gpt\"}, {\"accuracy\": 0.9428217871485943, \"precision\": 0.9200264575373627, \"recall\": 0.969905462185622, \"f1_score\": 0.9442826795920609, \"fp_rate\": 0.08424520526362574, \"std_accuracy\": 0.005020451768386409, \"std_precision\": 0.008198260108708054, \"std_recall\": 0.005362109233605745, \"std_f1_score\": 0.005097771289700382, \"std_fp_rate\": 0.008475849468308467, \"TP\": 965.721, \"TN\": 912.38, \"FP\": 83.938, \"FN\": 29.961, \"base_detector\": \"fast_detect_gpt\", \"trained_on_dataset\": \"z\", \"detector\": \"fast_detect_gpt\", \"dataset\": \"gemma_chat\", \"detector_short_name\": \"fast_detect_gpt\"}, {\"accuracy\": 0.9151232334652345, \"precision\": 0.9128440135376916, \"recall\": 0.9177728251041829, \"f1_score\": 0.9152566153338648, \"fp_rate\": 0.08752817165224709, \"std_accuracy\": 0.0066497891432981595, \"std_precision\": 0.009550439501023675, \"std_recall\": 0.00939536666721598, \"std_f1_score\": 0.006959143847618827, \"std_fp_rate\": 0.009584871707885575, \"TP\": 811.326, \"TN\": 807.527, \"FP\": 77.461, \"FN\": 72.686, \"base_detector\": \"fast_detect_gpt\", \"trained_on_dataset\": \"z\", \"detector\": \"fast_detect_gpt\", \"dataset\": \"zephyr\", \"detector_short_name\": \"fast_detect_gpt\"}, {\"accuracy\": 0.9509211847389558, \"precision\": 0.9213027717397361, \"recall\": 0.9860849691204533, \"f1_score\": 0.9525723404412723, \"fp_rate\": 0.08425500499232305, \"std_accuracy\": 0.004881928742239332, \"std_precision\": 0.008235837332407675, \"std_recall\": 0.0037555655491333766, \"std_f1_score\": 0.004846615937916802, \"std_fp_rate\": 0.0087583777162562, \"TP\": 982.3, \"TN\": 911.935, \"FP\": 83.906, \"FN\": 13.859, \"base_detector\": \"fast_detect_gpt\", \"trained_on_dataset\": \"z\", \"detector\": \"fast_detect_gpt\", \"dataset\": \"llama3\", \"detector_short_name\": \"fast_detect_gpt\"}, {\"accuracy\": 0.8559643574297188, \"precision\": 0.820084552630729, \"recall\": 0.9117611809003839, \"f1_score\": 0.8634341577264033, \"fp_rate\": 0.19971947270955817, \"std_accuracy\": 0.008035115518263095, \"std_precision\": 0.012020233972825064, \"std_recall\": 0.008990573027287469, \"std_f1_score\": 0.008056271651704857, \"std_fp_rate\": 0.013126541963769294, \"TP\": 907.409, \"TN\": 797.672, \"FP\": 199.086, \"FN\": 87.833, \"base_detector\": \"roberta_base_open_ai\", \"trained_on_dataset\": \"z\", \"detector\": \"roberta_base_open_ai\", \"dataset\": \"phi\", \"detector_short_name\": \"roberta_open_ai\"}, {\"accuracy\": 0.8389954499494439, \"precision\": 0.7963927064518835, \"recall\": 0.9107840979350804, \"f1_score\": 0.8497005829642301, \"fp_rate\": 0.23279170080355452, \"std_accuracy\": 0.00843155564509402, \"std_precision\": 0.011802823229072439, \"std_recall\": 0.009170951786959173, \"std_f1_score\": 0.008469417348832728, \"std_fp_rate\": 0.013343701353416415, \"TP\": 900.646, \"TN\": 758.887, \"FP\": 230.249, \"FN\": 88.218, \"base_detector\": \"roberta_base_open_ai\", \"trained_on_dataset\": \"z\", \"detector\": \"roberta_base_open_ai\", \"dataset\": \"gemma\", \"detector_short_name\": \"roberta_open_ai\"}, {\"accuracy\": 0.7785831643002029, \"precision\": 0.7199871314445668, \"recall\": 0.9128657337594812, \"f1_score\": 0.8049578783040565, \"fp_rate\": 0.3560671063710648, \"std_accuracy\": 0.009646172051887702, \"std_precision\": 0.013105627888776675, \"std_recall\": 0.00913518414572279, \"std_f1_score\": 0.009328135117423343, \"std_fp_rate\": 0.015768918225673573, \"TP\": 901.393, \"TN\": 633.973, \"FP\": 350.586, \"FN\": 86.048, \"base_detector\": \"roberta_base_open_ai\", \"trained_on_dataset\": \"z\", \"detector\": \"roberta_base_open_ai\", \"dataset\": \"mistral\", \"detector_short_name\": \"roberta_open_ai\"}, {\"accuracy\": 0.8402133333333334, \"precision\": 0.7647796882444668, \"recall\": 1.0, \"f1_score\": 0.8654904379353626, \"fp_rate\": 0.3327259271192883, \"std_accuracy\": 0.04134568417622328, \"std_precision\": 0.05775187494968978, \"std_recall\": 0.0, \"std_f1_score\": 0.037433215965674005, \"std_fp_rate\": 0.07862180250845129, \"TP\": 38.946, \"TN\": 24.07, \"FP\": 11.984, \"FN\": 0.0, \"base_detector\": \"roberta_base_open_ai\", \"trained_on_dataset\": \"z\", \"detector\": \"roberta_base_open_ai\", \"dataset\": \"round_robin\", \"detector_short_name\": \"roberta_open_ai\"}, {\"accuracy\": 0.7958368473895582, \"precision\": 0.7399187507283521, \"recall\": 0.9118946545897535, \"f1_score\": 0.816886386600537, \"fp_rate\": 0.3200331128320067, \"std_accuracy\": 0.009095143610862938, \"std_precision\": 0.012622631118547575, \"std_recall\": 0.008910821580216163, \"std_f1_score\": 0.008972551803522591, \"std_fp_rate\": 0.014647830447862845, \"TP\": 907.55, \"TN\": 677.757, \"FP\": 319.001, \"FN\": 87.692, \"base_detector\": \"roberta_base_open_ai\", \"trained_on_dataset\": \"z\", \"detector\": \"roberta_base_open_ai\", \"dataset\": \"gemma_chat\", \"detector_short_name\": \"roberta_open_ai\"}, {\"accuracy\": 0.6628439796495195, \"precision\": 0.6083516603322492, \"recall\": 0.9140770797461191, \"f1_score\": 0.7304275183053497, \"fp_rate\": 0.5883563766291604, \"std_accuracy\": 0.011060812662856016, \"std_precision\": 0.013430291275361037, \"std_recall\": 0.009450928149170389, \"std_f1_score\": 0.010659328475456269, \"std_fp_rate\": 0.01620882421323861, \"TP\": 808.43, \"TN\": 364.141, \"FP\": 520.437, \"FN\": 75.992, \"base_detector\": \"roberta_base_open_ai\", \"trained_on_dataset\": \"z\", \"detector\": \"roberta_base_open_ai\", \"dataset\": \"zephyr\", \"detector_short_name\": \"roberta_open_ai\"}, {\"accuracy\": 0.7785893574297189, \"precision\": 0.7197655063892987, \"recall\": 0.9118946545897535, \"f1_score\": 0.8044476580362421, \"fp_rate\": 0.35451524482388447, \"std_accuracy\": 0.009444764494343266, \"std_precision\": 0.012707052869791307, \"std_recall\": 0.008910821580216163, \"std_f1_score\": 0.00912926593608254, \"std_fp_rate\": 0.015553201999168608, \"TP\": 907.55, \"TN\": 643.4, \"FP\": 353.358, \"FN\": 87.692, \"base_detector\": \"roberta_base_open_ai\", \"trained_on_dataset\": \"z\", \"detector\": \"roberta_base_open_ai\", \"dataset\": \"llama3\", \"detector_short_name\": \"roberta_open_ai\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.VConcatChart(...)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_shot_detectors_and_best_trained = [\"fast_detect_gpt\", \"roberta_base_open_ai\", \"electra_large_phi\"]\n",
    "zero_shot_only_only_df = freeze_base_df[freeze_base_df[\"detector\"].apply(lambda x: x in zero_shot_detectors_and_best_trained)]\n",
    "\n",
    "# same as above but with bar chart\n",
    "bar_chart = alt.Chart(zero_shot_only_only_df).mark_bar().encode(\n",
    "    alt.X('detector_short_name:N', sort=None, title=None),\n",
    "    alt.Y('accuracy:Q').scale(alt.Scale(domain=(0.6, 1), clamp=True)),\n",
    "    #alt.Y('accuracy:Q'),\n",
    "    alt.Color(\"detector_short_name:N\", title=\"Detector\"),\n",
    "    column=alt.Column(\"dataset:N\", title=None)\n",
    ").properties(\n",
    "    width=100,\n",
    "    height=100,  \n",
    ")\n",
    "\n",
    "# spread the char into two rows\n",
    "grid_chart = alt.vconcat()\n",
    "nb_rows = 1\n",
    "nb_dataset_per_row = 3\n",
    "\n",
    "#datasets = zero_shot_only_only_df[\"dataset\"].unique()\n",
    "datasets = [\"gemma_chat\", \"zephyr\", \"llama3\"]\n",
    "for i in range(nb_rows):\n",
    "    row = alt.hconcat()\n",
    "    for j in range(nb_dataset_per_row):\n",
    "        if i*nb_dataset_per_row + j >= len(datasets):\n",
    "            break\n",
    "        row |= bar_chart.transform_filter(\n",
    "            alt.datum.dataset == datasets[i*nb_dataset_per_row + j]\n",
    "        )\n",
    "    grid_chart &= row\n",
    "\n",
    "grid_chart.configure_axis(\n",
    "    labelFontSize=18,\n",
    "    titleFontSize=18,\n",
    ").configure_legend(\n",
    "    labelFontSize=18,\n",
    "    titleFontSize=18,\n",
    "    titleLimit=0\n",
    ").configure_header(\n",
    "    titleFontSize=18,\n",
    "    labelFontSize=18\n",
    ")\n",
    "grid_chart.save(\"notebooks/plots/heatmap_zero_shot_bar.png\")\n",
    "\n",
    "grid_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['gemma', 'gemma_chat', 'llama3', 'mistral', 'phi', 'round_robin',\n",
       "       'zephyr'], dtype=object)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>detector</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>electra_large_phi</td>\n",
       "      <td>0.961782</td>\n",
       "      <td>0.973659</td>\n",
       "      <td>0.949037</td>\n",
       "      <td>0.960694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>electra_large_gemma</td>\n",
       "      <td>0.961628</td>\n",
       "      <td>0.963032</td>\n",
       "      <td>0.960107</td>\n",
       "      <td>0.961369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>electra_large_round_robin</td>\n",
       "      <td>0.957071</td>\n",
       "      <td>0.950538</td>\n",
       "      <td>0.964544</td>\n",
       "      <td>0.957243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>roberta_large_phi</td>\n",
       "      <td>0.954543</td>\n",
       "      <td>0.937130</td>\n",
       "      <td>0.973597</td>\n",
       "      <td>0.954834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>electra_large_mistral</td>\n",
       "      <td>0.947887</td>\n",
       "      <td>0.924454</td>\n",
       "      <td>0.974840</td>\n",
       "      <td>0.948762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>roberta_large_round_robin</td>\n",
       "      <td>0.943282</td>\n",
       "      <td>0.919024</td>\n",
       "      <td>0.972170</td>\n",
       "      <td>0.944423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>roberta_large_gemma</td>\n",
       "      <td>0.941932</td>\n",
       "      <td>0.916227</td>\n",
       "      <td>0.972282</td>\n",
       "      <td>0.943109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>roberta_large_mistral</td>\n",
       "      <td>0.941863</td>\n",
       "      <td>0.915510</td>\n",
       "      <td>0.974700</td>\n",
       "      <td>0.943407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>distil_roberta-base_phi</td>\n",
       "      <td>0.941789</td>\n",
       "      <td>0.956639</td>\n",
       "      <td>0.925422</td>\n",
       "      <td>0.940294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>distil_roberta-base_mistral</td>\n",
       "      <td>0.941352</td>\n",
       "      <td>0.955859</td>\n",
       "      <td>0.925363</td>\n",
       "      <td>0.939687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>distil_roberta-base_gemma</td>\n",
       "      <td>0.937376</td>\n",
       "      <td>0.949844</td>\n",
       "      <td>0.923449</td>\n",
       "      <td>0.936103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>distil_roberta-base_round_robin</td>\n",
       "      <td>0.925452</td>\n",
       "      <td>0.907554</td>\n",
       "      <td>0.949032</td>\n",
       "      <td>0.927176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           detector  accuracy  precision    recall  f1_score\n",
       "6                 electra_large_phi  0.961782   0.973659  0.949037  0.960694\n",
       "4               electra_large_gemma  0.961628   0.963032  0.960107  0.961369\n",
       "7         electra_large_round_robin  0.957071   0.950538  0.964544  0.957243\n",
       "10                roberta_large_phi  0.954543   0.937130  0.973597  0.954834\n",
       "5             electra_large_mistral  0.947887   0.924454  0.974840  0.948762\n",
       "11        roberta_large_round_robin  0.943282   0.919024  0.972170  0.944423\n",
       "8               roberta_large_gemma  0.941932   0.916227  0.972282  0.943109\n",
       "9             roberta_large_mistral  0.941863   0.915510  0.974700  0.943407\n",
       "2           distil_roberta-base_phi  0.941789   0.956639  0.925422  0.940294\n",
       "1       distil_roberta-base_mistral  0.941352   0.955859  0.925363  0.939687\n",
       "0         distil_roberta-base_gemma  0.937376   0.949844  0.923449  0.936103\n",
       "3   distil_roberta-base_round_robin  0.925452   0.907554  0.949032  0.927176"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best detector\n",
    "\n",
    "# change type of accuracy, precision, recall, f1-score to float\n",
    "freeze_base_df[\"accuracy\"] = freeze_base_df[\"accuracy\"].astype(float)\n",
    "freeze_base_df[\"precision\"] = freeze_base_df[\"precision\"].astype(float)\n",
    "freeze_base_df[\"recall\"] = freeze_base_df[\"recall\"].astype(float)\n",
    "freeze_base_df[\"f1_score\"] = freeze_base_df[\"f1_score\"].astype(float)\n",
    "\n",
    "freeze_base_df_metrics = freeze_base_df[[\"accuracy\", \"precision\", \"recall\", \"f1_score\", \"detector\"]]\n",
    "\n",
    "# group by detector and compute the mean accuracy per detector\n",
    "freeze_base_df_metrics.groupby([\"detector\"]).mean().reset_index().sort_values(by=\"accuracy\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_detector</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>electra_large</td>\n",
       "      <td>0.957092</td>\n",
       "      <td>0.952921</td>\n",
       "      <td>0.962132</td>\n",
       "      <td>0.957017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>roberta_large</td>\n",
       "      <td>0.945405</td>\n",
       "      <td>0.921973</td>\n",
       "      <td>0.973187</td>\n",
       "      <td>0.946443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>distil_roberta-base</td>\n",
       "      <td>0.936492</td>\n",
       "      <td>0.942474</td>\n",
       "      <td>0.930817</td>\n",
       "      <td>0.935815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         base_detector  accuracy  precision    recall  f1_score\n",
       "1        electra_large  0.957092   0.952921  0.962132  0.957017\n",
       "2        roberta_large  0.945405   0.921973  0.973187  0.946443\n",
       "0  distil_roberta-base  0.936492   0.942474  0.930817  0.935815"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# base detector\n",
    "\n",
    "freeze_base_df_metrics = freeze_base_df[[\"accuracy\", \"precision\", \"recall\", \"f1_score\", \"base_detector\"]]\n",
    "\n",
    "# group by detector and compute the mean accuracy per detector\n",
    "freeze_base_df_metrics.groupby([\"base_detector\"]).mean().reset_index().sort_values(by=\"accuracy\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trained_on_dataset</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>phi</td>\n",
       "      <td>0.952705</td>\n",
       "      <td>0.955809</td>\n",
       "      <td>0.949352</td>\n",
       "      <td>0.951940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gemma</td>\n",
       "      <td>0.946979</td>\n",
       "      <td>0.943034</td>\n",
       "      <td>0.951946</td>\n",
       "      <td>0.946860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mistral</td>\n",
       "      <td>0.943701</td>\n",
       "      <td>0.931941</td>\n",
       "      <td>0.958301</td>\n",
       "      <td>0.943952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>round_robin</td>\n",
       "      <td>0.941935</td>\n",
       "      <td>0.925705</td>\n",
       "      <td>0.961915</td>\n",
       "      <td>0.942947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  trained_on_dataset  accuracy  precision    recall  f1_score\n",
       "2                phi  0.952705   0.955809  0.949352  0.951940\n",
       "0              gemma  0.946979   0.943034  0.951946  0.946860\n",
       "1            mistral  0.943701   0.931941  0.958301  0.943952\n",
       "3        round_robin  0.941935   0.925705  0.961915  0.942947"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best dataset to train on\n",
    "\n",
    "freeze_base_df_metrics= freeze_base_df[[\"accuracy\", \"precision\", \"recall\", \"f1_score\", \"trained_on_dataset\"]].copy()\n",
    "freeze_base_df_metrics.groupby([\"trained_on_dataset\"]).mean().reset_index().sort_values(by=\"accuracy\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>detector</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>roberta_large_phi</td>\n",
       "      <td>0.960365</td>\n",
       "      <td>0.941962</td>\n",
       "      <td>0.981262</td>\n",
       "      <td>0.961156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>electra_large_phi</td>\n",
       "      <td>0.960018</td>\n",
       "      <td>0.970159</td>\n",
       "      <td>0.949317</td>\n",
       "      <td>0.959208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>electra_large_round_robin</td>\n",
       "      <td>0.950937</td>\n",
       "      <td>0.943454</td>\n",
       "      <td>0.959467</td>\n",
       "      <td>0.951116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>roberta_large_round_robin</td>\n",
       "      <td>0.949373</td>\n",
       "      <td>0.931687</td>\n",
       "      <td>0.969955</td>\n",
       "      <td>0.950355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>electra_large_gemma</td>\n",
       "      <td>0.949170</td>\n",
       "      <td>0.957301</td>\n",
       "      <td>0.940354</td>\n",
       "      <td>0.948654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>electra_large_mistral</td>\n",
       "      <td>0.948881</td>\n",
       "      <td>0.930841</td>\n",
       "      <td>0.969896</td>\n",
       "      <td>0.949890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>roberta_large_mistral</td>\n",
       "      <td>0.947042</td>\n",
       "      <td>0.933182</td>\n",
       "      <td>0.963109</td>\n",
       "      <td>0.947779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>roberta_large_gemma</td>\n",
       "      <td>0.943025</td>\n",
       "      <td>0.925633</td>\n",
       "      <td>0.963602</td>\n",
       "      <td>0.944131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>distil_roberta-base_phi</td>\n",
       "      <td>0.935869</td>\n",
       "      <td>0.950208</td>\n",
       "      <td>0.920031</td>\n",
       "      <td>0.934594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>distil_roberta-base_mistral</td>\n",
       "      <td>0.921012</td>\n",
       "      <td>0.947841</td>\n",
       "      <td>0.891160</td>\n",
       "      <td>0.918248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>distil_roberta-base_gemma</td>\n",
       "      <td>0.919846</td>\n",
       "      <td>0.941302</td>\n",
       "      <td>0.895663</td>\n",
       "      <td>0.917714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>distil_roberta-base_round_robin</td>\n",
       "      <td>0.912708</td>\n",
       "      <td>0.892880</td>\n",
       "      <td>0.938119</td>\n",
       "      <td>0.914685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           detector  accuracy  precision    recall  f1_score\n",
       "10                roberta_large_phi  0.960365   0.941962  0.981262  0.961156\n",
       "6                 electra_large_phi  0.960018   0.970159  0.949317  0.959208\n",
       "7         electra_large_round_robin  0.950937   0.943454  0.959467  0.951116\n",
       "11        roberta_large_round_robin  0.949373   0.931687  0.969955  0.950355\n",
       "4               electra_large_gemma  0.949170   0.957301  0.940354  0.948654\n",
       "5             electra_large_mistral  0.948881   0.930841  0.969896  0.949890\n",
       "9             roberta_large_mistral  0.947042   0.933182  0.963109  0.947779\n",
       "8               roberta_large_gemma  0.943025   0.925633  0.963602  0.944131\n",
       "2           distil_roberta-base_phi  0.935869   0.950208  0.920031  0.934594\n",
       "1       distil_roberta-base_mistral  0.921012   0.947841  0.891160  0.918248\n",
       "0         distil_roberta-base_gemma  0.919846   0.941302  0.895663  0.917714\n",
       "3   distil_roberta-base_round_robin  0.912708   0.892880  0.938119  0.914685"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best detectors on chat models\n",
    "chat_models = [\"gemma_chat\", \"zephyr\", \"llama3\"]\n",
    "freeze_base_df_metrics_chat = freeze_base_df[[\"accuracy\", \"precision\", \"recall\", \"f1_score\", \"detector\", \"dataset\"]].copy()\n",
    "freeze_base_df_metrics_chat = freeze_base_df_metrics_chat[freeze_base_df_metrics_chat[\"dataset\"].isin(chat_models)]\n",
    "freeze_base_df_metrics_chat = freeze_base_df_metrics_chat[[\"accuracy\", \"precision\", \"recall\", \"f1_score\", \"detector\"]]\n",
    "freeze_base_df_metrics_chat.groupby([\"detector\"]).mean().reset_index().sort_values(by=\"accuracy\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>zephyr</td>\n",
       "      <td>0.931474</td>\n",
       "      <td>0.942404</td>\n",
       "      <td>0.919633</td>\n",
       "      <td>0.930277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gemma_chat</td>\n",
       "      <td>0.941336</td>\n",
       "      <td>0.936464</td>\n",
       "      <td>0.947515</td>\n",
       "      <td>0.941615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mistral</td>\n",
       "      <td>0.943558</td>\n",
       "      <td>0.935949</td>\n",
       "      <td>0.952718</td>\n",
       "      <td>0.943913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>round_robin</td>\n",
       "      <td>0.947610</td>\n",
       "      <td>0.945933</td>\n",
       "      <td>0.951881</td>\n",
       "      <td>0.946317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>llama3</td>\n",
       "      <td>0.951750</td>\n",
       "      <td>0.937745</td>\n",
       "      <td>0.968335</td>\n",
       "      <td>0.952491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gemma</td>\n",
       "      <td>0.952164</td>\n",
       "      <td>0.937208</td>\n",
       "      <td>0.969822</td>\n",
       "      <td>0.952960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phi</td>\n",
       "      <td>0.956415</td>\n",
       "      <td>0.938155</td>\n",
       "      <td>0.977747</td>\n",
       "      <td>0.957402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dataset  accuracy  precision    recall  f1_score\n",
       "6       zephyr  0.931474   0.942404  0.919633  0.930277\n",
       "1   gemma_chat  0.941336   0.936464  0.947515  0.941615\n",
       "3      mistral  0.943558   0.935949  0.952718  0.943913\n",
       "5  round_robin  0.947610   0.945933  0.951881  0.946317\n",
       "2       llama3  0.951750   0.937745  0.968335  0.952491\n",
       "0        gemma  0.952164   0.937208  0.969822  0.952960\n",
       "4          phi  0.956415   0.938155  0.977747  0.957402"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset where detectors struggle the most\n",
    "\n",
    "freeze_base_df_metrics = freeze_base_df[[\"accuracy\", \"precision\", \"recall\", \"f1_score\", \"dataset\"]].copy()\n",
    "freeze_base_df_metrics.groupby([\"dataset\"]).mean().reset_index().sort_values(by=\"accuracy\", ascending=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_detector",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
