{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_from_disk, Dataset, DatasetDict, concatenate_datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import wasserstein_distance\n",
    "\n",
    "\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label: true = 0, fake = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"gemma_10k\"\n",
    "fake_train_dataset_df = pd.read_json(f\"fake_true_datasets/fake_true_dataset_{experiment_name}_train.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Four groups that advocate for immigrant right...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Four groups that advocate for immigrant right...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Former Vice President Dick Cheney on Sunday d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Former Vice President Dick Cheney on Sunday d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Space shuttle Discovery launched just before ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15555</th>\n",
       "      <td>[South Africa pace bowler Dale Steyn ripped th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15556</th>\n",
       "      <td>[In a bustling room full of computers, giant w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15557</th>\n",
       "      <td>[In a bustling room full of computers, giant w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15558</th>\n",
       "      <td>[President Obama said Thursday that watching t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15559</th>\n",
       "      <td>[Pope Benedict XVI completed his eight-day tou...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15560 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0      [Four groups that advocate for immigrant right...      1\n",
       "1      [Four groups that advocate for immigrant right...      0\n",
       "2      [Former Vice President Dick Cheney on Sunday d...      1\n",
       "3      [Former Vice President Dick Cheney on Sunday d...      0\n",
       "4      [Space shuttle Discovery launched just before ...      0\n",
       "...                                                  ...    ...\n",
       "15555  [South Africa pace bowler Dale Steyn ripped th...      0\n",
       "15556  [In a bustling room full of computers, giant w...      1\n",
       "15557  [In a bustling room full of computers, giant w...      0\n",
       "15558  [President Obama said Thursday that watching t...      0\n",
       "15559  [Pope Benedict XVI completed his eight-day tou...      1\n",
       "\n",
       "[15560 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_train_dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Four groups that advocate for immigrant rights said Thursday they are suing the Trump administration over its new policy that blocks federal funding for legal representation to immigrants facing deportation. The groups, including the American Civil Liberties Union and the National Immigration Law Center, said they are filing a lawsuit in the U.S. District Court in Los Angeles. The lawsuit alleges that the Trump administration’s policy violates the 14th Amendment, which guarantees equal protectio'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_train_dataset_df.iloc[0][\"text\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_train_dataset_df[\"text_sentences\"] = fake_train_dataset_df[\"text\"].apply(lambda x: x[0].split(\".\"))\n",
    "\n",
    "fake_texts_df = fake_train_dataset_df[fake_train_dataset_df[\"label\"] == 1]\n",
    "true_texts_df = fake_train_dataset_df[fake_train_dataset_df[\"label\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Four groups that advocate for immigrant rights said Thursday they are suing the Trump administration over its new policy that blocks federal funding for legal representation to immigrants facing deportation',\n",
       " ' The groups, including the American Civil Liberties Union and the National Immigration Law Center, said they are filing a lawsuit in the U',\n",
       " 'S',\n",
       " ' District Court in Los Angeles',\n",
       " ' The lawsuit alleges that the Trump administration’s policy violates the 14th Amendment, which guarantees equal protectio']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_train_dataset_df[\"text_sentences\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of sentences in fake texts: 5.834340059118365\n",
      "Average number of sentences in true texts: 5.230492351201954\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average number of sentences in fake texts: {np.mean(fake_texts_df['text_sentences'].apply(len))}\")\n",
    "print(f\"Average number of sentences in true texts: {np.mean(true_texts_df['text_sentences'].apply(len))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of 'the' in fake texts: 6.550186351368719\n",
      "Average number of 'the' in true texts: 5.141149247975318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_152844/176004568.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fake_texts_df[\"the_count\"] = fake_texts_df[\"text\"].apply(lambda x: x[0].count(\"the\"))\n",
      "/tmp/ipykernel_152844/176004568.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  true_texts_df[\"the_count\"] = true_texts_df[\"text\"].apply(lambda x: x[0].count(\"the\"))\n"
     ]
    }
   ],
   "source": [
    "# add column: number of \"the\" in text\n",
    "fake_texts_df[\"the_count\"] = fake_texts_df[\"text\"].apply(lambda x: x[0].count(\"the\"))\n",
    "true_texts_df[\"the_count\"] = true_texts_df[\"text\"].apply(lambda x: x[0].count(\"the\"))\n",
    "\n",
    "print(f\"Average number of 'the' in fake texts: {np.mean(fake_texts_df['the_count'])}\")\n",
    "print(f\"Average number of 'the' in true texts: {np.mean(true_texts_df['the_count'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_train_dataset_full_text = \" \".join([text for text in fake_train_dataset_df[\"text\"].apply(lambda x: x[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7795559"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fake_train_dataset_full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run through all the texts and count occurence of each characters in unicode representation\n",
    "\n",
    "def count_chars(texts):\n",
    "    char_counts = {}\n",
    "    for text in texts:\n",
    "        for char in text:\n",
    "            if char in char_counts:\n",
    "                char_counts[char] += 1\n",
    "            else:\n",
    "                char_counts[char] = 1\n",
    "    return char_counts\n",
    "\n",
    "fake_char_counts = count_chars(fake_train_dataset_full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 1324564,\n",
       " 'e': 730749,\n",
       " 'a': 544007,\n",
       " 't': 502372,\n",
       " 'i': 441080,\n",
       " 'o': 439503,\n",
       " 'n': 434506,\n",
       " 'r': 385742,\n",
       " 's': 384450,\n",
       " 'h': 296529,\n",
       " 'd': 243353,\n",
       " 'l': 235028,\n",
       " 'c': 173397,\n",
       " 'u': 148387,\n",
       " 'm': 137884,\n",
       " 'f': 129327,\n",
       " 'g': 117094,\n",
       " 'p': 108261,\n",
       " 'w': 105319,\n",
       " 'y': 103132,\n",
       " 'b': 80649,\n",
       " ',': 72646,\n",
       " '.': 70525,\n",
       " 'v': 56267,\n",
       " 'k': 44836,\n",
       " 'T': 35619,\n",
       " 'S': 27170,\n",
       " 'A': 24461,\n",
       " '-': 23031,\n",
       " '\"': 20058,\n",
       " 'I': 19869,\n",
       " 'C': 19799,\n",
       " '0': 19684,\n",
       " \"'\": 18914,\n",
       " 'M': 17583,\n",
       " '1': 15139,\n",
       " 'B': 13677,\n",
       " 'P': 13363,\n",
       " '2': 12242,\n",
       " 'N': 11335,\n",
       " 'H': 11250,\n",
       " 'W': 10941,\n",
       " 'F': 10207,\n",
       " 'D': 9551,\n",
       " 'x': 9324,\n",
       " 'R': 8289,\n",
       " 'L': 7812,\n",
       " 'J': 7761,\n",
       " 'U': 7572,\n",
       " 'j': 7570,\n",
       " 'O': 7258,\n",
       " 'G': 7127,\n",
       " 'z': 6850,\n",
       " 'E': 5611,\n",
       " '3': 5411,\n",
       " '9': 5318,\n",
       " '5': 5106,\n",
       " 'K': 5070,\n",
       " 'q': 4692,\n",
       " '4': 4453,\n",
       " '<': 4300,\n",
       " '>': 4250,\n",
       " '’': 3795,\n",
       " '6': 3670,\n",
       " '7': 3608,\n",
       " '8': 3410,\n",
       " 'V': 2918,\n",
       " 'Y': 2529,\n",
       " '/': 2355,\n",
       " ':': 2270,\n",
       " '“': 2099,\n",
       " '”': 1680,\n",
       " '(': 1662,\n",
       " ')': 1607,\n",
       " '$': 1365,\n",
       " '?': 991,\n",
       " 'Z': 973,\n",
       " 'Q': 667,\n",
       " '*': 370,\n",
       " ';': 283,\n",
       " 'X': 260,\n",
       " '!': 252,\n",
       " '&': 169,\n",
       " '\\\\': 143,\n",
       " '[': 136,\n",
       " '%': 135,\n",
       " ']': 131,\n",
       " '{': 95,\n",
       " '}': 90,\n",
       " 'é': 76,\n",
       " '‘': 75,\n",
       " '£': 62,\n",
       " '•': 55,\n",
       " '–': 28,\n",
       " 'â': 22,\n",
       " '€': 21,\n",
       " '+': 19,\n",
       " 'á': 19,\n",
       " 'ñ': 19,\n",
       " '—': 18,\n",
       " '½': 14,\n",
       " '#': 14,\n",
       " '^': 13,\n",
       " '_': 13,\n",
       " '@': 11,\n",
       " 'ó': 11,\n",
       " 'ö': 11,\n",
       " '\\u200b': 11,\n",
       " '|': 11,\n",
       " 'í': 10,\n",
       " '»': 9,\n",
       " 'ä': 7,\n",
       " '°': 6,\n",
       " 'ã': 6,\n",
       " 'ü': 5,\n",
       " 'ú': 4,\n",
       " 'è': 4,\n",
       " '¥': 4,\n",
       " '↑': 4,\n",
       " '™': 3,\n",
       " 'ô': 3,\n",
       " '\\xad': 3,\n",
       " 'µ': 2,\n",
       " 'Á': 2,\n",
       " 'č': 2,\n",
       " 'ï': 2,\n",
       " 'ø': 2,\n",
       " 'Č': 1,\n",
       " 'ě': 1,\n",
       " 'ę': 1,\n",
       " 'ł': 1,\n",
       " '=': 1,\n",
       " 'à': 1,\n",
       " 'ć': 1,\n",
       " 'ë': 1,\n",
       " '®': 1,\n",
       " 'ž': 1,\n",
       " 'ș': 1,\n",
       " 'É': 1,\n",
       " '高': 1,\n",
       " '橋': 1,\n",
       " '秀': 1,\n",
       " '行': 1,\n",
       " 'å': 1,\n",
       " 'æ': 1,\n",
       " '￡': 1,\n",
       " '″': 1,\n",
       " 'ř': 1}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_char_counts_sorted = dict(sorted(fake_char_counts.items(), key=lambda item: item[1], reverse=True))\n",
    "fake_char_counts_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{32: 1324564,\n",
       " 101: 730749,\n",
       " 97: 544007,\n",
       " 116: 502372,\n",
       " 105: 441080,\n",
       " 111: 439503,\n",
       " 110: 434506,\n",
       " 114: 385742,\n",
       " 115: 384450,\n",
       " 104: 296529,\n",
       " 100: 243353,\n",
       " 108: 235028,\n",
       " 99: 173397,\n",
       " 117: 148387,\n",
       " 109: 137884,\n",
       " 102: 129327,\n",
       " 103: 117094,\n",
       " 112: 108261,\n",
       " 119: 105319,\n",
       " 121: 103132,\n",
       " 98: 80649,\n",
       " 44: 72646,\n",
       " 46: 70525,\n",
       " 118: 56267,\n",
       " 107: 44836,\n",
       " 84: 35619,\n",
       " 83: 27170,\n",
       " 65: 24461,\n",
       " 45: 23031,\n",
       " 34: 20058,\n",
       " 73: 19869,\n",
       " 67: 19799,\n",
       " 48: 19684,\n",
       " 39: 18914,\n",
       " 77: 17583,\n",
       " 49: 15139,\n",
       " 66: 13677,\n",
       " 80: 13363,\n",
       " 50: 12242,\n",
       " 78: 11335,\n",
       " 72: 11250,\n",
       " 87: 10941,\n",
       " 70: 10207,\n",
       " 68: 9551,\n",
       " 120: 9324,\n",
       " 82: 8289,\n",
       " 76: 7812,\n",
       " 74: 7761,\n",
       " 85: 7572,\n",
       " 106: 7570,\n",
       " 79: 7258,\n",
       " 71: 7127,\n",
       " 122: 6850,\n",
       " 69: 5611,\n",
       " 51: 5411,\n",
       " 57: 5318,\n",
       " 53: 5106,\n",
       " 75: 5070,\n",
       " 113: 4692,\n",
       " 52: 4453,\n",
       " 60: 4300,\n",
       " 62: 4250,\n",
       " 8217: 3795,\n",
       " 54: 3670,\n",
       " 55: 3608,\n",
       " 56: 3410,\n",
       " 86: 2918,\n",
       " 89: 2529,\n",
       " 47: 2355,\n",
       " 58: 2270,\n",
       " 8220: 2099,\n",
       " 8221: 1680,\n",
       " 40: 1662,\n",
       " 41: 1607,\n",
       " 36: 1365,\n",
       " 63: 991,\n",
       " 90: 973,\n",
       " 81: 667,\n",
       " 42: 370,\n",
       " 59: 283,\n",
       " 88: 260,\n",
       " 33: 252,\n",
       " 38: 169,\n",
       " 92: 143,\n",
       " 91: 136,\n",
       " 37: 135,\n",
       " 93: 131,\n",
       " 123: 95,\n",
       " 125: 90,\n",
       " 233: 76,\n",
       " 8216: 75,\n",
       " 163: 62,\n",
       " 8226: 55,\n",
       " 8211: 28,\n",
       " 226: 22,\n",
       " 8364: 21,\n",
       " 43: 19,\n",
       " 225: 19,\n",
       " 241: 19,\n",
       " 8212: 18,\n",
       " 189: 14,\n",
       " 35: 14,\n",
       " 94: 13,\n",
       " 95: 13,\n",
       " 64: 11,\n",
       " 243: 11,\n",
       " 246: 11,\n",
       " 8203: 11,\n",
       " 124: 11,\n",
       " 237: 10,\n",
       " 187: 9,\n",
       " 228: 7,\n",
       " 176: 6,\n",
       " 227: 6,\n",
       " 252: 5,\n",
       " 250: 4,\n",
       " 232: 4,\n",
       " 165: 4,\n",
       " 8593: 4,\n",
       " 8482: 3,\n",
       " 244: 3,\n",
       " 173: 3,\n",
       " 181: 2,\n",
       " 193: 2,\n",
       " 269: 2,\n",
       " 239: 2,\n",
       " 248: 2,\n",
       " 268: 1,\n",
       " 283: 1,\n",
       " 281: 1,\n",
       " 322: 1,\n",
       " 61: 1,\n",
       " 224: 1,\n",
       " 263: 1,\n",
       " 235: 1,\n",
       " 174: 1,\n",
       " 382: 1,\n",
       " 537: 1,\n",
       " 201: 1,\n",
       " 39640: 1,\n",
       " 27211: 1,\n",
       " 31168: 1,\n",
       " 34892: 1,\n",
       " 229: 1,\n",
       " 230: 1,\n",
       " 65505: 1,\n",
       " 8243: 1,\n",
       " 345: 1}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert keys in char_counts to unicode\n",
    "fake_char_counts_unicode = {ord(k): v for k, v in fake_char_counts_sorted.items()}\n",
    "fake_char_counts_unicode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'’': 3795,\n",
       " '“': 2099,\n",
       " '”': 1680,\n",
       " 'é': 76,\n",
       " '‘': 75,\n",
       " '£': 62,\n",
       " '•': 55,\n",
       " '–': 28,\n",
       " 'â': 22,\n",
       " '€': 21,\n",
       " 'á': 19,\n",
       " 'ñ': 19,\n",
       " '—': 18,\n",
       " '½': 14,\n",
       " 'ó': 11,\n",
       " 'ö': 11,\n",
       " '\\u200b': 11,\n",
       " 'í': 10,\n",
       " '»': 9,\n",
       " 'ä': 7,\n",
       " '°': 6,\n",
       " 'ã': 6,\n",
       " 'ü': 5,\n",
       " 'ú': 4,\n",
       " 'è': 4,\n",
       " '¥': 4,\n",
       " '↑': 4,\n",
       " '™': 3,\n",
       " 'ô': 3,\n",
       " '\\xad': 3,\n",
       " 'µ': 2,\n",
       " 'Á': 2,\n",
       " 'č': 2,\n",
       " 'ï': 2,\n",
       " 'ø': 2,\n",
       " 'Č': 1,\n",
       " 'ě': 1,\n",
       " 'ę': 1,\n",
       " 'ł': 1,\n",
       " 'à': 1,\n",
       " 'ć': 1,\n",
       " 'ë': 1,\n",
       " '®': 1,\n",
       " 'ž': 1,\n",
       " 'ș': 1,\n",
       " 'É': 1,\n",
       " '高': 1,\n",
       " '橋': 1,\n",
       " '秀': 1,\n",
       " '行': 1,\n",
       " 'å': 1,\n",
       " 'æ': 1,\n",
       " '￡': 1,\n",
       " '″': 1,\n",
       " 'ř': 1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exclude from count all ascii characters, ie. all keys above 128\n",
    "fake_char_counts_special = {k: v for k, v in fake_char_counts_sorted.items() if ord(k) > 128}\n",
    "fake_char_counts_special"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of normal apostrophes: 8252\n",
      "Number of special apostrophes: 3795\n"
     ]
    }
   ],
   "source": [
    "# count different kind of apostrophes\n",
    "count_apostrophe_type_1 = 0\n",
    "count_apostrophe_type_2 = 0\n",
    "\n",
    "# iterate over fake texts and count occurence of different apostrophes\n",
    "for text in fake_texts_df[\"text\"].apply(lambda x: x[0]):\n",
    "    count_apostrophe_type_1 += text.count(\"'\")\n",
    "    count_apostrophe_type_2 += text.count(\"’\")\n",
    "\n",
    "print(f\"Number of normal apostrophes: {count_apostrophe_type_1}\")\n",
    "print(f\"Number of special apostrophes: {count_apostrophe_type_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'—'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert form unicode to character\n",
    "chr(8212)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'–'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr(8211)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_detector",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
