{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_from_disk, Dataset, DatasetDict, concatenate_datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import wasserstein_distance\n",
    "\n",
    "\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label: true = 0, fake = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"phi_10k\"\n",
    "fake_train_dataset_df = pd.read_json(f\"fake_true_datasets/fake_true_dataset_{experiment_name}_train.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Four groups that advocate for immigrant right...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Four groups that advocate for immigrant right...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Former Vice President Dick Cheney on Sunday d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Former Vice President Dick Cheney on Sunday d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Space shuttle Discovery launched just before ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15717</th>\n",
       "      <td>[The Cyrus family is ready to rock and always ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15718</th>\n",
       "      <td>[The Cyrus family is ready to rock and always ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15719</th>\n",
       "      <td>[Over the past month, we've watched from dista...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15720</th>\n",
       "      <td>[Over the past month, we've watched from dista...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15721</th>\n",
       "      <td>[A Pablo Picasso sketchbook with 33 pencil dra...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15722 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0      [Four groups that advocate for immigrant right...      0\n",
       "1      [Four groups that advocate for immigrant right...      1\n",
       "2      [Former Vice President Dick Cheney on Sunday d...      1\n",
       "3      [Former Vice President Dick Cheney on Sunday d...      0\n",
       "4      [Space shuttle Discovery launched just before ...      0\n",
       "...                                                  ...    ...\n",
       "15717  [The Cyrus family is ready to rock and always ...      1\n",
       "15718  [The Cyrus family is ready to rock and always ...      0\n",
       "15719  [Over the past month, we've watched from dista...      1\n",
       "15720  [Over the past month, we've watched from dista...      0\n",
       "15721  [A Pablo Picasso sketchbook with 33 pencil dra...      1\n",
       "\n",
       "[15722 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_train_dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Four groups that advocate for immigrant rights said Thursday they will challenge Arizona\\'s new immigration law, which allows police to ask anyone for proof of legal U.S. residency. The Mexican American Legal Defense and Educational Fund, the American Civil Liberties Union, the ACLU of Arizona and the National Immigration Law Center held a news conference Thursday in Phoenix to announce the legal challenge. \"The Arizona community can be assured that a vigorous and sophisticated legal challenge wi'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_train_dataset_df.iloc[0][\"text\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_train_dataset_df[\"text_sentences\"] = fake_train_dataset_df[\"text\"].apply(lambda x: x[0].split(\".\"))\n",
    "\n",
    "fake_texts_df = fake_train_dataset_df[fake_train_dataset_df[\"label\"] == 1]\n",
    "true_texts_df = fake_train_dataset_df[fake_train_dataset_df[\"label\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Four groups that advocate for immigrant rights said Thursday they will challenge Arizona's new immigration law, which allows police to ask anyone for proof of legal U\",\n",
       " 'S',\n",
       " ' residency',\n",
       " ' The Mexican American Legal Defense and Educational Fund, the American Civil Liberties Union, the ACLU of Arizona and the National Immigration Law Center held a news conference Thursday in Phoenix to announce the legal challenge',\n",
       " ' \"The Arizona community can be assured that a vigorous and sophisticated legal challenge wi']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_train_dataset_df[\"text_sentences\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of sentences in fake texts: 5.479908443540183\n",
      "Average number of sentences in true texts: 5.238101298040214\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average number of sentences in fake texts: {np.mean(fake_texts_df['text_sentences'].apply(len))}\")\n",
    "print(f\"Average number of sentences in true texts: {np.mean(true_texts_df['text_sentences'].apply(len))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of 'the' in fake texts: 6.546286876907426\n",
      "Average number of 'the' in true texts: 5.1333672690251975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_153952/176004568.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fake_texts_df[\"the_count\"] = fake_texts_df[\"text\"].apply(lambda x: x[0].count(\"the\"))\n",
      "/tmp/ipykernel_153952/176004568.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  true_texts_df[\"the_count\"] = true_texts_df[\"text\"].apply(lambda x: x[0].count(\"the\"))\n"
     ]
    }
   ],
   "source": [
    "# add column: number of \"the\" in text\n",
    "fake_texts_df[\"the_count\"] = fake_texts_df[\"text\"].apply(lambda x: x[0].count(\"the\"))\n",
    "true_texts_df[\"the_count\"] = true_texts_df[\"text\"].apply(lambda x: x[0].count(\"the\"))\n",
    "\n",
    "print(f\"Average number of 'the' in fake texts: {np.mean(fake_texts_df['the_count'])}\")\n",
    "print(f\"Average number of 'the' in true texts: {np.mean(true_texts_df['the_count'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_train_dataset_full_text = \" \".join([text for text in fake_train_dataset_df[\"text\"].apply(lambda x: x[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7876721"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fake_train_dataset_full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run through all the texts and count occurence of each characters in unicode representation\n",
    "\n",
    "def count_chars(texts):\n",
    "    char_counts = {}\n",
    "    for text in texts:\n",
    "        for char in text:\n",
    "            if char in char_counts:\n",
    "                char_counts[char] += 1\n",
    "            else:\n",
    "                char_counts[char] = 1\n",
    "    return char_counts\n",
    "\n",
    "fake_char_counts = count_chars(fake_train_dataset_full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 1339973,\n",
       " 'e': 744005,\n",
       " 'a': 549388,\n",
       " 't': 517748,\n",
       " 'i': 451459,\n",
       " 'o': 447215,\n",
       " 'n': 444813,\n",
       " 's': 393300,\n",
       " 'r': 391136,\n",
       " 'h': 301428,\n",
       " 'd': 243676,\n",
       " 'l': 240133,\n",
       " 'c': 182298,\n",
       " 'u': 154220,\n",
       " 'm': 139909,\n",
       " 'f': 132473,\n",
       " 'g': 119184,\n",
       " 'p': 112705,\n",
       " 'w': 104346,\n",
       " 'y': 103395,\n",
       " 'b': 82524,\n",
       " ',': 71625,\n",
       " '.': 68533,\n",
       " 'v': 58538,\n",
       " 'k': 45139,\n",
       " 'T': 34206,\n",
       " 'S': 25665,\n",
       " 'A': 24519,\n",
       " '-': 19558,\n",
       " 'I': 18898,\n",
       " 'C': 18644,\n",
       " '\"': 18453,\n",
       " \"'\": 18003,\n",
       " '0': 16648,\n",
       " 'M': 15816,\n",
       " 'B': 13079,\n",
       " 'P': 12450,\n",
       " '1': 11122,\n",
       " 'N': 10992,\n",
       " 'H': 10716,\n",
       " 'W': 10163,\n",
       " 'x': 10057,\n",
       " 'F': 9919,\n",
       " '2': 9057,\n",
       " 'D': 9014,\n",
       " 'U': 8186,\n",
       " 'j': 7790,\n",
       " 'R': 7615,\n",
       " 'O': 7101,\n",
       " 'J': 6893,\n",
       " 'L': 6883,\n",
       " 'z': 6728,\n",
       " 'G': 6427,\n",
       " 'E': 5438,\n",
       " 'q': 4854,\n",
       " 'K': 4627,\n",
       " '9': 4076,\n",
       " '5': 4013,\n",
       " '3': 3845,\n",
       " '’': 3548,\n",
       " '4': 3135,\n",
       " '8': 2804,\n",
       " '7': 2797,\n",
       " '6': 2769,\n",
       " 'V': 2739,\n",
       " 'Y': 2271,\n",
       " ':': 2105,\n",
       " '“': 1964,\n",
       " '(': 1786,\n",
       " ')': 1746,\n",
       " '”': 1588,\n",
       " '$': 1502,\n",
       " '?': 1203,\n",
       " 'Z': 911,\n",
       " 'Q': 649,\n",
       " ';': 264,\n",
       " '/': 257,\n",
       " 'X': 221,\n",
       " '!': 212,\n",
       " '&': 171,\n",
       " '%': 155,\n",
       " '–': 134,\n",
       " '[': 106,\n",
       " ']': 100,\n",
       " 'é': 99,\n",
       " '#': 91,\n",
       " '*': 86,\n",
       " '£': 85,\n",
       " '—': 50,\n",
       " '•': 50,\n",
       " '‘': 48,\n",
       " '=': 46,\n",
       " '|': 35,\n",
       " 'ó': 34,\n",
       " 'á': 33,\n",
       " '€': 25,\n",
       " 'ñ': 22,\n",
       " '½': 17,\n",
       " 'í': 17,\n",
       " '<': 16,\n",
       " '>': 16,\n",
       " '_': 16,\n",
       " '»': 13,\n",
       " '+': 12,\n",
       " 'ü': 11,\n",
       " 'ã': 10,\n",
       " 'ö': 8,\n",
       " 'ä': 8,\n",
       " '@': 7,\n",
       " '°': 7,\n",
       " 'è': 7,\n",
       " 'ć': 7,\n",
       " 'Á': 7,\n",
       " 'ç': 4,\n",
       " 'à': 4,\n",
       " 'ð': 4,\n",
       " 'ë': 4,\n",
       " '…': 4,\n",
       " 'ō': 4,\n",
       " '\\xad': 3,\n",
       " 'É': 3,\n",
       " 'ú': 3,\n",
       " '{': 3,\n",
       " 'ŏ': 3,\n",
       " '^': 2,\n",
       " 'â': 2,\n",
       " 'ń': 2,\n",
       " 'ư': 2,\n",
       " 'ờ': 2,\n",
       " 'ï': 2,\n",
       " 'ž': 2,\n",
       " '¥': 2,\n",
       " 'ô': 1,\n",
       " 'Č': 1,\n",
       " 'æ': 1,\n",
       " 'î': 1,\n",
       " '\\\\': 1,\n",
       " 'Þ': 1,\n",
       " '®': 1,\n",
       " 'Ó': 1,\n",
       " '春': 1,\n",
       " '日': 1,\n",
       " '昭': 1,\n",
       " '和': 1,\n",
       " '平': 1,\n",
       " '成': 1,\n",
       " 'ý': 1,\n",
       " 'š': 1,\n",
       " 'ě': 1,\n",
       " 'ğ': 1,\n",
       " 'Ł': 1,\n",
       " '₨': 1,\n",
       " '¡': 1,\n",
       " 'ø': 1,\n",
       " 'å': 1,\n",
       " '}': 1,\n",
       " 'ş': 1,\n",
       " 'ă': 1,\n",
       " 'ţ': 1,\n",
       " 'ê': 1}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_char_counts_sorted = dict(sorted(fake_char_counts.items(), key=lambda item: item[1], reverse=True))\n",
    "fake_char_counts_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{32: 1339973,\n",
       " 101: 744005,\n",
       " 97: 549388,\n",
       " 116: 517748,\n",
       " 105: 451459,\n",
       " 111: 447215,\n",
       " 110: 444813,\n",
       " 115: 393300,\n",
       " 114: 391136,\n",
       " 104: 301428,\n",
       " 100: 243676,\n",
       " 108: 240133,\n",
       " 99: 182298,\n",
       " 117: 154220,\n",
       " 109: 139909,\n",
       " 102: 132473,\n",
       " 103: 119184,\n",
       " 112: 112705,\n",
       " 119: 104346,\n",
       " 121: 103395,\n",
       " 98: 82524,\n",
       " 44: 71625,\n",
       " 46: 68533,\n",
       " 118: 58538,\n",
       " 107: 45139,\n",
       " 84: 34206,\n",
       " 83: 25665,\n",
       " 65: 24519,\n",
       " 45: 19558,\n",
       " 73: 18898,\n",
       " 67: 18644,\n",
       " 34: 18453,\n",
       " 39: 18003,\n",
       " 48: 16648,\n",
       " 77: 15816,\n",
       " 66: 13079,\n",
       " 80: 12450,\n",
       " 49: 11122,\n",
       " 78: 10992,\n",
       " 72: 10716,\n",
       " 87: 10163,\n",
       " 120: 10057,\n",
       " 70: 9919,\n",
       " 50: 9057,\n",
       " 68: 9014,\n",
       " 85: 8186,\n",
       " 106: 7790,\n",
       " 82: 7615,\n",
       " 79: 7101,\n",
       " 74: 6893,\n",
       " 76: 6883,\n",
       " 122: 6728,\n",
       " 71: 6427,\n",
       " 69: 5438,\n",
       " 113: 4854,\n",
       " 75: 4627,\n",
       " 57: 4076,\n",
       " 53: 4013,\n",
       " 51: 3845,\n",
       " 8217: 3548,\n",
       " 52: 3135,\n",
       " 56: 2804,\n",
       " 55: 2797,\n",
       " 54: 2769,\n",
       " 86: 2739,\n",
       " 89: 2271,\n",
       " 58: 2105,\n",
       " 8220: 1964,\n",
       " 40: 1786,\n",
       " 41: 1746,\n",
       " 8221: 1588,\n",
       " 36: 1502,\n",
       " 63: 1203,\n",
       " 90: 911,\n",
       " 81: 649,\n",
       " 59: 264,\n",
       " 47: 257,\n",
       " 88: 221,\n",
       " 33: 212,\n",
       " 38: 171,\n",
       " 37: 155,\n",
       " 8211: 134,\n",
       " 91: 106,\n",
       " 93: 100,\n",
       " 233: 99,\n",
       " 35: 91,\n",
       " 42: 86,\n",
       " 163: 85,\n",
       " 8212: 50,\n",
       " 8226: 50,\n",
       " 8216: 48,\n",
       " 61: 46,\n",
       " 124: 35,\n",
       " 243: 34,\n",
       " 225: 33,\n",
       " 8364: 25,\n",
       " 241: 22,\n",
       " 189: 17,\n",
       " 237: 17,\n",
       " 60: 16,\n",
       " 62: 16,\n",
       " 95: 16,\n",
       " 187: 13,\n",
       " 43: 12,\n",
       " 252: 11,\n",
       " 227: 10,\n",
       " 246: 8,\n",
       " 228: 8,\n",
       " 64: 7,\n",
       " 176: 7,\n",
       " 232: 7,\n",
       " 263: 7,\n",
       " 193: 7,\n",
       " 231: 4,\n",
       " 224: 4,\n",
       " 240: 4,\n",
       " 235: 4,\n",
       " 8230: 4,\n",
       " 333: 4,\n",
       " 173: 3,\n",
       " 201: 3,\n",
       " 250: 3,\n",
       " 123: 3,\n",
       " 335: 3,\n",
       " 94: 2,\n",
       " 226: 2,\n",
       " 324: 2,\n",
       " 432: 2,\n",
       " 7901: 2,\n",
       " 239: 2,\n",
       " 382: 2,\n",
       " 165: 2,\n",
       " 244: 1,\n",
       " 268: 1,\n",
       " 230: 1,\n",
       " 238: 1,\n",
       " 92: 1,\n",
       " 222: 1,\n",
       " 174: 1,\n",
       " 211: 1,\n",
       " 26149: 1,\n",
       " 26085: 1,\n",
       " 26157: 1,\n",
       " 21644: 1,\n",
       " 24179: 1,\n",
       " 25104: 1,\n",
       " 253: 1,\n",
       " 353: 1,\n",
       " 283: 1,\n",
       " 287: 1,\n",
       " 321: 1,\n",
       " 8360: 1,\n",
       " 161: 1,\n",
       " 248: 1,\n",
       " 229: 1,\n",
       " 125: 1,\n",
       " 351: 1,\n",
       " 259: 1,\n",
       " 355: 1,\n",
       " 234: 1}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert keys in char_counts to unicode\n",
    "fake_char_counts_unicode = {ord(k): v for k, v in fake_char_counts_sorted.items()}\n",
    "fake_char_counts_unicode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'’': 3548,\n",
       " '“': 1964,\n",
       " '”': 1588,\n",
       " '–': 134,\n",
       " 'é': 99,\n",
       " '£': 85,\n",
       " '—': 50,\n",
       " '•': 50,\n",
       " '‘': 48,\n",
       " 'ó': 34,\n",
       " 'á': 33,\n",
       " '€': 25,\n",
       " 'ñ': 22,\n",
       " '½': 17,\n",
       " 'í': 17,\n",
       " '»': 13,\n",
       " 'ü': 11,\n",
       " 'ã': 10,\n",
       " 'ö': 8,\n",
       " 'ä': 8,\n",
       " '°': 7,\n",
       " 'è': 7,\n",
       " 'ć': 7,\n",
       " 'Á': 7,\n",
       " 'ç': 4,\n",
       " 'à': 4,\n",
       " 'ð': 4,\n",
       " 'ë': 4,\n",
       " '…': 4,\n",
       " 'ō': 4,\n",
       " '\\xad': 3,\n",
       " 'É': 3,\n",
       " 'ú': 3,\n",
       " 'ŏ': 3,\n",
       " 'â': 2,\n",
       " 'ń': 2,\n",
       " 'ư': 2,\n",
       " 'ờ': 2,\n",
       " 'ï': 2,\n",
       " 'ž': 2,\n",
       " '¥': 2,\n",
       " 'ô': 1,\n",
       " 'Č': 1,\n",
       " 'æ': 1,\n",
       " 'î': 1,\n",
       " 'Þ': 1,\n",
       " '®': 1,\n",
       " 'Ó': 1,\n",
       " '春': 1,\n",
       " '日': 1,\n",
       " '昭': 1,\n",
       " '和': 1,\n",
       " '平': 1,\n",
       " '成': 1,\n",
       " 'ý': 1,\n",
       " 'š': 1,\n",
       " 'ě': 1,\n",
       " 'ğ': 1,\n",
       " 'Ł': 1,\n",
       " '₨': 1,\n",
       " '¡': 1,\n",
       " 'ø': 1,\n",
       " 'å': 1,\n",
       " 'ş': 1,\n",
       " 'ă': 1,\n",
       " 'ţ': 1,\n",
       " 'ê': 1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exclude from count all ascii characters, ie. all keys above 128\n",
    "fake_char_counts_special = {k: v for k, v in fake_char_counts_sorted.items() if ord(k) > 128}\n",
    "fake_char_counts_special"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of normal apostrophes: 7234\n",
      "Number of special apostrophes: 3548\n"
     ]
    }
   ],
   "source": [
    "# count different kind of apostrophes\n",
    "count_apostrophe_type_1 = 0\n",
    "count_apostrophe_type_2 = 0\n",
    "\n",
    "# iterate over fake texts and count occurence of different apostrophes\n",
    "for text in fake_texts_df[\"text\"].apply(lambda x: x[0]):\n",
    "    count_apostrophe_type_1 += text.count(\"'\")\n",
    "    count_apostrophe_type_2 += text.count(\"’\")\n",
    "\n",
    "print(f\"Number of normal apostrophes: {count_apostrophe_type_1}\")\n",
    "print(f\"Number of special apostrophes: {count_apostrophe_type_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'—'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert form unicode to character\n",
    "chr(8212)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'–'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr(8211)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_detector",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
