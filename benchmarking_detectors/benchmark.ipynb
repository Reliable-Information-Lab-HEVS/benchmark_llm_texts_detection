{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/marluxiaboss/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/marluxiaboss/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/marluxiaboss/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from datasets import concatenate_datasets, load_from_disk, DatasetDict\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import nltk.data\n",
    "nltk.download('punkt')\n",
    "from transformers import (AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForMaskedLM, AutoModelForCausalLM,\n",
    "                          ElectraForSequenceClassification, ElectraTokenizer, AutoConfig)\n",
    "from datasets import load_from_disk, concatenate_datasets, Dataset\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "from evasion_attack import PromptParaphrasingAttack, PromptAttack, GenParamsAttack\n",
    "from utils import ModelConfig, PromptConfig\n",
    "from generator import LLMGenerator\n",
    "from detector import Detector, BertDetector\n",
    "from fast_detect_gpt import FastDetectGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set generation parameters\n",
    "default_gen_params = {\n",
    "    #\"max_length\": 100,\n",
    "    \"max_new_tokens\": 100,\n",
    "    \"min_new_tokens\": 100,\n",
    "    \"temperature\": 0.8,\n",
    "    \"top_p\": 0.95,\n",
    "    \"repetition_penalty\": 1,\n",
    "    \"do_sample\": True,\n",
    "    \"top_k\": 50\n",
    "}\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marluxiaboss/anaconda3/envs/llm_detector/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/home/marluxiaboss/anaconda3/envs/llm_detector/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[' Many people argue that cats are simply more independent and independent in their behavior compared to dogs because they are more agile and agile than dogs. Cats can easily run and jump over obstacles while dogs are typically slower and more likely to get into trouble. Additionally, cats are often more social than dogs. This is why they are often the better option for humans. However, it is important to note that this argument is not based on any scientific evidence or studies. Additionally, it is important to note that it is',\n",
       " \" Dogs and cats are both great pets but dogs are generally considered to be more reliable and loyal. They have better physical abilities, such as running longer distances and being more alert and focused than cats. Additionally, dogs are known to be more intelligent than cats and have been shown to be more docile and trainable. However, there are some differences in their personalities and behaviors, and it's important to take into account the specific needs and preferences of the person or family member adopting the dog. Ultimately, the\",\n",
       " \" Cats are better than dogs because they are more independent and can handle certain tasks on their own, while dogs are more social and require less attention. While it's true that cats are more independent and may need more space and attention than dogs, they can also be more playful and social. It's worth noting that cats and dogs are both pets and can be trained to behave in certain ways. For example, some people believe that dogs are more independent and can handle certain tasks on their own, while others\",\n",
       " \" Dogs can lead to better behavior in dogs, including improved obedience and loyalty. They are trained with positive reinforcement, which leads to a greater willingness to perform certain tasks, such as retrieving toys, than dogs trained with negative reinforcement. Furthermore, the study found that dogs who were trained with positive reinforcement were more likely to exhibit positive behavior in various situations, such as when they were approached by strangers. This suggests that dogs are better than cats in some ways, but it's important to note that all dogs are\",\n",
       " ' Cats are generally considered superior because they are generally more social animals. Their social interaction is often seen as a defining feature of their breed, and their closeness to their companions is a hallmark of their loyalty. In contrast, dogs are generally considered inferior because they are more independent animals and their social interaction is often seen as a hindrance. The debate about whether cats are better or worse than dogs is a matter of opinion and personal preference. Ultimately, it is up to each individual to weigh the benefits and']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paraphraser_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"Qwen/Qwen2-0.5B-Instruct\",\n",
    "    pad_token='<|extra_0|>',\n",
    "    eos_token='<|endoftext|>',\n",
    "    padding_side='left',\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "paraphraser = AutoModelForCausalLM.from_pretrained(\n",
    "    \"Qwen/Qwen2-0.5B-Instruct\",\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\",\n",
    "    pad_token_id=paraphraser_tokenizer.pad_token_id,\n",
    ").to(device)\n",
    "\n",
    "\n",
    "paraphraser_config = ModelConfig(paraphraser_tokenizer,\n",
    "    use_chat_template=True, chat_template_type=\"system_user\", gen_params=default_gen_params, device=device)\n",
    "paraphraser_model = LLMGenerator(paraphraser, paraphraser_config)\n",
    "\n",
    "gen_model = paraphraser_model\n",
    "gen_tokenizer = paraphraser_tokenizer\n",
    "gen_config = paraphraser_config\n",
    "\n",
    "\n",
    "dataset_list = [\"Why are cats better than dogs\", \"Why are dogs better than cats\", \"Why are cats better than dogs\",\n",
    "                \"Why are dogs better than cats\", \"Why are cats better than dogs\"]\n",
    "\n",
    "system_paraphrasing_prompt = \"\"\"You are a paraphraser. You are given an input passage ‘INPUT’. You should paraphrase ‘INPUT’ to print ‘OUTPUT’.\"\n",
    "    \"‘OUTPUT’ shoud be diverse and different as much as possible from ‘INPUT’ and should not copy any part verbatim from ‘INPUT’.\"\n",
    "    \"‘OUTPUT’ should preserve the meaning and content of ’INPUT’ while maintaining text quality and grammar.\"\n",
    "    \"‘OUTPUT’ should not be much longer than ‘INPUT’. You should print ‘OUTPUT’ and nothing else so that its easy for me to parse.\"\"\"\n",
    "user_paraphrasing_prompt = \"INPUT:\"\n",
    "paraphraser_prompt_config = PromptConfig(system_prompt=system_paraphrasing_prompt, user_prompt=\"\")\n",
    "\n",
    "\n",
    "gen_prompt = \"You are a helpful assistant.\"\n",
    "user_prompt = \"Write a news article starting with:\"\n",
    "gen_prompt_config = PromptConfig(system_prompt=gen_prompt, user_prompt=user_prompt)\n",
    "\n",
    "prompt_paraphrasing_attack = PromptParaphrasingAttack(gen_model, gen_config, gen_prompt_config, paraphraser_model, paraphraser_config, paraphraser_prompt_config)\n",
    "paraphrased_fake_articles = prompt_paraphrasing_attack.generate_adversarial_text(dataset_list, batch_size=2)\n",
    "\n",
    "paraphrased_fake_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Why are cats better than dogs ?\\nThe question of whether cats are better than dogs is a topic that has been debated for centuries. While both animals are intelligent and capable of achieving success in various pursuits, there are several factors that could explain why cats are often considered more well-adjusted and intelligent than dogs. \\nOne reason that cats may outperform dogs in certain tasks is that they are often social and have a natural inclination towards nurturing and caring for others. Dogs, on the other hand, are often social animals that are more independent',\n",
       " 'Why are dogs better than cats ?\\nIn many households, dogs are the most commonly owned pets, but they are also beloved companions for many families. While cats may be a smaller pet, they offer a unique way to bond with humans and provide a loyal and affectionate friend.\\nAccording to a recent study published in the journal Nature, dogs are more social animals than cats and are known for their loyalty and intelligence. The study found that dogs can detect and respond to the presence of humans, which is a unique trait that many people find']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adversarial_system_prompt = \"You are a helpful assistant.\"\n",
    "advesarial_user_prompt = \"Write a news article in the CNN news article style starting with:\"\n",
    "adversarial_prompt_config = PromptConfig(system_prompt=adversarial_system_prompt, user_prompt=advesarial_user_prompt)\n",
    "\n",
    "prompt_attack = PromptAttack(gen_model, gen_config, gen_prompt_config, adversarial_prompt_config)\n",
    "prompt_attack_fake_articles = prompt_attack.generate_adversarial_text(dataset_list, batch_size=2)\n",
    "prompt_attack_fake_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Why are cats better than dogs ?\\nThe topic of cats being more intelligent and affectionate than dogs is a widely debated subject, with different opinions within the media, scientists, and among pet owners themselves. Some argue that cats are superior, as they are capable of better cognitive functions and possess unique personality traits. Others believe that dogs are more capable and docile.\\nRegardless of one's perspective, research has consistently shown that cats excel in certain tasks and interactions with their owners, and that they possess a keen sense of smell, a keen\",\n",
       " 'Why are dogs better than cats ?\\nThere are many reasons why dogs are often considered to be superior to cats. However, one key factor that stands out is their exceptional ability to sense their surroundings and react appropriately. In general, dogs are more alert and responsive to their environment, which means they are able to adapt to a wide range of situations quickly and effectively.\\nFurthermore, dogs are known for their ability to learn new skills and behaviors quickly, which is one of their primary advantages over cats. As a result, dogs are often more']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adversarial_gen_param = {\n",
    "    \"temperature\": 1.2\n",
    "}\n",
    "\n",
    "gen_parameters_attack = GenParamsAttack(gen_model, gen_config, gen_prompt_config, adversarial_gen_param)\n",
    "gen_parameters_fake_articles = gen_parameters_attack.generate_adversarial_text(dataset_list, batch_size=2)\n",
    "gen_parameters_fake_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Why are cats better than dogs ... It all begins now as The \"Alo !!g \" breeds one and every once and every another discovers we must take that leap that only some things do (it says...) In an experiment known to lovers there, scientists find it takes three bites rather just... A couple dogs decide between finding themselves cats instead, just a new way at trying and it happens, right? We then found and had found one in which, this morning The little brown one comes for it A dog named Jodie decides',\n",
       " \"Why are dogs better than cats  when coming from animal福利? Why and Can. When one breeds or socialize to another?\\nThis is one reason dog owners have long debated: While both of species excel in all physical behaviors: Intelligence vs Motion Dog Behavior The research shows:\\nMost experts, if all of breed's qualities were transferred as their ability towards social relationships would greatly evolve from breed A dog may learn tricks well if bred A because those that grew the best with human beings trained at dogs' level are generally higher social competence skills\"]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adversarial_gen_param = {\n",
    "    \"temperature\": 10.0\n",
    "}\n",
    "\n",
    "gen_parameters_attack = GenParamsAttack(gen_model, gen_config, gen_prompt_config, adversarial_gen_param)\n",
    "gen_parameters_fake_articles = gen_parameters_attack.generate_adversarial_text(dataset_list, batch_size=2)\n",
    "gen_parameters_fake_articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marluxiaboss/anaconda3/envs/llm_detector/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ElectraForSequenceClassification(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 1024)\n",
       "      (token_type_embeddings): Embedding(2, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): ElectraClassificationHead(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (activation): GELUActivation()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=1024, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "detector_path = \"google/electra-large-discriminator\"\n",
    "config = AutoConfig.from_pretrained(detector_path)\n",
    "detector_model = ElectraForSequenceClassification(config)\n",
    "bert_tokenizer = ElectraTokenizer.from_pretrained(detector_path)\n",
    "\n",
    "model_path = \"../saved_training_logs_experiment_2/electra_large/full_finetuning/fake_true_dataset_round_robin_10k/10_06_1308/saved_models/best_model.pt\"\n",
    "detector_model.load_state_dict(torch.load(model_path))\n",
    "detector_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'detector_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_489345/579843562.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtext_to_detect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"I am AI generated text\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"I am human generated text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdetector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertDetector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetector_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_to_detect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetection_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'detector_model' is not defined"
     ]
    }
   ],
   "source": [
    "text_to_detect = [\"I am AI generated text\", \"I am human generated text\"]\n",
    "detector = BertDetector(detector_model, bert_tokenizer, device)\n",
    "preds, logits = detector.detect(text_to_detect, detection_threshold=0.5, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 0], [0.14659571647644043, -0.6974161863327026])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds, logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fast-DetectGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marluxiaboss/anaconda3/envs/llm_detector/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "ref_model_path = \"openai-community/gpt2\"\n",
    "ref_model = AutoModelForCausalLM.from_pretrained(ref_model_path, torch_dtype=\"auto\").to(device)\n",
    "ref_tokenizer = AutoTokenizer.from_pretrained(ref_model_path, trust_remote_code=True, padding_side=\"left\")\n",
    "\n",
    "# special for gpt2\n",
    "ref_tokenizer.pad_token = ref_tokenizer.eos_token\n",
    "ref_tokenizer.padding_side = 'left'\n",
    "\n",
    "scoring_model = ref_model\n",
    "scoring_tokenizer = ref_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_492861/3717592639.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"I am AI generated text\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"I am human generated text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfast_detector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/llm_text_detector/new_repo/benchmark_ai_news_detection/benchmarking_detectors/fast_detect_gpt.py\u001b[0m in \u001b[0;36mdetect\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;31m#name = \"sampling_discrepancy_analytic\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mcriterion_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_sampling_discrepancy_analytic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mprob_estimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProbEstimatorFastDetectGPT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mref_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/llm_text_detector/new_repo/benchmark_ai_news_detection/benchmarking_detectors/fast_detect_gpt.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, ref_path)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal_crits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfake_crits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mresult_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'*.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "fast_detector = FastDetectGPT(ref_model, scoring_model, ref_tokenizer, scoring_tokenizer, device)\n",
    "\n",
    "texts = [\"I am AI generated text\", \"I am human generated text\"]\n",
    "preds, probs = fast_detector.detect(texts)\n",
    "preds, probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0ce5de16deb4b74b4e48781e4013c87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of data discarded after removing duplicate article: 0.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ea3164822254286b164bd043d789545",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d35b72ab8e4c44f6ba6e1b57cb960908",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a87939a3af84da7845ec2e18517a143",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 1600\n",
      "Eval size: 200\n",
      "Test size: 200\n"
     ]
    }
   ],
   "source": [
    "from cnn_dataset import CNNDataLoader\n",
    "\n",
    "dataset_size = 1000\n",
    "processed_cnn_dataset = CNNDataLoader(dataset_size).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'article', 'prefix'],\n",
       "        num_rows: 1600\n",
       "    })\n",
       "    eval: Dataset({\n",
       "        features: ['label', 'article', 'prefix'],\n",
       "        num_rows: 200\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'article', 'prefix'],\n",
       "        num_rows: 200\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_cnn_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 1,\n",
       " 'article': '',\n",
       " 'prefix': 'Three members of the same family who died in a'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_cnn_dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article processed:\n",
      "\n",
      "--------------------\n",
      "\n",
      "\n",
      "Article processed:\n",
      "Three members of the same family who died in a static caravan from carbon monoxide poisoning would have been unconscious 'within minutes', investigators said today. The bodies of married couple John and Audrey Cook were discovered alongside their daughter, Maureen, at the mobile home they shared on Tremarle Home Park in Camborne, west Cornwall. The inquests have now opened into the deaths last Saturday, with investigators saying the three died along with the family's pet dog, of carbon monoxide \n",
      "--------------------\n",
      "\n",
      "\n",
      "Article processed:\n",
      "A rare meeting of U.N. Security Council heads of state, led for the first time by a U.S. president, adopted a resolution focused on stopping the spread of nuclear weapons Thursday. President Obama is the first U.S. leader to head a United Nations Security Council meeting. President Obama challenged the gathering -- which included leaders of nuclear powers including Russia, China, Great Britain and France -- to overcome cynicism against the goal of ridding the planet of nuclear arms. \"We harbor n\n",
      "--------------------\n",
      "\n",
      "\n",
      "Article processed:\n",
      "\n",
      "--------------------\n",
      "\n",
      "\n",
      "Article processed:\n",
      "\n",
      "--------------------\n",
      "\n",
      "\n",
      "Article processed:\n",
      "Cover-up: Former Archbishop Lord Hope allowed a paedophile priest to escape punishment for sex crimes, a judge's report claims . A former archbishop who failed to act on alleged crimes of a paedophile priest should be jailed, the abuser’s victims have said. Lord Hope, the former Archbishop of York, did not act on 19 occasions when allegations of abuse or inappropriate conduct by the priest were raised with him, a scathing report revealed yesterday. But despite that, Lord Hope remains as an honor\n",
      "--------------------\n",
      "\n",
      "\n",
      "Article processed:\n",
      "\n",
      "--------------------\n",
      "\n",
      "\n",
      "Article processed:\n",
      "TLC has pulled an episode of Cake Boss from future screening schedules after receiving complaints over the show's mishandling of a transgender guest star. The episode, which aired on Monday night, showed transgender Carmen Carerra, 27, who was born as a man, take part in a stunt that she believed was edited to look distasteful. The stunt involved Buddy 'Cake Boss' Valastro, the reality show's star, tricking Anthony 'Cousin Anthony' Bellifemine into believing that Miss Carerra was born as a woman\n",
      "--------------------\n",
      "\n",
      "\n",
      "Article processed:\n",
      "\n",
      "--------------------\n",
      "\n",
      "\n",
      "Article processed:\n",
      "'The lamps are going out all over Europe. We shall not see them lit again in our lifetime' Foreign Secretary Sir Edward Grey, August 3, 1914 . Prime Minister David Cameron is urging Britons to switch off their lights for an hour tomorrow evening to mark the 100th anniversary of Britain’s declaration of war on Germany in 1914. The Lights Out initiative will be the culmination of a day of commemorative events across the country and in Europe, with members of the Royal Family fully involved at home\n",
      "--------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_examples_samples = 10\n",
    "\n",
    "for i in range(nb_examples_samples):\n",
    "    # select a random article\n",
    "    #random_idx = np.random.randint(0, len(processed_cnn_dataset[\"train\"]))\n",
    "    print(\"Article processed:\")\n",
    "    print(processed_cnn_dataset[\"train\"][\"article\"][i])\n",
    "    print(\"--------------------\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample:\n",
      "{'label': 1, 'article': '', 'prefix': 'Three members of the same family who died in a'}\n",
      "--------------------\n",
      "\n",
      "\n",
      "Sample:\n",
      "{'label': 0, 'article': \"Three members of the same family who died in a static caravan from carbon monoxide poisoning would have been unconscious 'within minutes', investigators said today. The bodies of married couple John and Audrey Cook were discovered alongside their daughter, Maureen, at the mobile home they shared on Tremarle Home Park in Camborne, west Cornwall. The inquests have now opened into the deaths last Saturday, with investigators saying the three died along with the family's pet dog, of carbon monoxide \", 'prefix': 'Three members of the same family who died in a'}\n",
      "--------------------\n",
      "\n",
      "\n",
      "Sample:\n",
      "{'label': 0, 'article': 'A rare meeting of U.N. Security Council heads of state, led for the first time by a U.S. president, adopted a resolution focused on stopping the spread of nuclear weapons Thursday. President Obama is the first U.S. leader to head a United Nations Security Council meeting. President Obama challenged the gathering -- which included leaders of nuclear powers including Russia, China, Great Britain and France -- to overcome cynicism against the goal of ridding the planet of nuclear arms. \"We harbor n', 'prefix': 'A rare meeting of U.N. Security Council heads of state,'}\n",
      "--------------------\n",
      "\n",
      "\n",
      "Sample:\n",
      "{'label': 1, 'article': '', 'prefix': 'A rare meeting of U.N. Security Council heads of state,'}\n",
      "--------------------\n",
      "\n",
      "\n",
      "Sample:\n",
      "{'label': 1, 'article': '', 'prefix': 'Cover-up: Former Archbishop Lord Hope allowed a paedophile priest to'}\n",
      "--------------------\n",
      "\n",
      "\n",
      "Sample:\n",
      "{'label': 0, 'article': \"Cover-up: Former Archbishop Lord Hope allowed a paedophile priest to escape punishment for sex crimes, a judge's report claims . A former archbishop who failed to act on alleged crimes of a paedophile priest should be jailed, the abuser’s victims have said. Lord Hope, the former Archbishop of York, did not act on 19 occasions when allegations of abuse or inappropriate conduct by the priest were raised with him, a scathing report revealed yesterday. But despite that, Lord Hope remains as an honor\", 'prefix': 'Cover-up: Former Archbishop Lord Hope allowed a paedophile priest to'}\n",
      "--------------------\n",
      "\n",
      "\n",
      "Sample:\n",
      "{'label': 1, 'article': '', 'prefix': 'TLC has pulled an episode of Cake Boss from future'}\n",
      "--------------------\n",
      "\n",
      "\n",
      "Sample:\n",
      "{'label': 0, 'article': \"TLC has pulled an episode of Cake Boss from future screening schedules after receiving complaints over the show's mishandling of a transgender guest star. The episode, which aired on Monday night, showed transgender Carmen Carerra, 27, who was born as a man, take part in a stunt that she believed was edited to look distasteful. The stunt involved Buddy 'Cake Boss' Valastro, the reality show's star, tricking Anthony 'Cousin Anthony' Bellifemine into believing that Miss Carerra was born as a woman\", 'prefix': 'TLC has pulled an episode of Cake Boss from future'}\n",
      "--------------------\n",
      "\n",
      "\n",
      "Sample:\n",
      "{'label': 1, 'article': '', 'prefix': \"'The lamps are going out all over Europe. We shall\"}\n",
      "--------------------\n",
      "\n",
      "\n",
      "Sample:\n",
      "{'label': 0, 'article': \"'The lamps are going out all over Europe. We shall not see them lit again in our lifetime' Foreign Secretary Sir Edward Grey, August 3, 1914 . Prime Minister David Cameron is urging Britons to switch off their lights for an hour tomorrow evening to mark the 100th anniversary of Britain’s declaration of war on Germany in 1914. The Lights Out initiative will be the culmination of a day of commemorative events across the country and in Europe, with members of the Royal Family fully involved at home\", 'prefix': \"'The lamps are going out all over Europe. We shall\"}\n",
      "--------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_examples_samples = 10\n",
    "\n",
    "for i in range(nb_examples_samples):\n",
    "    # select a random article\n",
    "    #random_idx = np.random.randint(0, len(processed_cnn_dataset[\"train\"]))\n",
    "    print(\"Sample:\")\n",
    "    print(processed_cnn_dataset[\"train\"][i])\n",
    "    print(\"--------------------\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test an Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set generation parameters\n",
    "default_gen_params = {\n",
    "    #\"max_length\": 100,\n",
    "    \"max_new_tokens\": 100,\n",
    "    \"min_new_tokens\": 100,\n",
    "    \"temperature\": 0.8,\n",
    "    \"top_p\": 0.95,\n",
    "    \"repetition_penalty\": 1,\n",
    "    \"do_sample\": True,\n",
    "    \"top_k\": 50\n",
    "}\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marluxiaboss/anaconda3/envs/llm_detector/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "gen_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"Qwen/Qwen2-0.5B-Instruct\",\n",
    "    pad_token='<|extra_0|>',\n",
    "    eos_token='<|endoftext|>',\n",
    "    padding_side='left',\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "gen = AutoModelForCausalLM.from_pretrained(\n",
    "    \"Qwen/Qwen2-0.5B-Instruct\",\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\",\n",
    "    pad_token_id=gen_tokenizer.pad_token_id,\n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78f153baa0ec4634a40f69afad005131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gen_config = ModelConfig(gen_tokenizer,\n",
    "    use_chat_template=True, chat_template_type=\"system_user\", gen_params=default_gen_params, device=device)\n",
    "\n",
    "gen_model = LLMGenerator(gen, gen_config)\n",
    "\n",
    "system_prompt = \"You are a helpful assistant.\"\n",
    "user_prompt = \"Continue writing the following news article starting with:\"\n",
    "prompt_config = PromptConfig(system_prompt=system_prompt, user_prompt=user_prompt)\n",
    "\n",
    "\n",
    "text_gen_no_attack = PromptAttack(gen_model, gen_config, system_prompt, prompt_config)\n",
    "\n",
    "\n",
    "true_articles = processed_cnn_dataset[\"train\"].filter(lambda x: x[\"label\"] == 0)\n",
    "true_articles_prefixes = true_articles[\"prefix\"][:10]\n",
    "\n",
    "fake_articles = text_gen_no_attack.generate_adversarial_text(true_articles_prefixes, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True article: Three members of the same family who died in a static caravan from carbon monoxide poisoning would have been unconscious 'within minutes', investigators said today. The bodies of married couple John and Audrey Cook were discovered alongside their daughter, Maureen, at the mobile home they shared on Tremarle Home Park in Camborne, west Cornwall. The inquests have now opened into the deaths last Saturday, with investigators saying the three died along with the family's pet dog, of carbon monoxide \n",
      "Fake article: Three members of the same family who died in a  tragic car accident on Thursday evening have been identified by the family's lawyer. The accident occurred around 8:30 p.m. on the I-275 eastbound exit ramp near the intersection with I-40.\n",
      "The three victims, who were wearing black and white safety belts, were pronounced dead at the scene. The driver of the vehicle was taken to a local hospital for treatment of minor injuries. The driver of the car was also taken to a hospital for treatment of minor injuries\n",
      "\n",
      "\n",
      "True article: A rare meeting of U.N. Security Council heads of state, led for the first time by a U.S. president, adopted a resolution focused on stopping the spread of nuclear weapons Thursday. President Obama is the first U.S. leader to head a United Nations Security Council meeting. President Obama challenged the gathering -- which included leaders of nuclear powers including Russia, China, Great Britain and France -- to overcome cynicism against the goal of ridding the planet of nuclear arms. \"We harbor n\n",
      "Fake article: A rare meeting of U.N. Security Council heads of state,  with a focus on peacekeeping and refugee aid, has taken place in Geneva, Switzerland. The meeting, which began on Monday, is expected to provide a platform for countries to discuss ways to reduce tensions and prevent conflicts in the Middle East and other regions.\n",
      "The Security Council is a body of 15 countries that meets to discuss global issues and to make decisions on how to resolve conflicts. The meeting, which is being held for the first time, will be attended by representatives from 51 countries\n",
      "\n",
      "\n",
      "True article: Cover-up: Former Archbishop Lord Hope allowed a paedophile priest to escape punishment for sex crimes, a judge's report claims . A former archbishop who failed to act on alleged crimes of a paedophile priest should be jailed, the abuser’s victims have said. Lord Hope, the former Archbishop of York, did not act on 19 occasions when allegations of abuse or inappropriate conduct by the priest were raised with him, a scathing report revealed yesterday. But despite that, Lord Hope remains as an honor\n",
      "Fake article: Cover-up: Former Archbishop Lord Hope allowed a paedophile priest to  marry his daughter\n",
      "Former Archbishop Lord Hope has admitted that he allowed a paedophile priest to marry his daughter, which is considered a serious crime under current laws in the UK. The decision to allow the priest to marry the daughter was made after the Archbishop had been involved in a scandal involving a number of other priests and was reported to the police.\n",
      "The scandal involved a priest who had been accused of sexually abusing children, and the Archbishop had been involved in a cover-up to protect his own position as arch\n",
      "\n",
      "\n",
      "True article: TLC has pulled an episode of Cake Boss from future screening schedules after receiving complaints over the show's mishandling of a transgender guest star. The episode, which aired on Monday night, showed transgender Carmen Carerra, 27, who was born as a man, take part in a stunt that she believed was edited to look distasteful. The stunt involved Buddy 'Cake Boss' Valastro, the reality show's star, tricking Anthony 'Cousin Anthony' Bellifemine into believing that Miss Carerra was born as a woman\n",
      "Fake article: TLC has pulled an episode of Cake Boss from future , which was planned to air in the coming months. The news came as a surprise to many fans of the show, as the episode was scheduled to air in January. The company behind the show, TLC, has not commented on the decision, but it is not uncommon for shows to be canceled or delayed in the future as they adjust to changing schedules or seasons.\n",
      "\n",
      "There have been concerns about the show's popularity, which has declined in recent years due to competition from other cooking shows. However, the\n",
      "\n",
      "\n",
      "True article: 'The lamps are going out all over Europe. We shall not see them lit again in our lifetime' Foreign Secretary Sir Edward Grey, August 3, 1914 . Prime Minister David Cameron is urging Britons to switch off their lights for an hour tomorrow evening to mark the 100th anniversary of Britain’s declaration of war on Germany in 1914. The Lights Out initiative will be the culmination of a day of commemorative events across the country and in Europe, with members of the Royal Family fully involved at home\n",
      "Fake article: 'The lamps are going out all over Europe. We shall  be facing a crisis. The lack of electricity has made it difficult for people to light their homes, drive, and even go to work. In Germany, an estimated 12 million homes have been affected by the lack of electricity. In France, 7 million homes have been affected, and in the UK, 4 million homes have been affected. In Spain, 2 million homes have been affected. The situation is becoming more and more dire, and it is clear that we are facing a\n",
      "\n",
      "\n",
      "True article: Roy Hodgson has come under fire for making public Raheem Sterling's admission that he was feeling tired ahead of England's Euro 2016 qualifier with Estonia. The Liverpool star told the England manager that he was too fatigued to start the match in Tallinn after shouldering a heavy burden this season for both club and country. Hodgson then made Sterling's comments public ahead of the match, which England won 1-0 thanks to Wayne Rooney's second-half free-kick. VIDEO Scroll down to watch Roy Hodgso\n",
      "Fake article: Roy Hodgson has come under fire for making public Raheem  Sterling's \"offensive language\" following his controversial comments about Liverpool manager Jurgen Klopp.\n",
      "The comments came after Liverpool fans accused Hodgson of being racist towards the Englishman after his move to Manchester United in January.\n",
      "Hodgson was reported to have made the comments while speaking to a group of United fans in a pub in Dublin, and it sparked a storm of criticism from fans, including Liverpool supporters.\n",
      "In a statement, Hodgson said: \"I am shocked and disappointed by the comments made\n",
      "\n",
      "\n",
      "True article: Every frontline police officer should be offered a Taser to help fight the threat from lone-wolf terrorists, a police leader declared yesterday. Steve White, who chairs the Police Federation, said evidence of plans to murder officers made the move necessary. ‘The terrorist ideal to get attention no longer relies on an attack being in a place of note,’ he said. ‘It could be in Cheam high street, in any town, in any part of the UK. We know there are more dangerous people out there, preparing to at\n",
      "Fake article: Every frontline police officer should be offered a Taser to  address the issue of excessive use of force by law enforcement officers. According to the American Civil Liberties Union, excessive use of force by law enforcement is a major contributor to the high rate of criminal activity and violence in the United States. The use of Taser by police officers is a controversial issue that has been the subject of numerous protests and legal challenges. However, it is important to note that not all police officers are equipped with Taser technology, and many officers may not have access to the necessary equipment\n",
      "\n",
      "\n",
      "True article: By . Dan Bloom . It's one very, very small step for man - but a giant leap for antkind. Around 800 common ants, usually found pattering across pavements and picnics, have been sent to the International Space Station to teach scientists how they move in low gravity. Eight colonies each about the size of a tablet computer have been set up to teach experts how to build robots which interact with each other. Welcome: Nasa astronaut Rick Mastracchio greets 800 new friends aboard the International Spa\n",
      "Fake article: By . Dan Bloom . It's one very, very small  project, one that requires a lot of hard work, but it's one that's going to have a big impact on the world.\n",
      "\n",
      "The project is a small-scale recycling initiative that aims to reduce waste and promote sustainable living. The initiative involves collecting and sorting recyclable materials such as newspapers, plastic bottles, and aluminum cans. It's a small project, but it's important to keep in mind that even a small change can make a big difference.\n",
      "\n",
      "The initiative is being led by a group of individuals\n",
      "\n",
      "\n",
      "True article: A pensioner died from fatal injuries after being hit on the head by a cricket ball during a match. David Wilcockson, 71, was bowling at a ground in Cranleigh, Surrey when the batsman's shot struck him on the head. Players battled in vain to revive him after he slumped on the pitch unconscious and he was taken by air ambulance to King's College Hospital in London. David Wilcockson (pictured), 71, was bowling at a ground in Cranleigh, Surrey when the ball struck him on the head . Players battled i\n",
      "Fake article: A pensioner died from fatal injuries after being hit on  his way to the local park. The incident occurred on Sunday morning, when the pensioner was walking along a busy road when he suddenly fell and hit a tree. He was taken to the hospital but unfortunately, he was pronounced dead on arrival. The pensioner's family have since expressed their shock and grief at the tragic loss of their loved one. The park where the accident occurred is currently closed and the police are investigating the incident. The local council has also expressed its condolences to the family and is\n",
      "\n",
      "\n",
      "True article: Workers digging an underground garage for a new hotel  recently struck something big about 30 feet below the surface. This week they uncovered it - a boulder that's thousands of years old and bigger than an SUV, weighing an estimated 150 tons or 300,000lbs. A geotechnical engineer who was called out to examine the giant rock in Everett, Washington. The rock, which weighs 150 tons and is bigger than an SUV was discovered in Everett, Washington. It is believed that a glacier left the 'erratic rock\n",
      "Fake article: Workers digging an underground garage for a new hotel recently  reported the news to their colleagues. The excavation was completed successfully, and the team was excited to see the new hotel. They were confident that the underground garage would be a major asset for the hotel, and the workers were looking forward to adding it to their project. The team had planned to use the garage for temporary storage, but the news of its completion brought them all back to reality. They had been working hard for months to excavate the site, and they were finally able to complete the task\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "true_articles_sample = true_articles[\"article\"][:10]\n",
    "for i in range(len(true_articles_sample)):\n",
    "    print(\"True article:\", true_articles_sample[i])\n",
    "    print(\"Fake article:\", fake_articles[i])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add a mechansim such that if a dataset has already been generated, we use it directly\n",
    "# and also to save intermediary datasets\n",
    "# Have a parseable dataset naming format \n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import json\n",
    "from time import gmtime, strftime\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "\n",
    "def compute_bootstrap_metrics(data, labels, n_bootstrap=1000, flip_labels=False):\n",
    "\n",
    "    # compute false postives, false negatives, true positives, true negatives using bootstrap\n",
    "    nb_false_positives = np.zeros(n_bootstrap)\n",
    "    nb_false_negatives = np.zeros(n_bootstrap)\n",
    "    nb_true_positives = np.zeros(n_bootstrap)\n",
    "    nb_true_negatives = np.zeros(n_bootstrap)\n",
    "\n",
    "    for i in range(n_bootstrap):\n",
    "        bootstrap_sample = np.random.choice(range(len(data)), len(data), replace=True)\n",
    "        nb_false_positives[i] = np.sum((data[bootstrap_sample] == 1) & (labels[bootstrap_sample] == 0))\n",
    "        nb_false_negatives[i] = np.sum((data[bootstrap_sample] == 0) & (labels[bootstrap_sample] == 1))\n",
    "        nb_true_positives[i] = np.sum((data[bootstrap_sample] == 1) & (labels[bootstrap_sample] == 1))\n",
    "        nb_true_negatives[i] = np.sum((data[bootstrap_sample] == 0) & (labels[bootstrap_sample] == 0))\n",
    "    \n",
    "    metrics = [\"accuracy\", \"precision\", \"recall\", \"f1_score\", \"fp_rate\", \"tp_rate\"]\n",
    "    avg_metrics = {}\n",
    "    std_metrics = {}\n",
    "    for metric in metrics:\n",
    "        metric_results = np.zeros(n_bootstrap)\n",
    "        for i in range(n_bootstrap):\n",
    "            nb_false_positives_i = nb_false_positives[i]\n",
    "            nb_false_negatives_i = nb_false_negatives[i]\n",
    "            nb_true_positives_i = nb_true_positives[i]\n",
    "            nb_true_negatives_i = nb_true_negatives[i]\n",
    "            \n",
    "            if flip_labels:\n",
    "                nb_false_positives_i = nb_false_negatives[i]\n",
    "                nb_false_negatives_i = nb_false_positives[i]\n",
    "                nb_true_positives_i = nb_true_negatives[i]\n",
    "                nb_true_negatives_i = nb_true_positives[i]\n",
    "            \n",
    "            # we need to test cases where the denominator is 0 because there might dataset with only 0 labels or 1 labels\n",
    "            match metric:\n",
    "                case \"accuracy\":\n",
    "                    if len(data) == 0:\n",
    "                        metric_results[i] = 0\n",
    "                    else:\n",
    "                        metric_results[i] = (nb_true_positives_i + nb_true_negatives_i) / len(data)\n",
    "                    \n",
    "                case \"precision\":\n",
    "                    if (nb_true_positives_i + nb_false_positives_i == 0):\n",
    "                        metric_results[i] = 0\n",
    "                    else:\n",
    "                        metric_results[i] = nb_true_positives_i / (nb_true_positives_i + nb_false_positives_i)\n",
    "                        \n",
    "                case \"recall\":\n",
    "                    if (nb_true_positives_i + nb_false_negatives_i == 0):\n",
    "                        metric_results[i] = 0\n",
    "                    else:\n",
    "                        metric_results[i] = nb_true_positives_i / (nb_true_positives_i + nb_false_negatives_i)\n",
    "                case \"f1_score\":\n",
    "                    if (2 * nb_true_positives_i + nb_false_positives_i + nb_false_negatives_i) == 0:\n",
    "                        metric_results[i] = 0\n",
    "                    else:\n",
    "                        metric_results[i] = 2 * nb_true_positives_i / (2 * nb_true_positives_i + nb_false_positives_i + nb_false_negatives_i)\n",
    "                case \"fp_rate\":\n",
    "                    if  (nb_false_positives_i + nb_true_negatives_i) == 0:\n",
    "                        metric_results[i] = 0\n",
    "                    else:\n",
    "                        metric_results[i] = nb_false_positives_i / (nb_false_positives_i + nb_true_negatives_i)\n",
    "                        \n",
    "                case \"tp_rate\":\n",
    "                    if  (nb_true_positives_i + nb_false_negatives_i) == 0:\n",
    "                        metric_results[i] = 0\n",
    "                    else:\n",
    "                        metric_results[i] = nb_true_positives_i / (nb_true_positives_i + nb_false_negatives_i)\n",
    "            \n",
    "        avg_metrics[metric] = np.mean(metric_results)\n",
    "        std_metrics[metric] = np.std(metric_results)\n",
    "\n",
    "    print(\"Average metrics: \", avg_metrics)\n",
    "    print(\"Standard deviation of metrics: \", std_metrics)\n",
    "\n",
    "    # change name of std_metrics as std_{metric_name}\n",
    "    for metric in metrics:\n",
    "        std_metrics[\"std_\" + metric] = std_metrics[metric]\n",
    "        del std_metrics[metric]\n",
    "    \n",
    "    avg_metrics.update(std_metrics)\n",
    "    metrics_dict = avg_metrics\n",
    "    \n",
    "    # add TP, TN, FP, FN to the metrics_dict\n",
    "    metrics_dict[\"TP\"] = np.mean(nb_true_positives)\n",
    "    metrics_dict[\"TN\"] = np.mean(nb_true_negatives)\n",
    "    metrics_dict[\"FP\"] = np.mean(nb_false_positives)\n",
    "    metrics_dict[\"FN\"] = np.mean(nb_false_negatives)\n",
    "    \n",
    "    return metrics_dict\n",
    "\n",
    "def create_logger(name, silent=False, to_disk=False, log_file=None):\n",
    "    \"\"\"Create a new logger\"\"\"\n",
    "    # setup logger\n",
    "    log = logging.getLogger(name)\n",
    "    log.setLevel(logging.DEBUG)\n",
    "    log.propagate = False\n",
    "    formatter = logging.Formatter(fmt='%(message)s', datefmt='%Y/%m/%d %I:%M:%S')\n",
    "    if not silent:\n",
    "        ch = logging.StreamHandler(sys.stdout)\n",
    "        ch.setLevel(logging.DEBUG)\n",
    "        ch.setFormatter(formatter)\n",
    "        log.addHandler(ch)\n",
    "    if to_disk:\n",
    "        log_file = log_file if log_file is not None else strftime(\"log/log_%m%d_%H%M.txt\", gmtime())\n",
    "        if type(log_file) == list:\n",
    "            for filename in log_file:\n",
    "                fh = logging.FileHandler(filename, mode='w')\n",
    "                fh.setLevel(logging.INFO)\n",
    "                fh.setFormatter(formatter)\n",
    "                log.addHandler(fh)\n",
    "        if type(log_file) == str:\n",
    "            fh = logging.FileHandler(log_file, mode='w')\n",
    "            fh.setLevel(logging.INFO)\n",
    "            fh.setFormatter(formatter)\n",
    "            log.addHandler(fh)\n",
    "    return log\n",
    "\n",
    "class ExperimentPipeline(ABC):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def run_pipeline(self):\n",
    "        pass\n",
    "    \n",
    "class ExperimentTestPipeline(ExperimentPipeline):\n",
    "    def __init__(self, dataset_loader, attack, detector, device, experiment_path, watermarking_scheme=None, batch_size=1):\n",
    "        self.dataset_loader = dataset_loader\n",
    "        self.attack = attack\n",
    "        self.detector = detector\n",
    "        self.device = device\n",
    "        self.experiment_path = experiment_path\n",
    "        self.batch_size = batch_size\n",
    "        self.watermarking_scheme = watermarking_scheme\n",
    "        \n",
    "        # setup log\n",
    "        log_path = f\"{experiment_path}/log\"\n",
    "        self.log = create_logger(__name__, silent=False, to_disk=True,\n",
    "                                 log_file=log_path)\n",
    "        \n",
    "    def create_logger(self):\n",
    "        if log_path is None:\n",
    "            if self.experiment_path is None:\n",
    "                raise ValueError(\"Experiment path not set\")\n",
    "            log_path = self.experiment_path\n",
    "        \n",
    "        # create log file\n",
    "        with open(f\"{log_path}/log.txt\", \"w\") as f:\n",
    "            f.write(\"\")\n",
    "\n",
    "        log = create_logger(__name__, silent=False, to_disk=True,\n",
    "                                    log_file=f\"{log_path}/log.txt\")\n",
    "        self.log = log\n",
    "        \n",
    "    def create_experiment_dataset(self, dataset_name):\n",
    "        ### CREATE THE (ADVERSRIAL) DATASET AND SAVE IT ###\n",
    "        \n",
    "        # Load the base dataset\n",
    "        dataset = self.dataset_loader.load_data()\n",
    "        \n",
    "        # We only use the test data split here\n",
    "        dataset = dataset[\"test\"]\n",
    "                \n",
    "        # Generate adversarial examples\n",
    "        true_articles = dataset.filter(lambda x: x[\"label\"] == 0)\n",
    "        true_articles_prefixes = true_articles[\"prefix\"][:]\n",
    "        fake_articles = self.attack.generate_adversarial_text(true_articles_prefixes, batch_size=self.batch_size)\n",
    "        \n",
    "        # Fuse true and fake articles by filling samples in dataset with label = 1\n",
    "        for i in range(len(dataset)):\n",
    "            if dataset[i][\"label\"] == 1:\n",
    "                \n",
    "                # should be in the same order as the dataset\n",
    "                dataset[i][\"article\"] = fake_articles[i]\n",
    "                \n",
    "        # Save the dataset using a specific naming convention\n",
    "        dataset.save_to_disk(f\"data/generated_datasets/{dataset_name}\")\n",
    "        \n",
    "        return dataset\n",
    "        \n",
    "    def run_pipeline(self):\n",
    "        log = self.log\n",
    "\n",
    "        # check if the dataset has already been generated for the attack and base dataset\n",
    "        base_dataset_name = self.dataset_loader.dataset_name\n",
    "        attack_name  = self.attack.attack_name\n",
    "        use_watermarking = self.watermarking_scheme is not None\n",
    "        dataset_name = f\"{base_dataset_name}_{attack_name}\"\n",
    "        \n",
    "        if use_watermarking:\n",
    "            dataset_name += \"_watermarked\"\n",
    "    \n",
    "        if os.path.isdir(f\"data/generated_datasets/{dataset_name}\"):\n",
    "            log.info(f\"Dataset {dataset_name} already exists, loading it\")\n",
    "            dataset = load_from_disk(f\"data/generated_datasets/{dataset_name}\")\n",
    "        else:\n",
    "            log.info(f\"Dataset {dataset_name} does not exist, creating it\")\n",
    "            dataset = self.create_experiment_dataset(dataset_name)\n",
    "                \n",
    "        ### TEST THE DETECTOR ###\n",
    "        fake_true_articles = dataset[\"article\"][:]\n",
    "        preds, logits = self.detector.detect(fake_true_articles, detection_threshold=0.5, batch_size=self.batch_size)\n",
    "        labels = dataset[\"label\"]\n",
    "        \n",
    "        # TODO: better to handle this in a helper\n",
    "        # compute metrics\n",
    "        nb_pos_labels = np.sum(dataset[\"label\"] == 1)\n",
    "        nb_neg_labels = np.sum(dataset[\"label\"] == 0)\n",
    "        \n",
    "        if nb_pos_labels == 0 or nb_neg_labels == 0:\n",
    "            #log.info(\"Only one class in the dataset, cannot compute roc_auc\")\n",
    "            roc_auc = 0\n",
    "            fpr = np.zeros(1)\n",
    "            tpr = np.zeros(1)\n",
    "            thresholds = np.zeros(1)\n",
    "        else:\n",
    "            roc_auc = roc_auc_score(labels, logits)\n",
    "            fpr, tpr, thresholds = roc_curve(labels, logits)\n",
    "        \n",
    "        #    fpr, tpr = 1 - fpr, 1 - tpr\n",
    "        \n",
    "        results = compute_bootstrap_metrics(preds, labels)\n",
    "        \n",
    "        log.info(\"Test metrics:\")\n",
    "        for key, value in results.items():\n",
    "            log.info(f\"{key}: {value}\")\n",
    "            \n",
    "        # also log the roc_auc and the fpr, tpr, thresholds\n",
    "        log.info(f\"roc_auc: {roc_auc}\")\n",
    "        log.info(f\"fpr: {fpr}\")\n",
    "        log.info(f\"tpr: {tpr}\")\n",
    "        log.info(f\"thresholds: {thresholds}\")\n",
    "        \n",
    "        results[\"roc_auc\"] = roc_auc\n",
    "        results[\"fpr_at_thresholds\"] = fpr.tolist()\n",
    "        results[\"tpr_at_thresholds\"] = tpr.tolist()\n",
    "        results[\"thresholds\"] = thresholds.tolist()\n",
    "    \n",
    "        \n",
    "        if self.classifier_threshold is not None:\n",
    "            \n",
    "            preds_at_threshold = np.where(logits > self.classifier_threshold, 1, 0)\n",
    "\n",
    "            results_at_threshold = compute_bootstrap_metrics(preds_at_threshold, labels)\n",
    "            log.info(\"Test metrics at specific given threshold:\")\n",
    "            \n",
    "            for key, value in results_at_threshold.items():\n",
    "                log.info(f\"{key}: {value}\")\n",
    "                \n",
    "            # add them to results dict as f\"{key}_at_given_threshold\"\n",
    "            results[\"given_threshold\"] = self.classifier_threshold\n",
    "            for key, value in results_at_threshold.items():\n",
    "                results[f\"{key}_at_given_threshold\"] = value\n",
    "                \n",
    "                \n",
    "        experiment_path = self.experiment_path\n",
    "        dataset_name = self.dataset_loader.dataset_name\n",
    "        if self.classifier_threshold is not None:\n",
    "            if not os.path.isdir(f\"{experiment_path}/test_at_threshold\"):\n",
    "                os.makedirs(f\"{experiment_path}/test_at_threshold\")\n",
    "                \n",
    "            json_res_file_path = f\"{experiment_path}/test_at_threshold/test_metrics_{dataset_name}.json\"\n",
    "            \n",
    "        else:\n",
    "            if not os.path.isdir(f\"{experiment_path}/test\"):\n",
    "                os.makedirs(f\"{experiment_path}/test\")\n",
    "            \n",
    "                json_res_file_path = f\"{experiment_path}/test/test_metrics_{dataset_name}.json\"\n",
    "                \n",
    "        with open(json_res_file_path, \"w\") as f:\n",
    "            f.write(json.dumps(results, indent=4))\n",
    " \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate all datasets (attack + non attack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Watermarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WatermarkingDetector(Detector):\n",
    "    def __init__(self, watermark):\n",
    "        self.watermark = watermark\n",
    "        \n",
    "    def detect(self, text: str) -> bool:\n",
    "        return self.watermark in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WatermarkingGenerator(Generator):\n",
    "    \n",
    "    def __init__(self, model, tokenizer, watermark):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.watermark = watermark\n",
    "        \n",
    "    def generate(self, prompt: str) -> str:\n",
    "        text = self.watermark + \" \" + prompt\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        outputs = self.model.generate(**inputs)\n",
    "        return self.tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_detector",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
