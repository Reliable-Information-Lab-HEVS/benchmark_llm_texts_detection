{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/marluxiaboss/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/marluxiaboss/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/marluxiaboss/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from abc import ABC, abstractmethod\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from datasets import concatenate_datasets, load_from_disk, DatasetDict\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import nltk.data\n",
    "nltk.download('punkt')\n",
    "from transformers import (AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForMaskedLM, AutoModelForCausalLM,\n",
    "                          ElectraForSequenceClassification, ElectraTokenizer, AutoConfig)\n",
    "from datasets import load_from_disk, concatenate_datasets, Dataset\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "from evasion_attack import PromptParaphrasingAttack, PromptAttack, GenParamsAttack\n",
    "from utils import ModelConfig, PromptConfig\n",
    "from generator import LLMGenerator\n",
    "from detector import Detector, BertDetector\n",
    "from fast_detect_gpt import FastDetectGPT\n",
    "from cnn_dataset import CNNDataLoader\n",
    "from experiment_pipeline import ExperimentTestPipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set generation parameters\n",
    "default_gen_params = {\n",
    "    #\"max_length\": 100,\n",
    "    \"max_new_tokens\": 100,\n",
    "    \"min_new_tokens\": 100,\n",
    "    \"temperature\": 0.8,\n",
    "    \"top_p\": 0.95,\n",
    "    \"repetition_penalty\": 1,\n",
    "    \"do_sample\": True,\n",
    "    \"top_k\": 50\n",
    "}\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marluxiaboss/anaconda3/envs/llm_detector/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[' Cats are better than dogs as they have developed traits that allow them to thrive and survive in various environments, while dogs lack such traits. Cats are known for being solitary animals, while dogs are social animals. Cats have the ability to be social animals, while dogs lack such traits. So, cats are better than dogs because they have developed unique traits that allow them to thrive and survive in various environments. Cats are known for being solitary animals, while dogs are social animals. Cats have the ability to be',\n",
       " ' Dogs are generally better at performing certain tasks than cats, while dogs are more trainable and have stronger attachments to their owners. They are known for their loyalty and intelligence. Dogs are also known for their ability to be highly trainable and to form strong attachments to their owners. They are also known for their ability to perform a variety of tasks, such as hunting, guarding, and performing tricks. They are also known for their ability to be highly trainable and to form strong attachments to their owners. They are known',\n",
       " \" Dogs are known for their physical abilities, whereas cats are known for their mental abilities. Cats are known for their calming and affectionate nature, while dogs are known for their strength, intelligence, and ability to navigate through various terrains. In this article, we'll explore why cats are better than dogs, focusing on some of their unique traits that set them apart. The article discusses the differences between cats and dogs and highlights the unique qualities and abilities of cats. The author argues that cats are better than\",\n",
       " ' Dogs are known for their loyalty and affectionate nature, which makes them popular pets around the world. While cats are known for their sharp claws and stealth, they are also known for their independent nature and the ability to keep a house clean. In terms of intelligence and problem-solving abilities, dogs are considered to be more intelligent than cats. Dogs are capable of learning new behaviors and habits, and they are often more intelligent than cats. They also tend to be more independent and able to clean their own',\n",
       " ' Cats are considered to be better than dogs for several reasons. First, cats are often more independent and self-sufficient than dogs. They can navigate their own way without the need for human assistance. Additionally, cats can be more affectionate and loving towards their owners than dogs. Finally, cats are known for their loyalty and affectionate nature, which make them a perfect companion for people with busy schedules or pets who may not be available to help. While dogs are known for their loyalty and affectionate nature']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paraphraser_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"Qwen/Qwen2-0.5B-Instruct\",\n",
    "    pad_token='<|extra_0|>',\n",
    "    eos_token='<|endoftext|>',\n",
    "    padding_side='left',\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "paraphraser = AutoModelForCausalLM.from_pretrained(\n",
    "    \"Qwen/Qwen2-0.5B-Instruct\",\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\",\n",
    "    pad_token_id=paraphraser_tokenizer.pad_token_id,\n",
    ").to(device)\n",
    "\n",
    "\n",
    "paraphraser_config = ModelConfig(paraphraser_tokenizer,\n",
    "    use_chat_template=True, chat_template_type=\"system_user\", gen_params=default_gen_params, device=device)\n",
    "paraphraser_model = LLMGenerator(paraphraser, paraphraser_config)\n",
    "\n",
    "gen_model = paraphraser_model\n",
    "gen_tokenizer = paraphraser_tokenizer\n",
    "gen_config = paraphraser_config\n",
    "\n",
    "\n",
    "dataset_list = [\"Why are cats better than dogs\", \"Why are dogs better than cats\", \"Why are cats better than dogs\",\n",
    "                \"Why are dogs better than cats\", \"Why are cats better than dogs\"]\n",
    "\n",
    "system_paraphrasing_prompt = \"\"\"You are a paraphraser. You are given an input passage ‘INPUT’. You should paraphrase ‘INPUT’ to print ‘OUTPUT’.\"\n",
    "    \"‘OUTPUT’ shoud be diverse and different as much as possible from ‘INPUT’ and should not copy any part verbatim from ‘INPUT’.\"\n",
    "    \"‘OUTPUT’ should preserve the meaning and content of ’INPUT’ while maintaining text quality and grammar.\"\n",
    "    \"‘OUTPUT’ should not be much longer than ‘INPUT’. You should print ‘OUTPUT’ and nothing else so that its easy for me to parse.\"\"\"\n",
    "user_paraphrasing_prompt = \"INPUT:\"\n",
    "paraphraser_prompt_config = PromptConfig(system_prompt=system_paraphrasing_prompt, user_prompt=\"\")\n",
    "\n",
    "\n",
    "gen_prompt = \"You are a helpful assistant.\"\n",
    "user_prompt = \"Write a news article starting with:\"\n",
    "gen_prompt_config = PromptConfig(system_prompt=gen_prompt, user_prompt=user_prompt)\n",
    "\n",
    "prompt_paraphrasing_attack = PromptParaphrasingAttack(gen_model, gen_config, gen_prompt_config, paraphraser_model, paraphraser_config, paraphraser_prompt_config)\n",
    "paraphrased_fake_articles = prompt_paraphrasing_attack.generate_adversarial_text(dataset_list, batch_size=2)\n",
    "\n",
    "paraphrased_fake_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Why are cats better than dogs ?\\nThe question of whether cats are better than dogs is a topic that has been debated for centuries. While both animals are intelligent and capable of achieving success in various pursuits, there are several factors that could explain why cats are often considered more well-adjusted and intelligent than dogs. \\nOne reason that cats may outperform dogs in certain tasks is that they are often social and have a natural inclination towards nurturing and caring for others. Dogs, on the other hand, are often social animals that are more independent',\n",
       " 'Why are dogs better than cats ?\\nIn many households, dogs are the most commonly owned pets, but they are also beloved companions for many families. While cats may be a smaller pet, they offer a unique way to bond with humans and provide a loyal and affectionate friend.\\nAccording to a recent study published in the journal Nature, dogs are more social animals than cats and are known for their loyalty and intelligence. The study found that dogs can detect and respond to the presence of humans, which is a unique trait that many people find']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adversarial_system_prompt = \"You are a helpful assistant.\"\n",
    "advesarial_user_prompt = \"Write a news article in the CNN news article style starting with:\"\n",
    "adversarial_prompt_config = PromptConfig(system_prompt=adversarial_system_prompt, user_prompt=advesarial_user_prompt)\n",
    "\n",
    "prompt_attack = PromptAttack(gen_model, gen_config, gen_prompt_config, adversarial_prompt_config)\n",
    "prompt_attack_fake_articles = prompt_attack.generate_adversarial_text(dataset_list, batch_size=2)\n",
    "prompt_attack_fake_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Why are cats better than dogs ?\\nThe topic of cats being more intelligent and affectionate than dogs is a widely debated subject, with different opinions within the media, scientists, and among pet owners themselves. Some argue that cats are superior, as they are capable of better cognitive functions and possess unique personality traits. Others believe that dogs are more capable and docile.\\nRegardless of one's perspective, research has consistently shown that cats excel in certain tasks and interactions with their owners, and that they possess a keen sense of smell, a keen\",\n",
       " 'Why are dogs better than cats ?\\nThere are many reasons why dogs are often considered to be superior to cats. However, one key factor that stands out is their exceptional ability to sense their surroundings and react appropriately. In general, dogs are more alert and responsive to their environment, which means they are able to adapt to a wide range of situations quickly and effectively.\\nFurthermore, dogs are known for their ability to learn new skills and behaviors quickly, which is one of their primary advantages over cats. As a result, dogs are often more']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adversarial_gen_param = {\n",
    "    \"temperature\": 1.2\n",
    "}\n",
    "\n",
    "gen_parameters_attack = GenParamsAttack(gen_model, gen_config, gen_prompt_config, adversarial_gen_param)\n",
    "gen_parameters_fake_articles = gen_parameters_attack.generate_adversarial_text(dataset_list, batch_size=2)\n",
    "gen_parameters_fake_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Why are cats better than dogs ... It all begins now as The \"Alo !!g \" breeds one and every once and every another discovers we must take that leap that only some things do (it says...) In an experiment known to lovers there, scientists find it takes three bites rather just... A couple dogs decide between finding themselves cats instead, just a new way at trying and it happens, right? We then found and had found one in which, this morning The little brown one comes for it A dog named Jodie decides',\n",
       " \"Why are dogs better than cats  when coming from animal福利? Why and Can. When one breeds or socialize to another?\\nThis is one reason dog owners have long debated: While both of species excel in all physical behaviors: Intelligence vs Motion Dog Behavior The research shows:\\nMost experts, if all of breed's qualities were transferred as their ability towards social relationships would greatly evolve from breed A dog may learn tricks well if bred A because those that grew the best with human beings trained at dogs' level are generally higher social competence skills\"]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adversarial_gen_param = {\n",
    "    \"temperature\": 10.0\n",
    "}\n",
    "\n",
    "gen_parameters_attack = GenParamsAttack(gen_model, gen_config, gen_prompt_config, adversarial_gen_param)\n",
    "gen_parameters_fake_articles = gen_parameters_attack.generate_adversarial_text(dataset_list, batch_size=2)\n",
    "gen_parameters_fake_articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElectraForSequenceClassification(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 1024)\n",
       "      (token_type_embeddings): Embedding(2, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): ElectraClassificationHead(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (activation): GELUActivation()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=1024, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "detector_path = \"google/electra-large-discriminator\"\n",
    "config = AutoConfig.from_pretrained(detector_path)\n",
    "detector_model = ElectraForSequenceClassification(config)\n",
    "bert_tokenizer = ElectraTokenizer.from_pretrained(detector_path)\n",
    "\n",
    "model_path = \"../saved_training_logs_experiment_2/electra_large/full_finetuning/fake_true_dataset_round_robin_10k/10_06_1308/saved_models/best_model.pt\"\n",
    "detector_model.load_state_dict(torch.load(model_path))\n",
    "detector_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'detector_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_489345/579843562.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtext_to_detect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"I am AI generated text\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"I am human generated text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdetector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertDetector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetector_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_to_detect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetection_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'detector_model' is not defined"
     ]
    }
   ],
   "source": [
    "text_to_detect = [\"I am AI generated text\", \"I am human generated text\"]\n",
    "detector = BertDetector(detector_model, bert_tokenizer, device)\n",
    "preds, logits = detector.detect(text_to_detect, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 0], [0.14659571647644043, -0.6974161863327026])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds, logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fast-DetectGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marluxiaboss/anaconda3/envs/llm_detector/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "ref_model_path = \"openai-community/gpt2\"\n",
    "ref_model = AutoModelForCausalLM.from_pretrained(ref_model_path, torch_dtype=\"auto\").to(device)\n",
    "ref_tokenizer = AutoTokenizer.from_pretrained(ref_model_path, trust_remote_code=True, padding_side=\"left\")\n",
    "\n",
    "# special for gpt2\n",
    "ref_tokenizer.pad_token = ref_tokenizer.eos_token\n",
    "ref_tokenizer.padding_side = 'left'\n",
    "\n",
    "scoring_model = ref_model\n",
    "scoring_tokenizer = ref_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_492861/3717592639.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"I am AI generated text\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"I am human generated text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfast_detector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/llm_text_detector/new_repo/benchmark_ai_news_detection/benchmarking_detectors/fast_detect_gpt.py\u001b[0m in \u001b[0;36mdetect\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;31m#name = \"sampling_discrepancy_analytic\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mcriterion_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_sampling_discrepancy_analytic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mprob_estimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProbEstimatorFastDetectGPT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mref_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/llm_text_detector/new_repo/benchmark_ai_news_detection/benchmarking_detectors/fast_detect_gpt.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, ref_path)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal_crits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfake_crits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mresult_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'*.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "fast_detector = FastDetectGPT(ref_model, scoring_model, ref_tokenizer, scoring_tokenizer, device)\n",
    "\n",
    "texts = [\"I am AI generated text\", \"I am human generated text\"]\n",
    "preds, probs = fast_detector.detect(texts)\n",
    "preds, probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of data discarded after removing duplicate article: 0.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ec6f7d3de424de9bc7490757f1d06c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4915ca9531c4a1f897a9aac2fbbfb8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4021f2f1b2b4a6da63e5ef90c453dcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 1600\n",
      "Eval size: 200\n",
      "Test size: 200\n"
     ]
    }
   ],
   "source": [
    "dataset_size = 1000\n",
    "processed_cnn_dataset = CNNDataLoader(dataset_size).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text', 'prefix'],\n",
       "        num_rows: 1600\n",
       "    })\n",
       "    eval: Dataset({\n",
       "        features: ['label', 'text', 'prefix'],\n",
       "        num_rows: 200\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'text', 'prefix'],\n",
       "        num_rows: 200\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_cnn_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 1,\n",
       " 'article': '',\n",
       " 'prefix': 'Three members of the same family who died in a'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_cnn_dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article processed:\n",
      "\n",
      "--------------------\n",
      "\n",
      "\n",
      "Article processed:\n",
      "Three members of the same family who died in a static caravan from carbon monoxide poisoning would have been unconscious 'within minutes', investigators said today. The bodies of married couple John and Audrey Cook were discovered alongside their daughter, Maureen, at the mobile home they shared on Tremarle Home Park in Camborne, west Cornwall. The inquests have now opened into the deaths last Saturday, with investigators saying the three died along with the family's pet dog, of carbon monoxide \n",
      "--------------------\n",
      "\n",
      "\n",
      "Article processed:\n",
      "A rare meeting of U.N. Security Council heads of state, led for the first time by a U.S. president, adopted a resolution focused on stopping the spread of nuclear weapons Thursday. President Obama is the first U.S. leader to head a United Nations Security Council meeting. President Obama challenged the gathering -- which included leaders of nuclear powers including Russia, China, Great Britain and France -- to overcome cynicism against the goal of ridding the planet of nuclear arms. \"We harbor n\n",
      "--------------------\n",
      "\n",
      "\n",
      "Article processed:\n",
      "\n",
      "--------------------\n",
      "\n",
      "\n",
      "Article processed:\n",
      "\n",
      "--------------------\n",
      "\n",
      "\n",
      "Article processed:\n",
      "Cover-up: Former Archbishop Lord Hope allowed a paedophile priest to escape punishment for sex crimes, a judge's report claims . A former archbishop who failed to act on alleged crimes of a paedophile priest should be jailed, the abuser’s victims have said. Lord Hope, the former Archbishop of York, did not act on 19 occasions when allegations of abuse or inappropriate conduct by the priest were raised with him, a scathing report revealed yesterday. But despite that, Lord Hope remains as an honor\n",
      "--------------------\n",
      "\n",
      "\n",
      "Article processed:\n",
      "\n",
      "--------------------\n",
      "\n",
      "\n",
      "Article processed:\n",
      "TLC has pulled an episode of Cake Boss from future screening schedules after receiving complaints over the show's mishandling of a transgender guest star. The episode, which aired on Monday night, showed transgender Carmen Carerra, 27, who was born as a man, take part in a stunt that she believed was edited to look distasteful. The stunt involved Buddy 'Cake Boss' Valastro, the reality show's star, tricking Anthony 'Cousin Anthony' Bellifemine into believing that Miss Carerra was born as a woman\n",
      "--------------------\n",
      "\n",
      "\n",
      "Article processed:\n",
      "\n",
      "--------------------\n",
      "\n",
      "\n",
      "Article processed:\n",
      "'The lamps are going out all over Europe. We shall not see them lit again in our lifetime' Foreign Secretary Sir Edward Grey, August 3, 1914 . Prime Minister David Cameron is urging Britons to switch off their lights for an hour tomorrow evening to mark the 100th anniversary of Britain’s declaration of war on Germany in 1914. The Lights Out initiative will be the culmination of a day of commemorative events across the country and in Europe, with members of the Royal Family fully involved at home\n",
      "--------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_examples_samples = 10\n",
    "\n",
    "for i in range(nb_examples_samples):\n",
    "    # select a random article\n",
    "    #random_idx = np.random.randint(0, len(processed_cnn_dataset[\"train\"]))\n",
    "    print(\"Article processed:\")\n",
    "    print(processed_cnn_dataset[\"train\"][\"text\"][i])\n",
    "    print(\"--------------------\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample:\n",
      "{'label': 1, 'article': '', 'prefix': 'Three members of the same family who died in a'}\n",
      "--------------------\n",
      "\n",
      "\n",
      "Sample:\n",
      "{'label': 0, 'article': \"Three members of the same family who died in a static caravan from carbon monoxide poisoning would have been unconscious 'within minutes', investigators said today. The bodies of married couple John and Audrey Cook were discovered alongside their daughter, Maureen, at the mobile home they shared on Tremarle Home Park in Camborne, west Cornwall. The inquests have now opened into the deaths last Saturday, with investigators saying the three died along with the family's pet dog, of carbon monoxide \", 'prefix': 'Three members of the same family who died in a'}\n",
      "--------------------\n",
      "\n",
      "\n",
      "Sample:\n",
      "{'label': 0, 'article': 'A rare meeting of U.N. Security Council heads of state, led for the first time by a U.S. president, adopted a resolution focused on stopping the spread of nuclear weapons Thursday. President Obama is the first U.S. leader to head a United Nations Security Council meeting. President Obama challenged the gathering -- which included leaders of nuclear powers including Russia, China, Great Britain and France -- to overcome cynicism against the goal of ridding the planet of nuclear arms. \"We harbor n', 'prefix': 'A rare meeting of U.N. Security Council heads of state,'}\n",
      "--------------------\n",
      "\n",
      "\n",
      "Sample:\n",
      "{'label': 1, 'article': '', 'prefix': 'A rare meeting of U.N. Security Council heads of state,'}\n",
      "--------------------\n",
      "\n",
      "\n",
      "Sample:\n",
      "{'label': 1, 'article': '', 'prefix': 'Cover-up: Former Archbishop Lord Hope allowed a paedophile priest to'}\n",
      "--------------------\n",
      "\n",
      "\n",
      "Sample:\n",
      "{'label': 0, 'article': \"Cover-up: Former Archbishop Lord Hope allowed a paedophile priest to escape punishment for sex crimes, a judge's report claims . A former archbishop who failed to act on alleged crimes of a paedophile priest should be jailed, the abuser’s victims have said. Lord Hope, the former Archbishop of York, did not act on 19 occasions when allegations of abuse or inappropriate conduct by the priest were raised with him, a scathing report revealed yesterday. But despite that, Lord Hope remains as an honor\", 'prefix': 'Cover-up: Former Archbishop Lord Hope allowed a paedophile priest to'}\n",
      "--------------------\n",
      "\n",
      "\n",
      "Sample:\n",
      "{'label': 1, 'article': '', 'prefix': 'TLC has pulled an episode of Cake Boss from future'}\n",
      "--------------------\n",
      "\n",
      "\n",
      "Sample:\n",
      "{'label': 0, 'article': \"TLC has pulled an episode of Cake Boss from future screening schedules after receiving complaints over the show's mishandling of a transgender guest star. The episode, which aired on Monday night, showed transgender Carmen Carerra, 27, who was born as a man, take part in a stunt that she believed was edited to look distasteful. The stunt involved Buddy 'Cake Boss' Valastro, the reality show's star, tricking Anthony 'Cousin Anthony' Bellifemine into believing that Miss Carerra was born as a woman\", 'prefix': 'TLC has pulled an episode of Cake Boss from future'}\n",
      "--------------------\n",
      "\n",
      "\n",
      "Sample:\n",
      "{'label': 1, 'article': '', 'prefix': \"'The lamps are going out all over Europe. We shall\"}\n",
      "--------------------\n",
      "\n",
      "\n",
      "Sample:\n",
      "{'label': 0, 'article': \"'The lamps are going out all over Europe. We shall not see them lit again in our lifetime' Foreign Secretary Sir Edward Grey, August 3, 1914 . Prime Minister David Cameron is urging Britons to switch off their lights for an hour tomorrow evening to mark the 100th anniversary of Britain’s declaration of war on Germany in 1914. The Lights Out initiative will be the culmination of a day of commemorative events across the country and in Europe, with members of the Royal Family fully involved at home\", 'prefix': \"'The lamps are going out all over Europe. We shall\"}\n",
      "--------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_examples_samples = 10\n",
    "\n",
    "for i in range(nb_examples_samples):\n",
    "    # select a random article\n",
    "    #random_idx = np.random.randint(0, len(processed_cnn_dataset[\"train\"]))\n",
    "    print(\"Sample:\")\n",
    "    print(processed_cnn_dataset[\"train\"][i])\n",
    "    print(\"--------------------\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test an Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set generation parameters\n",
    "default_gen_params = {\n",
    "    #\"max_length\": 100,\n",
    "    \"max_new_tokens\": 100,\n",
    "    \"min_new_tokens\": 100,\n",
    "    \"temperature\": 0.8,\n",
    "    \"top_p\": 0.95,\n",
    "    \"repetition_penalty\": 1,\n",
    "    \"do_sample\": True,\n",
    "    \"top_k\": 50\n",
    "}\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marluxiaboss/anaconda3/envs/llm_detector/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "gen_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"Qwen/Qwen2-0.5B-Instruct\",\n",
    "    pad_token='<|extra_0|>',\n",
    "    eos_token='<|endoftext|>',\n",
    "    padding_side='left',\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "gen = AutoModelForCausalLM.from_pretrained(\n",
    "    \"Qwen/Qwen2-0.5B-Instruct\",\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\",\n",
    "    pad_token_id=gen_tokenizer.pad_token_id,\n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78f153baa0ec4634a40f69afad005131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gen_config = ModelConfig(gen_tokenizer,\n",
    "    use_chat_template=True, chat_template_type=\"system_user\", gen_params=default_gen_params, device=device)\n",
    "\n",
    "gen_model = LLMGenerator(gen, gen_config)\n",
    "\n",
    "system_prompt = \"You are a helpful assistant.\"\n",
    "user_prompt = \"Continue writing the following news article starting with:\"\n",
    "prompt_config = PromptConfig(system_prompt=system_prompt, user_prompt=user_prompt)\n",
    "\n",
    "\n",
    "text_gen_no_attack = PromptAttack(gen_model, gen_config, system_prompt, prompt_config)\n",
    "\n",
    "\n",
    "true_articles = processed_cnn_dataset[\"train\"].filter(lambda x: x[\"label\"] == 0)\n",
    "true_articles_prefixes = true_articles[\"prefix\"][:10]\n",
    "\n",
    "fake_articles = text_gen_no_attack.generate_adversarial_text(true_articles_prefixes, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True article: Three members of the same family who died in a static caravan from carbon monoxide poisoning would have been unconscious 'within minutes', investigators said today. The bodies of married couple John and Audrey Cook were discovered alongside their daughter, Maureen, at the mobile home they shared on Tremarle Home Park in Camborne, west Cornwall. The inquests have now opened into the deaths last Saturday, with investigators saying the three died along with the family's pet dog, of carbon monoxide \n",
      "Fake article: Three members of the same family who died in a  tragic car accident on Thursday evening have been identified by the family's lawyer. The accident occurred around 8:30 p.m. on the I-275 eastbound exit ramp near the intersection with I-40.\n",
      "The three victims, who were wearing black and white safety belts, were pronounced dead at the scene. The driver of the vehicle was taken to a local hospital for treatment of minor injuries. The driver of the car was also taken to a hospital for treatment of minor injuries\n",
      "\n",
      "\n",
      "True article: A rare meeting of U.N. Security Council heads of state, led for the first time by a U.S. president, adopted a resolution focused on stopping the spread of nuclear weapons Thursday. President Obama is the first U.S. leader to head a United Nations Security Council meeting. President Obama challenged the gathering -- which included leaders of nuclear powers including Russia, China, Great Britain and France -- to overcome cynicism against the goal of ridding the planet of nuclear arms. \"We harbor n\n",
      "Fake article: A rare meeting of U.N. Security Council heads of state,  with a focus on peacekeeping and refugee aid, has taken place in Geneva, Switzerland. The meeting, which began on Monday, is expected to provide a platform for countries to discuss ways to reduce tensions and prevent conflicts in the Middle East and other regions.\n",
      "The Security Council is a body of 15 countries that meets to discuss global issues and to make decisions on how to resolve conflicts. The meeting, which is being held for the first time, will be attended by representatives from 51 countries\n",
      "\n",
      "\n",
      "True article: Cover-up: Former Archbishop Lord Hope allowed a paedophile priest to escape punishment for sex crimes, a judge's report claims . A former archbishop who failed to act on alleged crimes of a paedophile priest should be jailed, the abuser’s victims have said. Lord Hope, the former Archbishop of York, did not act on 19 occasions when allegations of abuse or inappropriate conduct by the priest were raised with him, a scathing report revealed yesterday. But despite that, Lord Hope remains as an honor\n",
      "Fake article: Cover-up: Former Archbishop Lord Hope allowed a paedophile priest to  marry his daughter\n",
      "Former Archbishop Lord Hope has admitted that he allowed a paedophile priest to marry his daughter, which is considered a serious crime under current laws in the UK. The decision to allow the priest to marry the daughter was made after the Archbishop had been involved in a scandal involving a number of other priests and was reported to the police.\n",
      "The scandal involved a priest who had been accused of sexually abusing children, and the Archbishop had been involved in a cover-up to protect his own position as arch\n",
      "\n",
      "\n",
      "True article: TLC has pulled an episode of Cake Boss from future screening schedules after receiving complaints over the show's mishandling of a transgender guest star. The episode, which aired on Monday night, showed transgender Carmen Carerra, 27, who was born as a man, take part in a stunt that she believed was edited to look distasteful. The stunt involved Buddy 'Cake Boss' Valastro, the reality show's star, tricking Anthony 'Cousin Anthony' Bellifemine into believing that Miss Carerra was born as a woman\n",
      "Fake article: TLC has pulled an episode of Cake Boss from future , which was planned to air in the coming months. The news came as a surprise to many fans of the show, as the episode was scheduled to air in January. The company behind the show, TLC, has not commented on the decision, but it is not uncommon for shows to be canceled or delayed in the future as they adjust to changing schedules or seasons.\n",
      "\n",
      "There have been concerns about the show's popularity, which has declined in recent years due to competition from other cooking shows. However, the\n",
      "\n",
      "\n",
      "True article: 'The lamps are going out all over Europe. We shall not see them lit again in our lifetime' Foreign Secretary Sir Edward Grey, August 3, 1914 . Prime Minister David Cameron is urging Britons to switch off their lights for an hour tomorrow evening to mark the 100th anniversary of Britain’s declaration of war on Germany in 1914. The Lights Out initiative will be the culmination of a day of commemorative events across the country and in Europe, with members of the Royal Family fully involved at home\n",
      "Fake article: 'The lamps are going out all over Europe. We shall  be facing a crisis. The lack of electricity has made it difficult for people to light their homes, drive, and even go to work. In Germany, an estimated 12 million homes have been affected by the lack of electricity. In France, 7 million homes have been affected, and in the UK, 4 million homes have been affected. In Spain, 2 million homes have been affected. The situation is becoming more and more dire, and it is clear that we are facing a\n",
      "\n",
      "\n",
      "True article: Roy Hodgson has come under fire for making public Raheem Sterling's admission that he was feeling tired ahead of England's Euro 2016 qualifier with Estonia. The Liverpool star told the England manager that he was too fatigued to start the match in Tallinn after shouldering a heavy burden this season for both club and country. Hodgson then made Sterling's comments public ahead of the match, which England won 1-0 thanks to Wayne Rooney's second-half free-kick. VIDEO Scroll down to watch Roy Hodgso\n",
      "Fake article: Roy Hodgson has come under fire for making public Raheem  Sterling's \"offensive language\" following his controversial comments about Liverpool manager Jurgen Klopp.\n",
      "The comments came after Liverpool fans accused Hodgson of being racist towards the Englishman after his move to Manchester United in January.\n",
      "Hodgson was reported to have made the comments while speaking to a group of United fans in a pub in Dublin, and it sparked a storm of criticism from fans, including Liverpool supporters.\n",
      "In a statement, Hodgson said: \"I am shocked and disappointed by the comments made\n",
      "\n",
      "\n",
      "True article: Every frontline police officer should be offered a Taser to help fight the threat from lone-wolf terrorists, a police leader declared yesterday. Steve White, who chairs the Police Federation, said evidence of plans to murder officers made the move necessary. ‘The terrorist ideal to get attention no longer relies on an attack being in a place of note,’ he said. ‘It could be in Cheam high street, in any town, in any part of the UK. We know there are more dangerous people out there, preparing to at\n",
      "Fake article: Every frontline police officer should be offered a Taser to  address the issue of excessive use of force by law enforcement officers. According to the American Civil Liberties Union, excessive use of force by law enforcement is a major contributor to the high rate of criminal activity and violence in the United States. The use of Taser by police officers is a controversial issue that has been the subject of numerous protests and legal challenges. However, it is important to note that not all police officers are equipped with Taser technology, and many officers may not have access to the necessary equipment\n",
      "\n",
      "\n",
      "True article: By . Dan Bloom . It's one very, very small step for man - but a giant leap for antkind. Around 800 common ants, usually found pattering across pavements and picnics, have been sent to the International Space Station to teach scientists how they move in low gravity. Eight colonies each about the size of a tablet computer have been set up to teach experts how to build robots which interact with each other. Welcome: Nasa astronaut Rick Mastracchio greets 800 new friends aboard the International Spa\n",
      "Fake article: By . Dan Bloom . It's one very, very small  project, one that requires a lot of hard work, but it's one that's going to have a big impact on the world.\n",
      "\n",
      "The project is a small-scale recycling initiative that aims to reduce waste and promote sustainable living. The initiative involves collecting and sorting recyclable materials such as newspapers, plastic bottles, and aluminum cans. It's a small project, but it's important to keep in mind that even a small change can make a big difference.\n",
      "\n",
      "The initiative is being led by a group of individuals\n",
      "\n",
      "\n",
      "True article: A pensioner died from fatal injuries after being hit on the head by a cricket ball during a match. David Wilcockson, 71, was bowling at a ground in Cranleigh, Surrey when the batsman's shot struck him on the head. Players battled in vain to revive him after he slumped on the pitch unconscious and he was taken by air ambulance to King's College Hospital in London. David Wilcockson (pictured), 71, was bowling at a ground in Cranleigh, Surrey when the ball struck him on the head . Players battled i\n",
      "Fake article: A pensioner died from fatal injuries after being hit on  his way to the local park. The incident occurred on Sunday morning, when the pensioner was walking along a busy road when he suddenly fell and hit a tree. He was taken to the hospital but unfortunately, he was pronounced dead on arrival. The pensioner's family have since expressed their shock and grief at the tragic loss of their loved one. The park where the accident occurred is currently closed and the police are investigating the incident. The local council has also expressed its condolences to the family and is\n",
      "\n",
      "\n",
      "True article: Workers digging an underground garage for a new hotel  recently struck something big about 30 feet below the surface. This week they uncovered it - a boulder that's thousands of years old and bigger than an SUV, weighing an estimated 150 tons or 300,000lbs. A geotechnical engineer who was called out to examine the giant rock in Everett, Washington. The rock, which weighs 150 tons and is bigger than an SUV was discovered in Everett, Washington. It is believed that a glacier left the 'erratic rock\n",
      "Fake article: Workers digging an underground garage for a new hotel recently  reported the news to their colleagues. The excavation was completed successfully, and the team was excited to see the new hotel. They were confident that the underground garage would be a major asset for the hotel, and the workers were looking forward to adding it to their project. The team had planned to use the garage for temporary storage, but the news of its completion brought them all back to reality. They had been working hard for months to excavate the site, and they were finally able to complete the task\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "true_articles_sample = true_articles[\"article\"][:10]\n",
    "for i in range(len(true_articles_sample)):\n",
    "    print(\"True article:\", true_articles_sample[i])\n",
    "    print(\"Fake article:\", fake_articles[i])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marluxiaboss/anaconda3/envs/llm_detector/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "dataset_size = 100\n",
    "cnn_data_loader = CNNDataLoader(dataset_size)\n",
    "\n",
    "\n",
    "# generator\n",
    "\n",
    "# set generation parameters\n",
    "default_gen_params = {\n",
    "    #\"max_length\": 100,\n",
    "    \"max_new_tokens\": 100,\n",
    "    \"min_new_tokens\": 100,\n",
    "    \"temperature\": 0.8,\n",
    "    \"top_p\": 0.95,\n",
    "    \"repetition_penalty\": 1,\n",
    "    \"do_sample\": True,\n",
    "    \"top_k\": 50\n",
    "}\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "gen_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"Qwen/Qwen2-0.5B-Instruct\",\n",
    "    pad_token='<|extra_0|>',\n",
    "    eos_token='<|endoftext|>',\n",
    "    padding_side='left',\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "gen = AutoModelForCausalLM.from_pretrained(\n",
    "    \"Qwen/Qwen2-0.5B-Instruct\",\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\",\n",
    "    pad_token_id=gen_tokenizer.pad_token_id,\n",
    ").to(device)\n",
    "\n",
    "gen_config = ModelConfig(gen_tokenizer,\n",
    "    use_chat_template=True, chat_template_type=\"system_user\", gen_params=default_gen_params, device=device)\n",
    "\n",
    "gen_model = LLMGenerator(gen, gen_config)\n",
    "\n",
    "system_prompt = \"You are a helpful assistant.\"\n",
    "user_prompt = \"Continue writing the following news article starting with:\"\n",
    "prompt_config = PromptConfig(system_prompt=system_prompt, user_prompt=user_prompt)\n",
    "\n",
    "\n",
    "text_gen_no_attack = PromptAttack(gen_model, gen_config, system_prompt, prompt_config)\n",
    "\n",
    "text_gen_no_attack.set_attack_name(\"no_attack\")\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "detector_path = \"google/electra-large-discriminator\"\n",
    "config = AutoConfig.from_pretrained(detector_path)\n",
    "detector_model = ElectraForSequenceClassification(config)\n",
    "bert_tokenizer = ElectraTokenizer.from_pretrained(detector_path)\n",
    "\n",
    "\n",
    "\n",
    "model_path = \"../saved_training_logs_experiment_2/electra_large/full_finetuning/fake_true_dataset_round_robin_10k/10_06_1308/saved_models/best_model.pt\"\n",
    "detector_model.load_state_dict(torch.load(model_path))\n",
    "detector_model.to(device)\n",
    "\n",
    "# threshold on the classifier softmaxed logits\n",
    "detection_threshold = 0.5\n",
    "detector = BertDetector(detector_model, bert_tokenizer, device, detection_threshold=detection_threshold)\n",
    "\n",
    "\n",
    "skip_cache = False\n",
    "simple_test_pipeline = ExperimentTestPipeline(cnn_data_loader, text_gen_no_attack, detector, device, \"benchmark_saved_results\", skip_cache=skip_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cnn_dailymail_no_attack already exists, loading it\n",
      "Classifying the articles...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42f902bd35674bd0af0c29ac13ce8021",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detecting...: 100%|██████████| 20/20 [00:04<00:00,  4.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average metrics:  {'accuracy': 0.84795, 'precision': 0.7663985216838545, 'recall': 1.0, 'f1_score': 0.862762629767672, 'fp_rate': 0.3023178210678211, 'tp_rate': 1.0}\n",
      "Standard deviation of metrics:  {'accuracy': 0.07888787929713917, 'precision': 0.11537122071282278, 'recall': 0.0, 'f1_score': 0.07669503854760946, 'fp_rate': 0.14694976332848445, 'tp_rate': 0.0}\n",
      "Test metrics:\n",
      "accuracy: 0.84795\n",
      "precision: 0.7663985216838545\n",
      "recall: 1.0\n",
      "f1_score: 0.862762629767672\n",
      "fp_rate: 0.3023178210678211\n",
      "tp_rate: 1.0\n",
      "std_accuracy: 0.07888787929713917\n",
      "std_precision: 0.11537122071282278\n",
      "std_recall: 0.0\n",
      "std_f1_score: 0.07669503854760946\n",
      "std_fp_rate: 0.14694976332848445\n",
      "std_tp_rate: 0.0\n",
      "TP: 9.912\n",
      "TN: 7.047\n",
      "FP: 3.041\n",
      "FN: 0.0\n",
      "roc_auc: 0\n",
      "fpr: [0.]\n",
      "tpr: [0.]\n",
      "thresholds: [0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average metrics:  {'accuracy': 0.5049, 'precision': 0.5049, 'recall': 1.0, 'f1_score': 0.6637278968167635, 'fp_rate': 1.0, 'tp_rate': 1.0}\n",
      "Standard deviation of metrics:  {'accuracy': 0.1109098282389798, 'precision': 0.1109098282389798, 'recall': 0.0, 'f1_score': 0.09929703240285644, 'fp_rate': 0.0, 'tp_rate': 0.0}\n",
      "Test metrics at specific given threshold:\n",
      "accuracy: 0.5049\n",
      "precision: 0.5049\n",
      "recall: 1.0\n",
      "f1_score: 0.6637278968167635\n",
      "fp_rate: 1.0\n",
      "tp_rate: 1.0\n",
      "std_accuracy: 0.1109098282389798\n",
      "std_precision: 0.1109098282389798\n",
      "std_recall: 0.0\n",
      "std_f1_score: 0.09929703240285644\n",
      "std_fp_rate: 0.0\n",
      "std_tp_rate: 0.0\n",
      "TP: 10.098\n",
      "TN: 0.0\n",
      "FP: 9.902\n",
      "FN: 0.0\n"
     ]
    }
   ],
   "source": [
    "simple_test_pipeline.run_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Watermarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marluxiaboss/anaconda3/envs/llm_detector/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from watermark.auto_watermark import AutoWatermark\n",
    "\n",
    "default_gen_params = {\n",
    "    #\"max_length\": 100,\n",
    "    \"max_new_tokens\": 100,\n",
    "    \"min_new_tokens\": 100,\n",
    "    \"temperature\": 0.8,\n",
    "    \"top_p\": 0.95,\n",
    "    \"repetition_penalty\": 1,\n",
    "    \"do_sample\": True,\n",
    "    \"top_k\": 50\n",
    "}\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "gen_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"Qwen/Qwen2-0.5B-Instruct\",\n",
    "    pad_token='<|extra_0|>',\n",
    "    eos_token='<|endoftext|>',\n",
    "    padding_side='left',\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "gen = AutoModelForCausalLM.from_pretrained(\n",
    "    \"Qwen/Qwen2-0.5B-Instruct\",\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\",\n",
    "    pad_token_id=gen_tokenizer.pad_token_id,\n",
    ").to(device)\n",
    "\n",
    "gen_config = ModelConfig(gen_tokenizer,\n",
    "    use_chat_template=True, chat_template_type=\"system_user\", gen_params=default_gen_params, device=device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "myWatermark = AutoWatermark.load('KGW', \n",
    "                                 algorithm_config='config/KGW.json',\n",
    "                                 gen_model=gen,\n",
    "                                 model_config=gen_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Good morning, and welcome back to the New York Times Best Sellers list. It\\'s 4:00 in the afternoon and it\\'s time for a look at what\\'s trending in bookstores across the country. We\\'re looking at the top titles, and I\\'m Jon Cale. We\\'re bringing you an insider\\'s look at what\\'s on the best sellers list today. Good evening. Thank you.\\nHere\\'s what I\\'m looking at:\\n\"War of the Worlds\" by Isaac Asimov.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"Good morning\"\n",
    "watermarked_text = myWatermark.generate_watermarked_text(prompt)\n",
    "watermarked_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'is_watermarked': True, 'score': 5.273697108112943}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_result = myWatermark.detect_watermark(watermarked_text)\n",
    "detect_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_detector",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
