{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class Scorer(ABC):\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        \n",
    "    @abstractmethod \n",
    "    def score(self, eval_text: str, ref_text: str) -> float:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sem score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marluxiaboss/anaconda3/envs/llm_detector/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "431c00c8e8ba4ed7966ce826b0bfc861",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d334ec8c72734b90bba744b1d02a345c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b683071133584b499a4b238c28309916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86f16dae2a354f7f85b386896f9752db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72bd7822c8d243e18cd87bd5dc5966ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marluxiaboss/anaconda3/envs/llm_detector/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e3e775904c245daa13c0a8c55ff1690",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-mpnet-base-v2')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine-Similarity: 0.4191148579120636\n"
     ]
    }
   ],
   "source": [
    "human_ref_text = \"Three members of the same family who died in a static caravan from carbon monoxide poisoning would have been unconscious 'within minutes', investigators said today. The bodies of married couple John and Audrey Cook were discovered alongside their daughter, Maureen, at the mobile home they shared on Tremarle Home Park in Camborne, west Cornwall. The inquests have now opened into the deaths last Saturday, with investigators saying the three died along with the family's pet dog, of carbon monoxide \"\n",
    "ai_text = \"Three members of the same family who died in a tragic accident in a remote mountain village in the Himalayas have been identified as siblings. The incident occurred on January 16, 2023, when a group of climbers from the same family fell into a ravine while exploring the mountain. The climbers were on a hike to the top of a mountain when they fell and were unable to climb out of the ravine. The family members were rushed to the hospital but were not able to survive the accident. The cause of the \"\n",
    "#human_ref_text = \"apple\"\n",
    "#ai_text = \"car\"\n",
    "\n",
    "tokenized_text = tokenizer([human_ref_text, ai_text], padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "with torch.no_grad():\n",
    "    model_output = model(**tokenized_text)\n",
    "    \n",
    "embeds = mean_pooling(model_output, tokenized_text['attention_mask'])\n",
    "sentence_embeddings = F.normalize(embeds, p=2, dim=1)\n",
    "\n",
    "# compute cosine-similarity\n",
    "cosine_scores = F.cosine_similarity(sentence_embeddings[0].unsqueeze(0), sentence_embeddings[1].unsqueeze(0))\n",
    "print(\"Cosine-Similarity:\", cosine_scores.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BertScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marluxiaboss/anaconda3/envs/llm_detector/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.1106])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bert_score\n",
    "cands = [ai_text]\n",
    "refs = [human_ref_text]\n",
    "model = \"microsoft/deberta-xlarge-mnli\"\n",
    "num_layers = 40\n",
    "precision, recall, f1_score = bert_score.score(cands, refs, lang='en', model_type=model, num_layers=num_layers, rescale_with_baseline=True)\n",
    "f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Three members of the same family who died in a tragic accident in a remote mountain village in the Himalayas have been identified as siblings. The incident occurred on January 16, 2023, when a group of climbers from the same family fell into a ravine while exploring the mountain. The climbers were on a hike to the top of a mountain when they fell and were unable to climb out of the ravine. The family members were rushed to the hospital but were not able to survive the accident. The cause of the '"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Three members of the same family who died in a static caravan from carbon monoxide poisoning would have been unconscious 'within minutes', investigators said today. The bodies of married couple John and Audrey Cook were discovered alongside their daughter, Maureen, at the mobile home they shared on Tremarle Home Park in Camborne, west Cornwall. The inquests have now opened into the deaths last Saturday, with investigators saying the three died along with the family's pet dog, of carbon monoxide \""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_ref_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marluxiaboss/anaconda3/envs/llm_detector/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/marluxiaboss/anaconda3/envs/llm_detector/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.1105894222855568, 0.4191148579120636)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bert_score\n",
    "\n",
    "class BertScoreScorer(Scorer):\n",
    "    def __init__(self, name):\n",
    "        super().__init__(name)\n",
    "        \n",
    "        self.model = \"microsoft/deberta-xlarge-mnli\"\n",
    "        self.num_layers = 40\n",
    "        \n",
    "    def score(self, eval_text: str, ref_text: str) -> float:\n",
    "        cands = [eval_text]\n",
    "        refs = [ref_text]\n",
    "        precision, recall, f1_score = bert_score.score(cands, refs, lang='en', model_type=self.model, num_layers=self.num_layers, rescale_with_baseline=True)\n",
    "        return f1_score.item()\n",
    "    \n",
    "class SemScoreScorer(Scorer):\n",
    "    def __init__(self, name):\n",
    "        super().__init__(name)\n",
    "        \n",
    "        self.tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-mpnet-base-v2')\n",
    "        self.model = AutoModel.from_pretrained('sentence-transformers/all-mpnet-base-v2')        \n",
    "        \n",
    "    def mean_pooling(model_output, attention_mask):\n",
    "        token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    \n",
    "    def score(self, eval_text: str, ref_text: str) -> float:\n",
    "        tokenized_text = self.tokenizer([ref_text, eval_text], padding=True, truncation=True, return_tensors='pt')\n",
    "        with torch.no_grad():\n",
    "            model_output = self.model(**tokenized_text)\n",
    "        embeds = mean_pooling(model_output, tokenized_text['attention_mask'])\n",
    "        sentence_embeddings = F.normalize(embeds, p=2, dim=1)\n",
    "        cosine_scores = F.cosine_similarity(sentence_embeddings[0].unsqueeze(0), sentence_embeddings[1].unsqueeze(0))\n",
    "        return cosine_scores.item()\n",
    "    \n",
    "bert_scorer = BertScoreScorer(\"bert_score\")\n",
    "score_bert = bert_scorer.score(ai_text, human_ref_text)\n",
    "\n",
    "sem_scorer = SemScoreScorer(\"semantic_score\")\n",
    "score_sem = sem_scorer.score(ai_text, human_ref_text)\n",
    "\n",
    "score_bert, score_sem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "        \n",
    "\n",
    "class IDFScorer(Scorer):\n",
    "    \n",
    "    def __init__(self, name, corpus: list[str]):\n",
    "        super().__init__(name)\n",
    "        self.corpus = corpus\n",
    "        \n",
    "        nltk.download('stopwords')\n",
    "        \n",
    "        # remove stopwords from the corpus\n",
    "        filtered_corpus = self.remove_stopwords(self.corpus)\n",
    "        self.filtered_corpus = filtered_corpus\n",
    "        \n",
    "        # Initialize and fit the TfidfVectorizer\n",
    "        # Note: Sk learn's TF-IDF does log(N_doc / N_doc where term appear + 1) \n",
    "        # where N_doc and N_doc where term appear include the eval_sentence.\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        vectorizer.fit(filtered_corpus)\n",
    "        \n",
    "        # Create a dictionary mapping words to their IDF values\n",
    "        feature_names = vectorizer.get_feature_names_out()\n",
    "        idf_values = vectorizer.idf_\n",
    "        self.word_to_idf = dict(zip(feature_names, idf_values))\n",
    "        \n",
    "    def remove_stopwords(self, corpus: list[str]):\n",
    "        \n",
    "        filtered_corpus = []\n",
    "        # Remove stopwords from the corpus\n",
    "        for sentence in corpus:\n",
    "            tokenized_sentence = sentence.split()\n",
    "            filtered_sentence = [word for word in tokenized_sentence if word not in stopwords.words('english')]\n",
    "            filtered_corpus.append(\" \".join(filtered_sentence))\n",
    "            \n",
    "        # drop empty sentences\n",
    "        filtered_corpus = [sentence for sentence in filtered_corpus if sentence]\n",
    "        \n",
    "        return filtered_corpus\n",
    "        \n",
    "    def score(self, eval_text: str) -> float:\n",
    "        \n",
    "        filtered_eval_text = self.remove_stopwords([eval_text])[0]\n",
    "        \n",
    "        # Compute the average IDF of the words in the sentence\n",
    "        tokenized_sentence = filtered_eval_text.split()\n",
    "        idfs = [self.word_to_idf.get(word, 0) for word in tokenized_sentence]\n",
    "        average_idf = np.mean(idfs)\n",
    "        median_idf = np.median(idfs)\n",
    "        \n",
    "        return median_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9526531601278915"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf_scorer = IDFScorer(\"idf_score\", [human_ref_text, ai_text])\n",
    "\n",
    "score_idf = idf_scorer.score(ai_text)\n",
    "score_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "cnn_dailymail = load_dataset(\"cnn_dailymail\", \"3.0.0\")[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_scorer_1000 = IDFScorer(\"idf_score\", cnn_dailymail[\"article\"][:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.131108185680104, 1.2018924427124735)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_text = \"TLC has pulled an episode of Cake Boss from future screening schedules after receiving complaints over the show's mishandling of a transgender guest star. The episode, which aired on Monday night, showed transgender Carmen Carerra, 27, who was born as a man, take part in a stunt that she believed was edited to look distasteful. The stunt involved Buddy 'Cake Boss' Valastro, the reality show's star, tricking Anthony 'Cousin Anthony' Bellifemine into believing that Miss Carerra was born as a woman\"\n",
    "ai_text = \"TLC has pulled an episode of Cake Boss from future due to an issue that requires a significant amount of editing and rework. \\nThe episode had originally been released earlier this year and had gained critical acclaim for the way it played out. However, after a more thorough review, it emerged that there had been some creative issues with the show that needed to be addressed. This included a deletion of characters and shots that had come to the fore when the episode was produced. It was hoped tha\"\n",
    "\n",
    "idf_scorer_1000.score(human_text), idf_scorer.score(ai_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many articles do we need to sample from the corpus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.1283880153018644, 1.2018924427124735)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf_scorer_10000 = IDFScorer(\"idf_score\", cnn_dailymail[\"article\"][:10000])\n",
    "\n",
    "idf_scorer_10000.score(human_text), idf_scorer.score(ai_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/marluxiaboss/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_177838/1128237060.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0midf_scorer_full\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIDFScorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"idf_score\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnn_dailymail\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"article\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0midf_scorer_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhuman_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midf_scorer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mai_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_177838/2494736891.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, eval_text)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_text\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mfiltered_eval_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove_stopwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0meval_text\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# Compute the average IDF of the words in the sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_177838/2494736891.py\u001b[0m in \u001b[0;36mremove_stopwords\u001b[0;34m(self, corpus)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# Remove stopwords from the corpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mtokenized_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0mfiltered_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenized_sentence\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mfiltered_corpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "idf_scorer_full = IDFScorer(\"idf_score\", cnn_dailymail[\"article\"][:1000])\n",
    "\n",
    "idf_scorer_full.score(human_text), idf_scorer.score(ai_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.chdir(\"../\")\n",
    "\n",
    "SRC_PATH = [\"src\"]\n",
    "for module_path in SRC_PATH:\n",
    "    if module_path not in sys.path:\n",
    "        sys.path.append(module_path)\n",
    "\n",
    "from text_quality_evalution import BertScoreScorer\n",
    "\n",
    "bert_scorer = BertScoreScorer(\"bert_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"A school nurse accused of failing to properly raise the alarm after a student suffered an allergic reaction has been placed on administrative leave by the school district. The student, who has a severe peanut allergy, reportedly experienced symptoms such as hives and difficulty breathing after consuming a snack provided by the nurse during a field trip. According to witnesses, the nurse initially dismissed the student's complaints and did not administer epinephrine, a life-saving medication for \",\n",
       " 'Shopping in the Chinese city of Shenyang is very similar to that of any bustling metropolis, with a wide array of options for both locals and tourists alike. From high-end malls to traditional markets, Shenyang has something for every shopper.\\n\\nOne of the most popular destinations for shopping in Shenyang is the Taiyanggong Metro Plaza, which boasts over 200 stores spread over six floors. The mall features well-known international brands as well as popular Chinese retailers, making it a one-stop',\n",
       " \"Juana Vidal yearns to reunite with her undocumented immigrant son , who has been held in a detention center in Arizona for the past three months. Vidal, a U.S. Citizen, has been fighting tirelessly to secure her son's release, but has faced numerous obstacles in the process.\\n\\nThe story of Vidal and her son, Carlos, has gained national attention as the Trump administration's immigration policies continue to come under scrutiny. Vidal's lawyer, Daniel Derckser, claims that her son's detention is u\",\n",
       " 'Promoters of a dance festival where a young woman died on Saturday night have released a statement offering their condolences and assuring attendees that an investigation is underway to determine the circumstances surrounding the tragic incident.\\n\\nIn a statement posted on social media, the festival organizers expressed their deepest sympathies to the family and friends of the victim, whose name has not been released, and acknowledged the shock and distress that the incident has caused.\\n\\nThe stat',\n",
       " \"Today, you get a call from a friend. They need your expert opinion on a matter that they've been grappling with for some time now. As you listen intently to their concerns, you can sense the urgency and seriousness in their voice. You feel a sense of responsibility to provide them with the best possible advice, and you know that your friend is relying on you to guide them through this tough situation. As the conversation progresses, you carefully weigh your words, ensuring that you're providing \",\n",
       " 'Prostitution and drug dealing provide a £10billion boost to the UK economy, according to a groundbreaking new report by leading academics. The study challenges the commonly held belief that these activities are purely criminal and argues they should be regulated and taxed like any other industry.\\n\\nThe research, commissioned by the English Collective of Prostitutes (ECP), found that prostitution generates around £6.2bn a year for the UK economy and drug use, including sales, produces a further £3',\n",
       " 'The UK is one of the most vulnerable countries in the world when it comes to the impacts of climate change, according to a report by the Global Climate Risk Index published by Germanwatch and the climate risk analysis group, CARE International. The report ranks countries based on their exposure and vulnerability to climate-related disasters and adaptation challenges.\\n\\nThe UK has been consistently ranked among the top 10 countries most affected by climate change in recent years, and this year is ',\n",
       " 'Craig Bellamy has returned to Cardiff City as an academy coach, nearly a decade after leaving the Welsh club as a player. The former Wales international spent two spells with Cardiff, scoring 77 goals in 198 appearances across two separate stints. Bellamy, who retired from playing in 2014, joins the Bluebirds academy staff as part of the under-18 set-up. \"I\\'m really excited to be back at Cardiff City,\" Bellamy said in a statement released by the club. \"I\\'ve missed the environment and the buzz th',\n",
       " \"If you're planning to move house, you may wish to consider hiring a professional packing service to help you make the transition as smooth and stress-free as possible. Moving can be an overwhelming and time-consuming process, and many people find themselves struggling to pack all their belongings in a timely and organized manner.\\n\\nPacking services are becoming increasingly popular as more and more people recognize the benefits they offer. These services can range from full-service packing, where\",\n",
       " \"While his namesake Cristiano Ronaldo was collecting a third Ballon d'Or award in Zurich on Monday night, another Portuguese talent was making a name for himself in the Premier League.\\nRonaldo Nazário de Lima, known simply as Ronaldo to football fans, marked his first start for Stoke City with a brace in their 3-2 win over Everton at the Britannia Stadium.\\nThe 36-year-old, who began his career at Sporting Lisbon and went on to become one of the greatest players of his generation at Barcelona and \"]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "dataset_test = load_from_disk(\"test_notebooks/zephyr_compare_watermark\")\n",
    "ai_dataset_test = dataset_test[\"test\"].filter(lambda sample: sample[\"label\"] == 1)\n",
    "human_dataset_test = dataset_test[\"test\"].filter(lambda sample: sample[\"label\"] == 0)\n",
    "\n",
    "ai_texts = ai_dataset_test[\"text\"][:]\n",
    "human_texts = human_dataset_test[\"text\"][:]\n",
    "\n",
    "ai_texts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# human_text\n",
    "scores_human = []\n",
    "for text in human_text:\n",
    "    score = idf_scorer_full.score(text)\n",
    "    scores_human.append(score)\n",
    "\n",
    "scores_ai = []\n",
    "for text in ai_texts:\n",
    "    score = idf_scorer_full.score(text)\n",
    "    scores_ai.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(498, 499)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scores_human), len(scores_ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average IDF score for human texts: 1.7691867598289848\n",
      "Average IDF score for AI texts: 2.253120445815108\n",
      "\n",
      "Median IDF score for human texts: 2.2096599006003443\n",
      "Median IDF score for AI texts: 2.6054498712561447\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average IDF score for human texts: {np.mean(scores_human)}\")\n",
    "print(f\"Average IDF score for AI texts: {np.mean(scores_ai)}\")\n",
    "print()\n",
    "print(f\"Median IDF score for human texts: {np.median(scores_human)}\")\n",
    "print(f\"Median IDF score for AI texts: {np.median(scores_ai)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>prefix</th>\n",
       "      <th>generation_config</th>\n",
       "      <th>watermark_config</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A school nurse accused of failing to properly ...</td>\n",
       "      <td>A school nurse accused of failing to properly ...</td>\n",
       "      <td>{'attack_name': 'no_attack', 'attack_type': 'n...</td>\n",
       "      <td>{'algorithm_name': 'no_watermark'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Shopping in the Chinese city of Shenyang is ve...</td>\n",
       "      <td>Shopping in the Chinese city of Shenyang is ve...</td>\n",
       "      <td>{'attack_name': 'no_attack', 'attack_type': 'n...</td>\n",
       "      <td>{'algorithm_name': 'no_watermark'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Shopping in the Chinese city of Shenyang is ve...</td>\n",
       "      <td>Shopping in the Chinese city of Shenyang is ve...</td>\n",
       "      <td>{'attack_name': 'no_attack', 'attack_type': 'n...</td>\n",
       "      <td>{'algorithm_name': 'no_watermark'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Juana Vidal yearns to reunite with her undocum...</td>\n",
       "      <td>Juana Vidal yearns to reunite with her undocum...</td>\n",
       "      <td>{'attack_name': 'no_attack', 'attack_type': 'n...</td>\n",
       "      <td>{'algorithm_name': 'no_watermark'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Juana Vidal yearns to reunite with her undocum...</td>\n",
       "      <td>Juana Vidal yearns to reunite with her undocum...</td>\n",
       "      <td>{'attack_name': 'no_attack', 'attack_type': 'n...</td>\n",
       "      <td>{'algorithm_name': 'no_watermark'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>1</td>\n",
       "      <td>A 17-year-old girl who was found lying on the ...</td>\n",
       "      <td>A 17-year-old girl who was found lying on the ...</td>\n",
       "      <td>{'attack_name': 'no_attack', 'attack_type': 'n...</td>\n",
       "      <td>{'algorithm_name': 'no_watermark'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>0</td>\n",
       "      <td>Faced with months of roadworks and a 14-mile d...</td>\n",
       "      <td>Faced with months of roadworks and a 14-mile d...</td>\n",
       "      <td>{'attack_name': 'no_attack', 'attack_type': 'n...</td>\n",
       "      <td>{'algorithm_name': 'no_watermark'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>1</td>\n",
       "      <td>Faced with months of roadworks and a 14-mile d...</td>\n",
       "      <td>Faced with months of roadworks and a 14-mile d...</td>\n",
       "      <td>{'attack_name': 'no_attack', 'attack_type': 'n...</td>\n",
       "      <td>{'algorithm_name': 'no_watermark'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0</td>\n",
       "      <td>Rare pictures of the U.S. Navy taken during th...</td>\n",
       "      <td>Rare pictures of the U.S. Navy taken during th...</td>\n",
       "      <td>{'attack_name': 'no_attack', 'attack_type': 'n...</td>\n",
       "      <td>{'algorithm_name': 'no_watermark'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1</td>\n",
       "      <td>Rare pictures of the U.S. Navy taken during th...</td>\n",
       "      <td>Rare pictures of the U.S. Navy taken during th...</td>\n",
       "      <td>{'attack_name': 'no_attack', 'attack_type': 'n...</td>\n",
       "      <td>{'algorithm_name': 'no_watermark'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>997 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text  \\\n",
       "0        1  A school nurse accused of failing to properly ...   \n",
       "1        1  Shopping in the Chinese city of Shenyang is ve...   \n",
       "2        0  Shopping in the Chinese city of Shenyang is ve...   \n",
       "3        0  Juana Vidal yearns to reunite with her undocum...   \n",
       "4        1  Juana Vidal yearns to reunite with her undocum...   \n",
       "..     ...                                                ...   \n",
       "992      1  A 17-year-old girl who was found lying on the ...   \n",
       "993      0  Faced with months of roadworks and a 14-mile d...   \n",
       "994      1  Faced with months of roadworks and a 14-mile d...   \n",
       "995      0  Rare pictures of the U.S. Navy taken during th...   \n",
       "996      1  Rare pictures of the U.S. Navy taken during th...   \n",
       "\n",
       "                                                prefix  \\\n",
       "0    A school nurse accused of failing to properly ...   \n",
       "1    Shopping in the Chinese city of Shenyang is ve...   \n",
       "2    Shopping in the Chinese city of Shenyang is ve...   \n",
       "3    Juana Vidal yearns to reunite with her undocum...   \n",
       "4    Juana Vidal yearns to reunite with her undocum...   \n",
       "..                                                 ...   \n",
       "992  A 17-year-old girl who was found lying on the ...   \n",
       "993  Faced with months of roadworks and a 14-mile d...   \n",
       "994  Faced with months of roadworks and a 14-mile d...   \n",
       "995  Rare pictures of the U.S. Navy taken during th...   \n",
       "996  Rare pictures of the U.S. Navy taken during th...   \n",
       "\n",
       "                                     generation_config  \\\n",
       "0    {'attack_name': 'no_attack', 'attack_type': 'n...   \n",
       "1    {'attack_name': 'no_attack', 'attack_type': 'n...   \n",
       "2    {'attack_name': 'no_attack', 'attack_type': 'n...   \n",
       "3    {'attack_name': 'no_attack', 'attack_type': 'n...   \n",
       "4    {'attack_name': 'no_attack', 'attack_type': 'n...   \n",
       "..                                                 ...   \n",
       "992  {'attack_name': 'no_attack', 'attack_type': 'n...   \n",
       "993  {'attack_name': 'no_attack', 'attack_type': 'n...   \n",
       "994  {'attack_name': 'no_attack', 'attack_type': 'n...   \n",
       "995  {'attack_name': 'no_attack', 'attack_type': 'n...   \n",
       "996  {'attack_name': 'no_attack', 'attack_type': 'n...   \n",
       "\n",
       "                       watermark_config  \n",
       "0    {'algorithm_name': 'no_watermark'}  \n",
       "1    {'algorithm_name': 'no_watermark'}  \n",
       "2    {'algorithm_name': 'no_watermark'}  \n",
       "3    {'algorithm_name': 'no_watermark'}  \n",
       "4    {'algorithm_name': 'no_watermark'}  \n",
       "..                                  ...  \n",
       "992  {'algorithm_name': 'no_watermark'}  \n",
       "993  {'algorithm_name': 'no_watermark'}  \n",
       "994  {'algorithm_name': 'no_watermark'}  \n",
       "995  {'algorithm_name': 'no_watermark'}  \n",
       "996  {'algorithm_name': 'no_watermark'}  \n",
       "\n",
       "[997 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test_df = dataset_test[\"test\"].to_pandas()\n",
    "dataset_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('\"Dancing with the Stars\" got off to a fresh start Monday with actor Alfonso Ribeiro taking the lead in the season 19 premiere. The episode was the debut of the new cast, which includes \"Fresh Prince\" star Ribeiro, comedian Tommy Chong, athlete Lolo Jones, \"Duck Dynasty\" star Sadie Robertson and more. Performing a jive with pro partner Witney Carson, Ribeiro got a standing ovation for his moves. Judge Julianne Hough, herself a former \"Dancing with the Stars\" pro, said she was \"blown away,\" and he',\n",
       "  '\"Dancing with the Stars\" got off to a fresh start Monday night, kicking off its 29th season with a glittering premiere packed with new celebrity contestants, dazzling routines, and high-energy performances from the show\\'s talented pros.\\n\\nHost Tyra Banks brought her signature style and infectious energy to the ballroom, while judges Carrie Ann Inaba, Bruno Tonioli, and Derek Hough returned to their seats, ready to critique the dancers\\' moves.\\n\\nThe night\\'s standout performances included \"Bachelore'),\n",
       " ('\"Keep your feet on the ground, and keep reaching for the stars.\" That signature sign-off of Casey Kasem\\'s was recalled by fans of his syndicated weekend radio show \"American Top 40\" Sunday after the legendary disc jockey died at the age of 82. Kasem began that show in 1970 and hosted it and variations of it until finally ending his radio career in 2009. But for more than just those encouraging words, Kasem will be remembered for helping to elevate the radio disc jockey gig to one of storyteller ',\n",
       "  '\"Keep your feet on the ground, and keep reaching for the stars\" - this inspiring mantra has guided countless individuals to achieve their dreams and overcome obstacles. Now, a new study has found that this phrase might have more than just a figurative meaning when it comes to success.\\n\\nAccording to the research, individuals who maintain a strong sense of groundedness and connection to their surroundings are more likely to achieve their goals and feel a greater sense of fulfillment in their lives'),\n",
       " (\"$16.19, according to the Pittsburgh Post-Gazette. Disguised as a nurse, Moore walked into the hospital and wandered the halls, before finding Rhonda King, 27, in her hospital room with Bryce, her newborn son. 'She said she was taking the baby to get a checkup, that she would bring the baby right back,' Thelma Broughton, Bryce's grandmother, told the Post-Gazette at the time. Ms King willingly handed over the infant, believing Moore was a nurse. 'But she never came back,' Ms Broughton said. Bryce\",\n",
       "  '$16.19, according to the Pittsburgh Post-Gazette. Disguised as a nurse, a brazen thief made off with an expensive piece of medical equipment from the intensive care unit of a local hospital. The device, a state-of-the-art ventilator, is worth over $50,000 and is crucial for the survival of critically ill patients.\\n\\nThe heist, which occurred in the early hours of Tuesday morning, left hospital staff reeling. \"We\\'re baffled. This is a high-security area, and we have strict protocols in place. Yet '),\n",
       " (\"'Bemused': The IPCC today criticised the decision to give PC Shaun Jenkins his job back after having sex while on duty in Caerphilly, South Wales . An armed policeman who had sex with a married woman while on duty has been allowed to keep his job because his gun was within reach – attached to the trousers which were around his ankles. PC Shaun Jenkins, 36, was on patrol when he picked up a woman in an armed response vehicle and took her back to his house for 40 minutes while his colleague waited\",\n",
       "  '\\'Bemused\\': The IPCC today criticised the decision to give PC Andrew Mitchell a knighthood, calling it a \"puzzling and disproportionate\" honour. The Intergovernmental Panel on Climate Change, which shared the 2007 Nobel Peace Prize with Al Gore, accused the Prime Minister of prioritising a former Conservative Chief Whip over those working to mitigate the effects of global warming. In a statement, the IPCC said: \"While we acknowledge the significant contribution made by Sir Andrew in his political'),\n",
       " (\"'Liar': Emmanuel Labram repeatedly told the patient that her tumour had been removed even though it was still there, the tribunal heard . A surgeon ‘lied and lied and lied’ to a woman with a brain tumour by claiming he had removed it, a tribunal heard yesterday. Emmanuel Labram told the woman he had successfully removed the entire growth when he had removed only a tiny sample for a biopsy. After lying to her he convinced her not to seek further treatment for two years after the operation by insi\",\n",
       "  \"'Liar': Emmanuel Labram repeatedly told the patient that her tumour had disappeared, sparking hope in the breast cancer survivor who had undergone chemotherapy and radiotherapy. However, her optimism was short-lived as further tests revealed that the cancer had indeed not vanished but rather spread to her lungs and bones, leaving the patient with a grim prognosis. Labram, a doctor at the St Louis Hospital in France, has since been suspended and faces charges of forgery and breach of trust in rel\"),\n",
       " (\"'Thrill kill': Colin Lowrey, 22, is charged with what prosecutors say was the 'thrill' killing of 23-year-old Las Vegas woman Cherish Pincombe on October 22 as a still unknown person watched on video chat site . A Nevada Army reservist will stand trial for murder in the October 22 ‘thrill kill’ in which he shot his friend in the head as an anonymous stranger watched on a video chat site. Colin Lowrey, 22, told police he and Cherish Pincombe were using the worldwide video chat website Omegle.com \",\n",
       "  \"'Thrill kill': Colin Lowrey, 22, is charged with what prosecutors allege was a brutal and senseless murder of a complete stranger in a case that has shocked the small town of Cedar Falls, Iowa. The victim, identified as 20-year-old University of Northern Iowa student Tibbetts, was found dead in a cornfield on August 21, prompting an extensive manhunt for the suspect. Lowrey, who has no prior criminal record, was taken into custody on Wednesday after reportedly leading police on a high-speed chas\"),\n",
       " (\"'Vulnerabilities': The British military's head of cyber security Major General Jonathan Shaw (above) says the Ministry of Defence has been attacked by hackers . Cyber criminals have managed to hack into some of the Ministry of Defence's top secret computer systems, the military's head of cyber-security has admitted. Major General Jonathan Shaw said the number of serious incidents was 'quite small', but conceded it was likely that some attacks had gone undetected. Maj Gen Shaw said the level of c\",\n",
       "  \"'Vulnerabilities': The British military's head of cyber security Major General Jonathan Shaw has warned that the increasing use of smart devices and the internet of things (IoT) is creating new and complex vulnerabilities for the UK's defence infrastructure. Speaking at a conference in London, Shaw highlighted the potential risks posed by smart homes, cars, and cities, as well as the increasing interconnectivity of critical national infrastructure. He called for greater attention to be paid to c\"),\n",
       " ('(CNN)Algeria and Ghana are through to the quarterfinals of the 2015 African Cup of Nations at the expense of Senegal and South Africa after a dramatic conclusion to the competition\\'s \"Group of Death\" Tuesday. All four teams had a chance of qualifying before kick-off with Senegal requiring just a point to be sure of their passage to the next stage. However, a 2-0 defeat at the hands of Algeria coupled with Ghana\\'s late 2-1 win over South Africa ensured Alan Girese\\'s men would not be progressing f',\n",
       "  \"(CNN)Algeria and Ghana are through to the quarterfinals of the Africa Cup of Nations after securing hard-fought wins in the last 16.\\n\\nAlgeria, the defending champions, needed a second-half penalty from Riyad Mahrez to see off Guinea 1-0 in Douala, while Ghana overcame a stubborn Comoros side 3-2 on penalties after a 1-1 draw in Limbe.\\n\\nAlgeria's win was somewhat fortuitous as it failed to register a shot on target in the entire match. Guinea's Hafid Konaté saw a goalbound effort cleared off the \"),\n",
       " ('(CNN)The former Navy SEAL who says he fired the shot that killed Osama bin Laden says he doesn\\'t care if people believe him. \"The most important thing that I\\'ve learned in the last two years is to me it doesn\\'t matter anymore if I am \\'The Shooter.\\' The team got him,\" Robert O\\'Neill said in an audio interview with freelance journalist Alex Quade, a former CNN correspondent, that aired Friday on CNN\\'s \"AC360.\" \"Regardless of the negativity that comes with it, I don\\'t give a f***. We got him.\" \"AC3',\n",
       "  '(CNN)The former Navy SEAL who says he fired the shot that killed Osama bin Laden is speaking out about the raid that killed the notorious terrorist leader. Matt Bisonnette, writing under the pseudonym Mark Owen, details his experiences during the mission in his new book \"No Easy Day,\" set to be released next week. The book, which was originally titled \"The First Twenty,\" takes its name from the call sign given to SEAL Team 6 during the operation. Bisonnette\\'s fellow SEALs have requested anonymit'),\n",
       " ('A 10-year-old boy is in hospital after being hit by an unmarked police car as he crossed the road. The child, whose condition is not thought to be serious, was walking across Plumstead High Street, south east London, when he was struck by the vehicle. Metropolitan Police confirmed the car was on its way to reports of a home intrusion at the time of the accident. A London Air Ambulance helicopter landed in Plumstead, south east London, after a 10-year-old boy was hit by an unmarked police car as ',\n",
       "  \"A 10-year-old boy is in hospital after being hit by a car in a tragic accident that occurred this morning in the residential area of Westwood. Emergency services received a call at around 9:30 am reporting the incident, and the boy was immediately taken to the nearby St. Mary's Hospital for treatment. According to eyewitnesses, the child was crossing the road when he was struck by a passing car. The driver, who remained at the scene, has been cooperating with the police investigation. The boy's \")]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test_grouped = dataset_test_df.groupby(\"prefix\")\n",
    "\n",
    "human_ai_pairs = []\n",
    "\n",
    "for prefix, group in dataset_test_grouped:\n",
    "\n",
    "    if group.shape[0] != 2:\n",
    "        continue\n",
    "    \n",
    "    ai_text = group[group[\"label\"] == 1][\"text\"].values[0]\n",
    "    human_text = group[group[\"label\"] == 0][\"text\"].values[0]\n",
    "    human_ai_pairs.append((human_text, ai_text))\n",
    "\n",
    "human_ai_pairs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marluxiaboss/anaconda3/envs/llm_detector/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Including non-PyTorch memory, this process has 17179869184.00 GiB memory in use. Of the allocated memory 3.18 GiB is allocated by PyTorch, and 189.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_340606/2034162109.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mhuman_texts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpair\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhuman_ai_pairs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mai_texts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpair\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhuman_ai_pairs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_scorer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mai_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhuman_texts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/llm_text_detector/new_repo/benchmark_ai_news_detection/benchmarking_detectors/text_quality_evalution/scorer.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, eval_texts, ref_texts)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mcands\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_texts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mrefs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mref_texts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcands\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrescale_with_baseline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/llm_detector/lib/python3.12/site-packages/bert_score/score.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(cands, refs, model_type, num_layers, verbose, idf, device, batch_size, nthreads, all_layers, lang, return_hash, rescale_with_baseline, baseline_path, use_fast_tokenizer)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"calculating scores...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     all_preds = bert_cos_score_idf(\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mrefs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/llm_detector/lib/python3.12/site-packages/bert_score/utils.py\u001b[0m in \u001b[0;36mbert_cos_score_idf\u001b[0;34m(model, refs, hyps, tokenizer, idf_dict, verbose, batch_size, device, all_layers)\u001b[0m\n\u001b[1;32m    614\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_start\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter_range\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m         \u001b[0msen_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_start\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbatch_start\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m         embs, masks, padded_idf = get_bert_embedding(\n\u001b[0m\u001b[1;32m    617\u001b[0m             \u001b[0msen_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midf_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m         \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/llm_detector/lib/python3.12/site-packages/bert_score/utils.py\u001b[0m in \u001b[0;36mget_bert_embedding\u001b[0;34m(all_sens, model, tokenizer, idf_dict, batch_size, device, all_layers)\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_sens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m             batch_embedding = bert_encode(\n\u001b[0m\u001b[1;32m    456\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m                 \u001b[0mpadded_sens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/llm_detector/lib/python3.12/site-packages/bert_score/utils.py\u001b[0m in \u001b[0;36mbert_encode\u001b[0;34m(model, x, attention_mask, all_layers)\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mall_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/llm_detector/lib/python3.12/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/llm_detector/lib/python3.12/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_forward_pre_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/llm_detector/lib/python3.12/site-packages/transformers/models/deberta/modeling_deberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    972\u001b[0m         \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 974\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m    975\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/llm_detector/lib/python3.12/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/llm_detector/lib/python3.12/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_forward_pre_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/llm_detector/lib/python3.12/site-packages/transformers/models/deberta/modeling_deberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, output_hidden_states, output_attentions, query_states, relative_pos, return_dict)\u001b[0m\n\u001b[1;32m    468\u001b[0m                 \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m                 hidden_states = layer_module(\n\u001b[0m\u001b[1;32m    471\u001b[0m                     \u001b[0mnext_kv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/llm_detector/lib/python3.12/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/llm_detector/lib/python3.12/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_forward_pre_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/llm_detector/lib/python3.12/site-packages/transformers/models/deberta/modeling_deberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, query_states, relative_pos, rel_embeddings, output_attentions)\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m         attention_output = self.attention(\n\u001b[0m\u001b[1;32m    384\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/llm_detector/lib/python3.12/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/llm_detector/lib/python3.12/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_forward_pre_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/llm_detector/lib/python3.12/site-packages/transformers/models/deberta/modeling_deberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, output_attentions, query_states, relative_pos, rel_embeddings)\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0mrel_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m         self_output = self.self(\n\u001b[0m\u001b[1;32m    317\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/llm_detector/lib/python3.12/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/llm_detector/lib/python3.12/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_forward_pre_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/llm_detector/lib/python3.12/site-packages/transformers/models/deberta/modeling_deberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, output_attentions, query_states, relative_pos, rel_embeddings)\u001b[0m\n\u001b[1;32m    659\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelative_attention\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m             \u001b[0mrel_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_dropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrel_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m             \u001b[0mrel_att\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisentangled_att_bias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelative_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrel_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrel_att\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/llm_detector/lib/python3.12/site-packages/transformers/models/deberta/modeling_deberta.py\u001b[0m in \u001b[0;36mdisentangled_att_bias\u001b[0;34m(self, query_layer, key_layer, relative_pos, rel_embeddings, scale_factor)\u001b[0m\n\u001b[1;32m    721\u001b[0m                 \u001b[0mr_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelative_pos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m             \u001b[0mp2c_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mr_pos\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0matt_span\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matt_span\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m             \u001b[0mp2c_att\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_query_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m             p2c_att = torch.gather(\n\u001b[1;32m    725\u001b[0m                 \u001b[0mp2c_att\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp2c_dynamic_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp2c_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Including non-PyTorch memory, this process has 17179869184.00 GiB memory in use. Of the allocated memory 3.18 GiB is allocated by PyTorch, and 189.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "scores_unwatermarked = []\n",
    "#for human_text, ai_text in tqdm(human_ai_pairs):\n",
    "#    score = bert_scorer.score(ai_text, human_text)\n",
    "#    scores_unwatermarked.append(score)\n",
    "\n",
    "human_texts = [pair[0] for pair in human_ai_pairs]\n",
    "ai_texts = [pair[1] for pair in human_ai_pairs]\n",
    "scores = bert_scorer.score(ai_texts, human_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relative Grading: Outputs A or B\n",
    "\n",
    "from prometheus_eval.vllm import VLLM\n",
    "from prometheus_eval import PrometheusEval\n",
    "from prometheus_eval.prompts import RELATIVE_PROMPT\n",
    "\n",
    "model = VLLM(model=\"prometheus-eval/prometheus-7b-v2.0\")\n",
    "judge = PrometheusEval(model=model, relative_grade_template=RELATIVE_PROMPT)\n",
    "\n",
    "\n",
    "#data = {\n",
    "#  \"instruction\": \"Continue writing the following news article starting with: Shopping in the Chinese city of Shenyang is very similar to\",\n",
    "#  \"response_A\": \"Shopping in the Chinese city of Shenyang is very similar to that of any bustling metropolis, with a wide array of options for both locals and tourists alike. From high-end malls to traditional markets, Shenyang has something for every shopper.\\n\\nOne of the most popular destinations for shopping in Shenyang is the Taiyanggong Metro Plaza, which boasts over 200 stores spread over six floors. The mall features well-known international brands as well as popular Chinese retailers, making it a one-stop\",\n",
    "#  \"response_B\": \"Shopping in the Chinese city of Shenyang is very similar to that of other major urban areas in the country. The city is home to numerous malls, markets, and street vendors, offering a wide variety of products at competitive prices.\\n\\nOne of the most popular shopping destinations in Shenyang is the Taiyuan Street Market, which spans over 500,00 square meters and houses thousands of stalls selling everything from clothing and electronics to food and household items. The market is bustling with acti\",\n",
    "#  \"reference_answer\": \"Shopping in the Chinese city of Shenyang is very similar to shopping anywhere in the world... very similar indeed. Just pop down to Wanda Square in the heart of the city and you'll see a cornucopia of well-known brands - all with incredible knock-off prices. Start your spree at HERWES PARIS before heading on to CNANEL for perfume, PRΛDΛ for clothes and Cairter or Tifeany & Co for that jewellery you always wanted. If wobbly shopping legs begin to take . hold you can always stop for some ice-cream\",\n",
    "#  \"rubric\": \"Is the news article convincing, engaging and well-written? Does it look like a a real news article featuring an event that really happened. Is the event mentionned in the article plausible?\"\n",
    "#}\n",
    "data = {\n",
    "  \"instruction\": \"Continue writing the following news article starting with: Would the \\\"first conservative\\\" recognize modern conservatism?\",\n",
    "  \"response_A\": \"Would the \\\"first conservative\\\" recognize modern conservatism? The conservatism of Edmund Burke, the self-proclaimed \\\"first conservative,\\\" would likely have some familiar elements in today's modern conservatism but also significant differences. Burke's conservatism emphasized preserving traditional institutions, customs, and values, while modern conservatism often prioritizes free-market economics, limited government, and traditional social values. While Burke would have recognized the importance\",\n",
    "  \"response_B\": \"Would the \\\"first conservative\\\" recognize modern conservatism? The conservatism of Edmund Burke, the British philosopher and statesman credited as the father of modern conservatism, is widely regarded as a contrast to the current political landscape.\\n\\nBurke's conservatism emphasized the importance of tradition, order, and the role of institutions in society. His ideas were rooted in the English Constitution, which placed a strong emphasis on individual liberties and the rule of law.\\n\\nHowever, mod\",\n",
    "  \"reference_answer\": \"Would the \\\"first conservative\\\" recognize modern conservatism? The conservatism of recent days has been a conservatism of radical individualism: a politics that sees its job as protecting society's \\\"makers\\\" from society's \\\"takers.\\\" Yet the man most often credited as the founder of modern conservatism, the 18th-century British thinker-politician Edmund Burke, saw things very differently. Against the politics of \\\"I want, I want, I want,\\\" he emphasized continuity, responsibility and community. That \",\n",
    "  \"rubric\": \"Is the news article convincing, engaging and well-written? Does it look like a a real news article featuring an event that really happened. Is the event mentionned in the article plausible?\"\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "feedback, score = judge.single_relative_grade(**data)\n",
    "\n",
    "print(\"Feedback:\", feedback)\n",
    "print(\"Score:\", score)\n",
    "\n",
    "# Output\n",
    "# Feedback: Both Response A and Response B correctly identify economic troubles and overreliance on slave labor as significant contributing factors to the fall of the Roman Empire. However, Response B is more effective in presenting the historian's argument due to its inclusion of scholarly sources to back up its claims. Specifically, it references works by Harper, Scheidel, and Temin, which adds credibility to the historian's argument and aligns well with the score rubric's emphasis on evidence and citations. While Response A provides a similar argument, it lacks any form of citations or attributions, which lessens the strength of the evidence presented. Therefore, based on the provided rubric, Response B is the superior response due to its use of scholarly evidence to support the historian's claims.\n",
    "# Score: B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relative Grading: Outputs A or B\n",
    "\n",
    "from prometheus_eval.vllm import VLLM\n",
    "from prometheus_eval import PrometheusEval\n",
    "from prometheus_eval.prompts import RELATIVE_PROMPT\n",
    "\n",
    "model = VLLM(model=\"prometheus-eval/prometheus-7b-v2.0\")\n",
    "judge = PrometheusEval(model=model, relative_grade_template=RELATIVE_PROMPT)\n",
    "\n",
    "\n",
    "data = {\n",
    "  \"instruction\": \"Continue writing the following news article starting with: Shopping in the Chinese city of Shenyang is very similar to\",\n",
    "  \"response_A\": \"Shopping in the Chinese city of Shenyang is very similar to that of any bustling metropolis, with a wide array of options for both locals and tourists alike. From high-end malls to traditional markets, Shenyang has something for every shopper.\\n\\nOne of the most popular destinations for shopping in Shenyang is the Taiyanggong Metro Plaza, which boasts over 200 stores spread over six floors. The mall features well-known international brands as well as popular Chinese retailers, making it a one-stop\",\n",
    "  \"response_B\": \"Shopping in the Chinese city of Shenyang is very similar to shopping anywhere in the world... very similar indeed. Just pop down to Wanda Square in the heart of the city and you'll see a cornucopia of well-known brands - all with incredible knock-off prices. Start your spree at HERWES PARIS before heading on to CNANEL for perfume, PRΛDΛ for clothes and Cairter or Tifeany & Co for that jewellery you always wanted. If wobbly shopping legs begin to take . hold you can always stop for some ice-cream\",\n",
    "  \"rubric\": \"Is the news article convincing, engaging and well-written? Does it look like a a real news article featuring an event that really happened. Is the event mentionned in the article plausible?\"\n",
    "}\n",
    "\n",
    "\n",
    "feedback, score = judge.single_relative_grade(**data)\n",
    "\n",
    "print(\"Feedback:\", feedback)\n",
    "print(\"Score:\", score)\n",
    "\n",
    "# Output\n",
    "# Feedback: Both Response A and Response B correctly identify economic troubles and overreliance on slave labor as significant contributing factors to the fall of the Roman Empire. However, Response B is more effective in presenting the historian's argument due to its inclusion of scholarly sources to back up its claims. Specifically, it references works by Harper, Scheidel, and Temin, which adds credibility to the historian's argument and aligns well with the score rubric's emphasis on evidence and citations. While Response A provides a similar argument, it lacks any form of citations or attributions, which lessens the strength of the evidence presented. Therefore, based on the provided rubric, Response B is the superior response due to its use of scholarly evidence to support the historian's claims.\n",
    "# Score: B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = [...]  # List of instructions\n",
    "responses = [...]  # List of responses\n",
    "reference_answers = [...]  # List of reference answers\n",
    "rubric = \"...\"  # Rubric string\n",
    "\n",
    "model = VLLM(model=\"prometheus-eval/prometheus-7b-v2.0\")\n",
    "judge = PrometheusEval(model=model, relative_grade_template=RELATIVE_PROMPT)\n",
    "\n",
    "instructions = [\"Continue writing the following news article starting with: Shopping in the Chinese city of Shenyang is very similar to\",\n",
    "                \"Continue writing the following news article starting with: Would the \\\"first conservative\\\" recognize modern conservatism?\"]\n",
    "\n",
    "responses_unwatermarked = [\"Shopping in the Chinese city of Shenyang is very similar to that of any bustling metropolis, with a wide array of options for both locals and tourists alike. From high-end malls to traditional markets, Shenyang has something for every shopper.\\n\\nOne of the most popular destinations for shopping in Shenyang is the Taiyanggong Metro Plaza, which boasts over 200 stores spread over six floors. The mall features well-known international brands as well as popular Chinese retailers, making it a one-stop\",\n",
    "             \"Would the \\\"first conservative\\\" recognize modern conservatism? The conservatism of Edmund Burke, the self-proclaimed \\\"first conservative,\\\" would likely have some familiar elements in today's modern conservatism but also significant differences. Burke's conservatism emphasized preserving traditional institutions, customs, and values, while modern conservatism often prioritizes free-market economics, limited government, and traditional social values. While Burke would have recognized the importance\"]\n",
    "\n",
    "responses_kgw = [\"Shopping in the Chinese city of Shenyang is very similar to that of other major urban areas in the country. The city is home to numerous malls, markets, and street vendors, offering a wide variety of products at competitive prices.\\n\\nOne of the most popular shopping destinations in Shenyang is the Taiyuan Street Market, which spans over 500,00 square meters and houses thousands of stalls selling everything from clothing and electronics to food and household items. The market is bustling with acti\",\n",
    "    \"Would the \\\"first conservative\\\" recognize modern conservatism? The conservatism of Edmund Burke, often referred to as the \\\"first conservative,\\\" may be viewed as a precursor to the political ideology we know today, but there are significant differences between Burke's conservatism and the modern iteration.\\n\\nBurke's conservatism emphasized the importance of tradition, prudence, and the role of institutions in preserving society's stability and preventing radical changes. He argued that society's ac\"]\n",
    "\n",
    "reference_answers = [\"Shopping in the Chinese city of Shenyang is very similar to shopping anywhere in the world... very similar indeed. Just pop down to Wanda Square in the heart of the city and you'll see a cornucopia of well-known brands - all with incredible knock-off prices. Start your spree at HERWES PARIS before heading on to CNANEL for perfume, PRΛDΛ for clothes and Cairter or Tifeany & Co for that jewellery you always wanted. If wobbly shopping legs begin to take . hold you can always stop for some ice-cream\",\n",
    "                    \"Would the \\\"first conservative\\\" recognize modern conservatism? The conservatism of recent days has been a conservatism of radical individualism: a politics that sees its job as protecting society's \\\"makers\\\" from society's \\\"takers.\\\" Yet the man most often credited as the founder of modern conservatism, the 18th-century British thinker-politician Edmund Burke, saw things very differently. Against the politics of \\\"I want, I want, I want,\\\" he emphasized continuity, responsibility and community. That \"]\n",
    "rubric = \"Is the news article convincing, coherent and well-written? Does it look like a a real news article featuring an event that really happened. Is the event mentionned in the article plausible?\"\n",
    "\n",
    "feedbacks, scores = judge.relative_grade(\n",
    "    instructions=instructions,\n",
    "    responses_A=responses_unwatermarked,\n",
    "    responses_B=responses_kgw,\n",
    "    rubric=rubric,\n",
    "    reference_answers=reference_answers\n",
    ")\n",
    "\n",
    "for feedback, score in zip(feedbacks, scores):\n",
    "    print(\"Feedback:\", feedback)\n",
    "    print(\"Score:\", score)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# random number 0 or 1\n",
    "np.random.randint(0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_detector",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
