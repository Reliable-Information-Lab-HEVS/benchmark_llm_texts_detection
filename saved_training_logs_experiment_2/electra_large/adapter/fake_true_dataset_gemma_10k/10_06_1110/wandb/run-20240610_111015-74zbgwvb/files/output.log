
----------------Epoch 1/1----------------
Epoch 1/1, Loss after 192 samples: 0.6890
Epoch 1/1, Loss after 392 samples: 0.6711
Mean accuracy: 0.7015, std: 0.0102, lower bound: 0.6810, upper bound: 0.7214 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 496 samples: 0.7012 with eval loss: 0.6423
Best model with eval loss 0.6423012518113659 and eval accuracy 0.7012133468149646 with 496 samples seen is saved
Epoch 1/1, Loss after 592 samples: 0.6494
Epoch 1/1, Loss after 792 samples: 0.5985
Epoch 1/1, Loss after 992 samples: 0.4175
Mean accuracy: 0.8746, std: 0.0075, lower bound: 0.8605, upper bound: 0.8883 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 1000 samples: 0.8746 with eval loss: 0.2880
Best model with eval loss 0.28800713871755906 and eval accuracy 0.8746208291203236 with 1000 samples seen is saved
Epoch 1/1, Loss after 1192 samples: 0.3306
Epoch 1/1, Loss after 1392 samples: 0.2549
Mean accuracy: 0.9039, std: 0.0063, lower bound: 0.8913, upper bound: 0.9161 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 1504 samples: 0.9039 with eval loss: 0.2470
Best model with eval loss 0.24701518325075025 and eval accuracy 0.9039433771486349 with 1504 samples seen is saved
Epoch 1/1, Loss after 1592 samples: 0.3431
Epoch 1/1, Loss after 1792 samples: 0.2885
Epoch 1/1, Loss after 1992 samples: 0.1742
Mean accuracy: 0.8534, std: 0.0080, lower bound: 0.8377, upper bound: 0.8681 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 2008 samples: 0.8534 with eval loss: 0.3838
Epoch 1/1, Loss after 2192 samples: 0.1551
Epoch 1/1, Loss after 2392 samples: 0.2435
Mean accuracy: 0.9432, std: 0.0053, lower bound: 0.9328, upper bound: 0.9535 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 2512 samples: 0.9434 with eval loss: 0.1518
Best model with eval loss 0.1517629132515961 and eval accuracy 0.9433771486349848 with 2512 samples seen is saved
Epoch 1/1, Loss after 2592 samples: 0.2346
Epoch 1/1, Loss after 2792 samples: 0.1788
Epoch 1/1, Loss after 2992 samples: 0.1409
Mean accuracy: 0.9381, std: 0.0056, lower bound: 0.9267, upper bound: 0.9484 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 3016 samples: 0.9383 with eval loss: 0.1531
Epoch 1/1, Loss after 3192 samples: 0.1483
Epoch 1/1, Loss after 3392 samples: 0.2100
Mean accuracy: 0.8652, std: 0.0077, lower bound: 0.8498, upper bound: 0.8802 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 3520 samples: 0.8650 with eval loss: 0.3626
Epoch 1/1, Loss after 3592 samples: 0.1604
Epoch 1/1, Loss after 3792 samples: 0.1682
Epoch 1/1, Loss after 3992 samples: 0.1684
Mean accuracy: 0.9307, std: 0.0058, lower bound: 0.9186, upper bound: 0.9419 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 4024 samples: 0.9307 with eval loss: 0.1783
Epoch 1/1, Loss after 4192 samples: 0.2311
Epoch 1/1, Loss after 4392 samples: 0.2502
Mean accuracy: 0.8933, std: 0.0069, lower bound: 0.8797, upper bound: 0.9065 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 4528 samples: 0.8933 with eval loss: 0.2538
Epoch 1/1, Loss after 4592 samples: 0.1355
Epoch 1/1, Loss after 4792 samples: 0.1069
Epoch 1/1, Loss after 4992 samples: 0.1883
Mean accuracy: 0.9361, std: 0.0055, lower bound: 0.9257, upper bound: 0.9464 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 5032 samples: 0.9363 with eval loss: 0.1615
Epoch 1/1, Loss after 5192 samples: 0.1691
Epoch 1/1, Loss after 5392 samples: 0.1044
Mean accuracy: 0.9514, std: 0.0049, lower bound: 0.9414, upper bound: 0.9606 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 5536 samples: 0.9515 with eval loss: 0.1259
Best model with eval loss 0.12588101030597765 and eval accuracy 0.9514661274014156 with 5536 samples seen is saved
Epoch 1/1, Loss after 5592 samples: 0.1298
Epoch 1/1, Loss after 5792 samples: 0.1213
Epoch 1/1, Loss after 5992 samples: 0.1306
Mean accuracy: 0.8986, std: 0.0069, lower bound: 0.8847, upper bound: 0.9115 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 6040 samples: 0.8984 with eval loss: 0.3044
Epoch 1/1, Loss after 6192 samples: 0.1591
Epoch 1/1, Loss after 6392 samples: 0.1549
Mean accuracy: 0.9597, std: 0.0045, lower bound: 0.9509, upper bound: 0.9681 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 6544 samples: 0.9596 with eval loss: 0.1129
Best model with eval loss 0.11292359274962256 and eval accuracy 0.9595551061678463 with 6544 samples seen is saved
Epoch 1/1, Loss after 6592 samples: 0.1550
Epoch 1/1, Loss after 6792 samples: 0.1642
Epoch 1/1, Loss after 6992 samples: 0.1241
Mean accuracy: 0.9531, std: 0.0047, lower bound: 0.9444, upper bound: 0.9621 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 7048 samples: 0.9530 with eval loss: 0.1272
Epoch 1/1, Loss after 7192 samples: 0.1444
Epoch 1/1, Loss after 7392 samples: 0.1633
Mean accuracy: 0.9658, std: 0.0043, lower bound: 0.9575, upper bound: 0.9737 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 7552 samples: 0.9656 with eval loss: 0.0956
Best model with eval loss 0.09556810888311555 and eval accuracy 0.9656218402426694 with 7552 samples seen is saved
Epoch 1/1, Loss after 7592 samples: 0.0936
Epoch 1/1, Loss after 7792 samples: 0.0705
Epoch 1/1, Loss after 7992 samples: 0.1876
Mean accuracy: 0.9438, std: 0.0052, lower bound: 0.9338, upper bound: 0.9540 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 8056 samples: 0.9439 with eval loss: 0.1432
Epoch 1/1, Loss after 8192 samples: 0.0896
Epoch 1/1, Loss after 8392 samples: 0.1354
Mean accuracy: 0.9295, std: 0.0059, lower bound: 0.9181, upper bound: 0.9408 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 8560 samples: 0.9292 with eval loss: 0.1856
Epoch 1/1, Loss after 8592 samples: 0.0563
Epoch 1/1, Loss after 8792 samples: 0.1141
Epoch 1/1, Loss after 8992 samples: 0.0871
Mean accuracy: 0.9596, std: 0.0043, lower bound: 0.9515, upper bound: 0.9681 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 9064 samples: 0.9596 with eval loss: 0.1053
Epoch 1/1, Loss after 9192 samples: 0.0653
Epoch 1/1, Loss after 9392 samples: 0.0825
Mean accuracy: 0.9135, std: 0.0063, lower bound: 0.9009, upper bound: 0.9257 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 9568 samples: 0.9135 with eval loss: 0.2607
Epoch 1/1, Loss after 9592 samples: 0.0740
Epoch 1/1, Loss after 9792 samples: 0.1765
Epoch 1/1, Loss after 9992 samples: 0.1113
Mean accuracy: 0.9559, std: 0.0045, lower bound: 0.9469, upper bound: 0.9646 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 10072 samples: 0.9560 with eval loss: 0.1214
Epoch 1/1, Loss after 10192 samples: 0.0821
Epoch 1/1, Loss after 10392 samples: 0.1107
Mean accuracy: 0.9284, std: 0.0060, lower bound: 0.9161, upper bound: 0.9408 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 10576 samples: 0.9282 with eval loss: 0.1876
Epoch 1/1, Loss after 10592 samples: 0.1184
Epoch 1/1, Loss after 10792 samples: 0.0839
Epoch 1/1, Loss after 10992 samples: 0.0509
Mean accuracy: 0.9279, std: 0.0059, lower bound: 0.9171, upper bound: 0.9398 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 11080 samples: 0.9277 with eval loss: 0.2096
Epoch 1/1, Loss after 11192 samples: 0.0891
Epoch 1/1, Loss after 11392 samples: 0.0909
Mean accuracy: 0.9291, std: 0.0057, lower bound: 0.9186, upper bound: 0.9403 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 11584 samples: 0.9292 with eval loss: 0.1968
Epoch 1/1, Loss after 11592 samples: 0.1249
Epoch 1/1, Loss after 11792 samples: 0.1236
Epoch 1/1, Loss after 11992 samples: 0.0935
Mean accuracy: 0.9481, std: 0.0050, lower bound: 0.9383, upper bound: 0.9575 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 12088 samples: 0.9479 with eval loss: 0.1452
Epoch 1/1, Loss after 12192 samples: 0.1012
Epoch 1/1, Loss after 12392 samples: 0.0707
Epoch 1/1, Loss after 12592 samples: 0.0982
Mean accuracy: 0.9448, std: 0.0050, lower bound: 0.9348, upper bound: 0.9540 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 12592 samples: 0.9449 with eval loss: 0.1522
Epoch 1/1, Loss after 12792 samples: 0.1356
Epoch 1/1, Loss after 12992 samples: 0.0682
Mean accuracy: 0.9202, std: 0.0060, lower bound: 0.9085, upper bound: 0.9317 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 13096 samples: 0.9201 with eval loss: 0.2284
Epoch 1/1, Loss after 13192 samples: 0.0513
Epoch 1/1, Loss after 13392 samples: 0.0977
Epoch 1/1, Loss after 13592 samples: 0.1016
Mean accuracy: 0.9420, std: 0.0052, lower bound: 0.9312, upper bound: 0.9515 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 13600 samples: 0.9419 with eval loss: 0.1652
Epoch 1/1, Loss after 13792 samples: 0.0764
Epoch 1/1, Loss after 13992 samples: 0.0462
Mean accuracy: 0.9576, std: 0.0046, lower bound: 0.9489, upper bound: 0.9661 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 14104 samples: 0.9575 with eval loss: 0.1243
Epoch 1/1, Loss after 14192 samples: 0.1209
Epoch 1/1, Loss after 14392 samples: 0.1254
Epoch 1/1, Loss after 14592 samples: 0.1158
Mean accuracy: 0.9567, std: 0.0045, lower bound: 0.9474, upper bound: 0.9656 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 14608 samples: 0.9565 with eval loss: 0.1257
Epoch 1/1, Loss after 14792 samples: 0.0667
Epoch 1/1, Loss after 14992 samples: 0.0712
Mean accuracy: 0.9466, std: 0.0051, lower bound: 0.9363, upper bound: 0.9560 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 15112 samples: 0.9464 with eval loss: 0.1562
Epoch 1/1, Loss after 15192 samples: 0.0636
Epoch 1/1, Loss after 15392 samples: 0.0930
Epoch 1/1, Loss after 15592 samples: 0.0819
Mean accuracy: 0.9551, std: 0.0048, lower bound: 0.9449, upper bound: 0.9641 for 1000 bootstraps
Epoch 1/1, Validation accuracy after 15616 samples: 0.9550 with eval loss: 0.1338
Epoch 1/1, Loss after 15792 samples: 0.1122
Training signal is False, stopping training
Training finished
Best model: {'eval_acc': 0.9656218402426694, 'nb_samples': 7552, 'eval_loss': 0.09556810888311555}
Training loss logs: [{'samples': 192, 'loss': 0.689013671875}, {'samples': 392, 'loss': 0.67106689453125}, {'samples': 592, 'loss': 0.649371337890625}, {'samples': 792, 'loss': 0.5984872436523437}, {'samples': 992, 'loss': 0.41745079040527344}, {'samples': 1192, 'loss': 0.3305929613113403}, {'samples': 1392, 'loss': 0.25490499019622803}, {'samples': 1592, 'loss': 0.34310184955596923}, {'samples': 1792, 'loss': 0.2884877610206604}, {'samples': 1992, 'loss': 0.17424435734748842}, {'samples': 2192, 'loss': 0.15505513846874236}, {'samples': 2392, 'loss': 0.24352351307868958}, {'samples': 2592, 'loss': 0.2346048855781555}, {'samples': 2792, 'loss': 0.17880432605743407}, {'samples': 2992, 'loss': 0.14093969166278839}, {'samples': 3192, 'loss': 0.1483074003458023}, {'samples': 3392, 'loss': 0.20997466564178466}, {'samples': 3592, 'loss': 0.16036103367805482}, {'samples': 3792, 'loss': 0.16815114498138428}, {'samples': 3992, 'loss': 0.16838725447654723}, {'samples': 4192, 'loss': 0.23111214518547057}, {'samples': 4392, 'loss': 0.25024973511695864}, {'samples': 4592, 'loss': 0.13550667643547057}, {'samples': 4792, 'loss': 0.10685275256633758}, {'samples': 4992, 'loss': 0.18825413882732392}, {'samples': 5192, 'loss': 0.16914989531040192}, {'samples': 5392, 'loss': 0.10441250383853912}, {'samples': 5592, 'loss': 0.12984548330307008}, {'samples': 5792, 'loss': 0.12129811525344848}, {'samples': 5992, 'loss': 0.13059282779693604}, {'samples': 6192, 'loss': 0.1590990275144577}, {'samples': 6392, 'loss': 0.1549163717031479}, {'samples': 6592, 'loss': 0.15495981395244598}, {'samples': 6792, 'loss': 0.16418614983558655}, {'samples': 6992, 'loss': 0.1240588092803955}, {'samples': 7192, 'loss': 0.14435831010341643}, {'samples': 7392, 'loss': 0.16327156007289886}, {'samples': 7592, 'loss': 0.09361712396144867}, {'samples': 7792, 'loss': 0.07051213204860687}, {'samples': 7992, 'loss': 0.18763997316360473}, {'samples': 8192, 'loss': 0.0895789235830307}, {'samples': 8392, 'loss': 0.13543859720230103}, {'samples': 8592, 'loss': 0.05633294641971588}, {'samples': 8792, 'loss': 0.11408794403076172}, {'samples': 8992, 'loss': 0.08707394242286683}, {'samples': 9192, 'loss': 0.06530946552753449}, {'samples': 9392, 'loss': 0.08248388826847076}, {'samples': 9592, 'loss': 0.07404381394386292}, {'samples': 9792, 'loss': 0.17653946876525878}, {'samples': 9992, 'loss': 0.11126901805400849}, {'samples': 10192, 'loss': 0.0820880764722824}, {'samples': 10392, 'loss': 0.11072184503078461}, {'samples': 10592, 'loss': 0.11842487633228302}, {'samples': 10792, 'loss': 0.08389948070049286}, {'samples': 10992, 'loss': 0.050920591950416566}, {'samples': 11192, 'loss': 0.08911890983581543}, {'samples': 11392, 'loss': 0.09088272333145142}, {'samples': 11592, 'loss': 0.12487115025520325}, {'samples': 11792, 'loss': 0.12362059473991394}, {'samples': 11992, 'loss': 0.09348142683506012}, {'samples': 12192, 'loss': 0.10115957200527191}, {'samples': 12392, 'loss': 0.0706681990623474}, {'samples': 12592, 'loss': 0.0982185059785843}, {'samples': 12792, 'loss': 0.13556700050830842}, {'samples': 12992, 'loss': 0.06818516492843628}, {'samples': 13192, 'loss': 0.05130596101284027}, {'samples': 13392, 'loss': 0.09773244142532349}, {'samples': 13592, 'loss': 0.10156580984592438}, {'samples': 13792, 'loss': 0.07639941275119781}, {'samples': 13992, 'loss': 0.0461975371837616}, {'samples': 14192, 'loss': 0.12090822994709015}, {'samples': 14392, 'loss': 0.12535577058792113}, {'samples': 14592, 'loss': 0.11583593904972077}, {'samples': 14792, 'loss': 0.06672626674175262}, {'samples': 14992, 'loss': 0.07116279542446137}, {'samples': 15192, 'loss': 0.0635974657535553}, {'samples': 15392, 'loss': 0.09296992182731628}, {'samples': 15592, 'loss': 0.08189435422420502}, {'samples': 15792, 'loss': 0.11222169637680053}]
Evaluation accuracy logs: [{'samples': 496, 'accuracy': 0.7014863498483317, 'std': 0.010231918674592012, 'lower_bound': 0.6809908998988877, 'upper_bound': 0.7214357937310415}, {'samples': 1000, 'accuracy': 0.8746304347826087, 'std': 0.007543485003489262, 'lower_bound': 0.8604651162790697, 'upper_bound': 0.888283619817998}, {'samples': 1504, 'accuracy': 0.9038513650151667, 'std': 0.006338512919156162, 'lower_bound': 0.8912917087967643, 'upper_bound': 0.916076845298281}, {'samples': 2008, 'accuracy': 0.853447927199191, 'std': 0.007995248153985305, 'lower_bound': 0.8377148634984833, 'upper_bound': 0.8680611729019212}, {'samples': 2512, 'accuracy': 0.9431921132457026, 'std': 0.005290403435914305, 'lower_bound': 0.9327603640040445, 'upper_bound': 0.9534883720930233}, {'samples': 3016, 'accuracy': 0.9381435793731041, 'std': 0.0055612670274229475, 'lower_bound': 0.9266936299292214, 'upper_bound': 0.948432760364004}, {'samples': 3520, 'accuracy': 0.8651769464105157, 'std': 0.007666241342206672, 'lower_bound': 0.8498483316481295, 'upper_bound': 0.8801820020222447}, {'samples': 4024, 'accuracy': 0.9306663296258847, 'std': 0.005826948066593775, 'lower_bound': 0.9186046511627907, 'upper_bound': 0.9418604651162791}, {'samples': 4528, 'accuracy': 0.893309403437816, 'std': 0.006948199324312182, 'lower_bound': 0.8796638018200202, 'upper_bound': 0.9064711830131446}, {'samples': 5032, 'accuracy': 0.9361122345803842, 'std': 0.005530411752426577, 'lower_bound': 0.925669868554095, 'upper_bound': 0.9464105156723963}, {'samples': 5536, 'accuracy': 0.9514484327603641, 'std': 0.004856066389588135, 'lower_bound': 0.9413549039433772, 'upper_bound': 0.9605662285136501}, {'samples': 6040, 'accuracy': 0.8986208291203235, 'std': 0.0068712294833110435, 'lower_bound': 0.884732052578362, 'upper_bound': 0.9115267947421638}, {'samples': 6544, 'accuracy': 0.9597052578361981, 'std': 0.004515846922530171, 'lower_bound': 0.9509479271991911, 'upper_bound': 0.968149646107179}, {'samples': 7048, 'accuracy': 0.9531324570273003, 'std': 0.0046769842003912205, 'lower_bound': 0.9443882709807887, 'upper_bound': 0.962082912032356}, {'samples': 7552, 'accuracy': 0.9657724974721941, 'std': 0.0042659057645035685, 'lower_bound': 0.9575328614762386, 'upper_bound': 0.9737108190091001}, {'samples': 8056, 'accuracy': 0.9438397371081901, 'std': 0.005181392230268503, 'lower_bound': 0.9337714863498483, 'upper_bound': 0.9539939332659252}, {'samples': 8560, 'accuracy': 0.929463599595551, 'std': 0.005876777530495199, 'lower_bound': 0.9180990899898888, 'upper_bound': 0.9408493427704753}, {'samples': 9064, 'accuracy': 0.959566734074823, 'std': 0.004342369391908409, 'lower_bound': 0.9514661274014156, 'upper_bound': 0.968149646107179}, {'samples': 9568, 'accuracy': 0.9134817997977754, 'std': 0.006336222826694522, 'lower_bound': 0.9009100101112234, 'upper_bound': 0.9256825075834176}, {'samples': 10072, 'accuracy': 0.955896865520728, 'std': 0.004463114650780731, 'lower_bound': 0.9469160768452983, 'upper_bound': 0.9646107178968655}, {'samples': 10576, 'accuracy': 0.9284256825075834, 'std': 0.0059768904386312514, 'lower_bound': 0.916076845298281, 'upper_bound': 0.9408493427704753}, {'samples': 11080, 'accuracy': 0.9278574317492416, 'std': 0.005865485693324678, 'lower_bound': 0.917087967644085, 'upper_bound': 0.9398382204246714}, {'samples': 11584, 'accuracy': 0.9290591506572295, 'std': 0.005678691181622698, 'lower_bound': 0.9186046511627907, 'upper_bound': 0.9403437815975733}, {'samples': 12088, 'accuracy': 0.9480894843276038, 'std': 0.005047565867590529, 'lower_bound': 0.9383215369059656, 'upper_bound': 0.9575328614762386}, {'samples': 12592, 'accuracy': 0.9448083923154702, 'std': 0.005038353733873593, 'lower_bound': 0.9347699696663296, 'upper_bound': 0.9539939332659252}, {'samples': 13096, 'accuracy': 0.9201830131445905, 'std': 0.005988352694295926, 'lower_bound': 0.9084807886754297, 'upper_bound': 0.9317492416582407}, {'samples': 13600, 'accuracy': 0.9420166835187058, 'std': 0.005161963252684602, 'lower_bound': 0.9312436804853387, 'upper_bound': 0.9514661274014156}, {'samples': 14104, 'accuracy': 0.9575722952477249, 'std': 0.004604713663670947, 'lower_bound': 0.9489383215369059, 'upper_bound': 0.9661274014155713}, {'samples': 14608, 'accuracy': 0.956665318503539, 'std': 0.00452761980333678, 'lower_bound': 0.9474216380182002, 'upper_bound': 0.9656218402426694}, {'samples': 15112, 'accuracy': 0.9466137512639029, 'std': 0.0051326883890290146, 'lower_bound': 0.9362992922143579, 'upper_bound': 0.9560288169868555}, {'samples': 15616, 'accuracy': 0.9550596562184024, 'std': 0.004826251660944385, 'lower_bound': 0.9448938321536906, 'upper_bound': 0.9641051567239636}]