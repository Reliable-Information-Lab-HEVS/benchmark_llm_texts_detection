Evaluating the best model on the test set of dataset fake_true_datasets/fake_true_dataset_gemma_chat_10k...
Test metrics:
accuracy: 0.9532806224899598
precision: 0.9622939978071315
recall: 0.9435872492559669
f1_score: 0.9528275292979351
fp_rate: 0.037013140986082646
tp_rate: 0.9435872492559669
std_accuracy: 0.004617785629482263
std_precision: 0.006031401734379805
std_recall: 0.007121407608509393
std_f1_score: 0.004848416042262739
std_fp_rate: 0.005819954610912715
std_tp_rate: 0.007121407608509393
TP: 940.537
TN: 958.398
FP: 36.844
FN: 56.221
roc_auc: 0.9931624086708278
fpr: [0.         0.         0.         0.00100402 0.00100402 0.00200803
 0.00200803 0.00301205 0.00301205 0.00401606 0.00401606 0.00502008
 0.00502008 0.0060241  0.0060241  0.00702811 0.00702811 0.00803213
 0.00803213 0.00903614 0.00903614 0.01004016 0.01004016 0.01204819
 0.01204819 0.01305221 0.01305221 0.01405622 0.01405622 0.01506024
 0.01506024 0.01706827 0.01706827 0.01907631 0.01907631 0.02309237
 0.02309237 0.02409639 0.02409639 0.02610442 0.02610442 0.02811245
 0.02811245 0.02911647 0.02911647 0.03012048 0.03012048 0.0311245
 0.0311245  0.03313253 0.03313253 0.03413655 0.03413655 0.03614458
 0.03614458 0.03714859 0.03714859 0.04016064 0.04016064 0.04216867
 0.04216867 0.04317269 0.04317269 0.04618474 0.04618474 0.04919679
 0.04919679 0.0502008  0.0502008  0.05120482 0.05120482 0.05220884
 0.05220884 0.05321285 0.05321285 0.05722892 0.05722892 0.05823293
 0.05823293 0.06024096 0.06024096 0.06425703 0.06425703 0.06726908
 0.06726908 0.07429719 0.07429719 0.0753012  0.0753012  0.08232932
 0.08232932 0.0873494  0.0873494  0.08935743 0.08935743 0.09036145
 0.09036145 0.09236948 0.09236948 0.09638554 0.09638554 0.09839357
 0.09839357 0.10441767 0.10441767 0.10542169 0.10542169 0.1064257
 0.1064257  0.10943775 0.10943775 0.11044177 0.11044177 0.11345382
 0.11345382 0.11646586 0.11646586 0.11746988 0.11746988 0.12449799
 0.12449799 0.15963855 0.15963855 0.1746988  0.1746988  0.2248996
 0.2248996  0.23594378 0.23594378 1.        ]
tpr: [0.         0.00100402 0.45983936 0.45983936 0.49598394 0.49598394
 0.70883534 0.70883534 0.75200803 0.75200803 0.78413655 0.78413655
 0.84136546 0.84136546 0.84437751 0.84437751 0.8564257  0.8564257
 0.87349398 0.87349398 0.89658635 0.89658635 0.90662651 0.90662651
 0.91164659 0.91164659 0.91365462 0.91365462 0.91465863 0.91465863
 0.91967871 0.91967871 0.92369478 0.92369478 0.92570281 0.92570281
 0.92670683 0.92670683 0.92771084 0.92771084 0.92971888 0.92971888
 0.93072289 0.93072289 0.93473896 0.93473896 0.93875502 0.93875502
 0.93975904 0.93975904 0.94277108 0.94277108 0.9437751  0.9437751
 0.94477912 0.94477912 0.94578313 0.94578313 0.94779116 0.94779116
 0.94879518 0.94879518 0.95381526 0.95381526 0.95481928 0.95481928
 0.95682731 0.95682731 0.95783133 0.95783133 0.95883534 0.95883534
 0.96084337 0.96084337 0.96184739 0.96184739 0.96586345 0.96586345
 0.97088353 0.97088353 0.97188755 0.97188755 0.97289157 0.97289157
 0.97389558 0.97389558 0.97791165 0.97791165 0.97891566 0.97891566
 0.97991968 0.97991968 0.98092369 0.98092369 0.98192771 0.98192771
 0.98293173 0.98293173 0.98393574 0.98393574 0.98493976 0.98493976
 0.98594378 0.98594378 0.98694779 0.98694779 0.98795181 0.98795181
 0.98995984 0.98995984 0.99096386 0.99096386 0.99196787 0.99196787
 0.99297189 0.99297189 0.9939759  0.9939759  0.99497992 0.99497992
 0.99598394 0.99598394 0.99698795 0.99698795 0.99799197 0.99799197
 0.99899598 0.99899598 1.         1.        ]
thresholds: [           inf  3.0861740e+00  2.5853109e+00  2.5802925e+00
  2.5273125e+00  2.5236456e+00  2.0499692e+00  2.0270915e+00
  1.8139551e+00  1.8132684e+00  1.6635650e+00  1.6625569e+00
  1.3388321e+00  1.3341393e+00  1.3276180e+00  1.3208063e+00
  1.2067235e+00  1.1916149e+00  1.1251589e+00  1.1226552e+00
  9.0726924e-01  9.0411383e-01  8.1323272e-01  8.0122888e-01
  7.5247556e-01  7.4258918e-01  7.2749132e-01  7.2207421e-01
  7.0657086e-01  6.9887567e-01  6.6036093e-01  6.1844653e-01
  5.8295894e-01  5.5671918e-01  5.0851780e-01  4.5289534e-01
  4.4250318e-01  4.4051993e-01  4.3037370e-01  2.8424704e-01
  2.5149468e-01  2.3786424e-01  2.3496126e-01  1.9806063e-01
  1.4636873e-01  1.3407136e-01  1.0967357e-01  7.1863331e-02
  7.1231939e-02  4.0421098e-02  6.1916020e-03 -2.2672850e-04
 -1.0890689e-03 -1.7831380e-02 -3.9135285e-02 -7.8137904e-02
 -7.9421423e-02 -1.1487765e-01 -1.4399785e-01 -1.8353491e-01
 -2.0845561e-01 -2.4173960e-01 -2.5331500e-01 -2.8365231e-01
 -3.0137420e-01 -4.0851870e-01 -4.3261671e-01 -4.5100006e-01
 -4.5172754e-01 -4.5377868e-01 -4.5403075e-01 -4.6329632e-01
 -5.0328231e-01 -5.4306740e-01 -5.5068356e-01 -6.0154706e-01
 -6.4249784e-01 -6.6108066e-01 -7.0106000e-01 -7.4867922e-01
 -7.4881727e-01 -7.6345205e-01 -7.6394403e-01 -8.2055724e-01
 -8.2548285e-01 -8.8967633e-01 -9.0507120e-01 -9.1506571e-01
 -9.1853404e-01 -1.0124762e+00 -1.0251422e+00 -1.0758733e+00
 -1.0953113e+00 -1.1275884e+00 -1.1333164e+00 -1.1529044e+00
 -1.1533557e+00 -1.1770234e+00 -1.1905116e+00 -1.2425061e+00
 -1.2476051e+00 -1.2811166e+00 -1.2836891e+00 -1.3340318e+00
 -1.3404869e+00 -1.3542610e+00 -1.3669111e+00 -1.3763728e+00
 -1.4066666e+00 -1.4371383e+00 -1.4565803e+00 -1.4609246e+00
 -1.4624703e+00 -1.4768182e+00 -1.5030583e+00 -1.5320238e+00
 -1.5415580e+00 -1.5428026e+00 -1.5439965e+00 -1.5977148e+00
 -1.5995663e+00 -1.7996668e+00 -1.8134184e+00 -1.8750242e+00
 -1.8762679e+00 -2.1157782e+00 -2.1294484e+00 -2.1890316e+00
 -2.1899064e+00 -2.9244184e+00]
Test metrics at specific given threshold:
accuracy: 0.9537951807228915
precision: 0.9466432514804859
recall: 0.9617184541620055
f1_score: 0.9541010808030992
fp_rate: 0.05411680904302686
tp_rate: 0.9617184541620055
std_accuracy: 0.004843594522319846
std_precision: 0.007017487287809172
std_recall: 0.006057292655849133
std_f1_score: 0.004882846564676634
std_fp_rate: 0.007164357654665335
std_tp_rate: 0.006057292655849133
TP: 957.027
TN: 942.933
FP: 53.942
FN: 38.098
