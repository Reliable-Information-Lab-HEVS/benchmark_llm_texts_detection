Flipping labels for the dataset
Evaluating the best model on the test set of dataset fake_true_datasets/modified_datasets/fake_true_dataset_phi_10k_cnn_style_gemma_2b_chat...
Test metrics:
accuracy: 0.7757609999999999
precision: 0.8748811886371118
recall: 0.6427776184086212
f1_score: 0.7408650505353115
fp_rate: 0.09163496609707365
tp_rate: 0.6427776184086212
std_accuracy: 0.013274030247065144
std_precision: 0.017853441837343487
std_recall: 0.021618297428697173
std_f1_score: 0.017177749589051185
std_fp_rate: 0.013007601530184995
std_tp_rate: 0.021618297428697173
TP: 454.794
TN: 320.967
FP: 178.352
FN: 45.887
roc_auc: 0.8479319999999999
fpr: [0.    0.    0.    0.002 0.002 0.004 0.004 0.006 0.006 0.008 0.008 0.01
 0.01  0.012 0.012 0.014 0.014 0.016 0.016 0.018 0.018 0.02  0.02  0.022
 0.022 0.024 0.024 0.026 0.026 0.028 0.028 0.03  0.03  0.032 0.032 0.036
 0.036 0.04  0.04  0.042 0.042 0.044 0.044 0.046 0.046 0.048 0.048 0.05
 0.05  0.052 0.052 0.054 0.054 0.056 0.056 0.058 0.058 0.06  0.06  0.062
 0.062 0.064 0.064 0.066 0.066 0.068 0.068 0.07  0.07  0.072 0.072 0.078
 0.078 0.08  0.08  0.082 0.082 0.084 0.084 0.088 0.088 0.092 0.092 0.096
 0.096 0.098 0.098 0.102 0.102 0.104 0.104 0.106 0.106 0.108 0.108 0.11
 0.11  0.116 0.116 0.118 0.118 0.122 0.122 0.13  0.13  0.132 0.132 0.134
 0.134 0.136 0.136 0.138 0.138 0.142 0.142 0.146 0.146 0.154 0.154 0.156
 0.156 0.16  0.16  0.162 0.162 0.166 0.166 0.168 0.168 0.174 0.174 0.186
 0.186 0.188 0.188 0.19  0.19  0.194 0.194 0.196 0.196 0.2   0.2   0.204
 0.204 0.208 0.208 0.212 0.212 0.214 0.214 0.218 0.218 0.222 0.222 0.228
 0.228 0.23  0.23  0.234 0.234 0.254 0.254 0.258 0.258 0.26  0.26  0.266
 0.266 0.278 0.278 0.282 0.282 0.288 0.288 0.308 0.308 0.314 0.314 0.316
 0.316 0.322 0.322 0.328 0.328 0.334 0.334 0.336 0.336 0.354 0.354 0.368
 0.368 0.37  0.37  0.374 0.374 0.376 0.376 0.384 0.384 0.392 0.392 0.402
 0.402 0.408 0.408 0.422 0.422 0.426 0.426 0.432 0.432 0.446 0.446 0.45
 0.45  0.452 0.452 0.454 0.454 0.474 0.474 0.49  0.49  0.494 0.494 0.5
 0.5   0.504 0.504 0.506 0.506 0.508 0.508 0.51  0.51  0.512 0.512 0.518
 0.518 0.528 0.528 0.538 0.538 0.55  0.55  0.558 0.558 0.56  0.56  0.576
 0.576 0.578 0.578 0.582 0.582 0.586 0.586 0.596 0.596 0.598 0.598 0.606
 0.606 0.608 0.608 0.614 0.614 0.62  0.62  0.622 0.622 0.63  0.63  0.648
 0.648 0.65  0.65  0.678 0.678 0.684 0.684 0.696 0.696 0.702 0.702 0.712
 0.712 0.754 0.754 0.764 0.764 0.766 0.766 0.78  0.78  0.788 0.788 0.79
 0.79  0.806 0.806 0.814 0.814 0.816 0.816 0.834 0.834 0.836 0.836 0.876
 0.876 0.906 0.906 0.918 0.918 0.932 0.932 0.934 0.934 0.984 0.984 1.   ]
tpr: [0.    0.002 0.106 0.106 0.156 0.156 0.248 0.248 0.284 0.284 0.296 0.296
 0.346 0.346 0.394 0.394 0.398 0.398 0.412 0.412 0.422 0.422 0.432 0.432
 0.45  0.45  0.47  0.47  0.474 0.474 0.482 0.482 0.49  0.49  0.492 0.492
 0.494 0.494 0.502 0.502 0.506 0.506 0.53  0.53  0.534 0.534 0.542 0.542
 0.552 0.552 0.554 0.554 0.564 0.564 0.57  0.57  0.578 0.578 0.58  0.58
 0.582 0.582 0.586 0.586 0.588 0.588 0.59  0.59  0.592 0.592 0.606 0.606
 0.608 0.608 0.618 0.618 0.626 0.626 0.63  0.63  0.64  0.64  0.644 0.644
 0.648 0.648 0.65  0.65  0.658 0.658 0.674 0.674 0.678 0.678 0.68  0.68
 0.682 0.682 0.688 0.688 0.69  0.69  0.692 0.692 0.706 0.706 0.708 0.708
 0.71  0.71  0.72  0.72  0.722 0.722 0.734 0.734 0.738 0.738 0.746 0.746
 0.748 0.748 0.75  0.75  0.752 0.752 0.754 0.754 0.756 0.756 0.758 0.758
 0.76  0.76  0.762 0.762 0.764 0.764 0.766 0.766 0.768 0.768 0.77  0.77
 0.774 0.774 0.776 0.776 0.778 0.778 0.78  0.78  0.782 0.782 0.784 0.784
 0.786 0.786 0.788 0.788 0.79  0.79  0.792 0.792 0.794 0.794 0.796 0.796
 0.798 0.798 0.802 0.802 0.804 0.804 0.812 0.812 0.814 0.814 0.818 0.818
 0.82  0.82  0.822 0.822 0.826 0.826 0.828 0.828 0.83  0.83  0.832 0.832
 0.834 0.834 0.836 0.836 0.838 0.838 0.84  0.84  0.842 0.842 0.844 0.844
 0.846 0.846 0.848 0.848 0.85  0.85  0.854 0.854 0.856 0.856 0.858 0.858
 0.862 0.862 0.864 0.864 0.866 0.866 0.868 0.868 0.87  0.87  0.872 0.872
 0.874 0.874 0.878 0.878 0.88  0.88  0.882 0.882 0.884 0.884 0.886 0.886
 0.888 0.888 0.892 0.892 0.894 0.894 0.896 0.896 0.898 0.898 0.9   0.9
 0.902 0.902 0.904 0.904 0.906 0.906 0.908 0.908 0.91  0.91  0.914 0.914
 0.918 0.918 0.92  0.92  0.924 0.924 0.926 0.926 0.928 0.928 0.93  0.93
 0.932 0.932 0.934 0.934 0.936 0.936 0.94  0.94  0.952 0.952 0.954 0.954
 0.956 0.956 0.958 0.958 0.96  0.96  0.962 0.962 0.964 0.964 0.968 0.968
 0.97  0.97  0.972 0.972 0.974 0.974 0.976 0.976 0.978 0.978 0.982 0.982
 0.984 0.984 0.986 0.986 0.988 0.988 0.992 0.992 0.998 0.998 1.    1.   ]
thresholds: [        inf  4.7094088   4.4328103   4.420733    4.1689587   4.161752
  3.3898697   3.3804214   3.1831682   3.176591    3.1137428   3.0619423
  2.6172142   2.5971656   2.286595    2.2664266   2.1745636   2.1478696
  1.9986322   1.9928658   1.9262087   1.9041985   1.8267305   1.822807
  1.7344577   1.725924    1.6249052   1.6118169   1.5558723   1.4614749
  1.4271798   1.4257184   1.3300881   1.30307     1.2788316   1.2211485
  1.1934503   1.152836    1.1199771   1.1113334   1.0891626   1.0877966
  0.9677309   0.93790907  0.9081521   0.9044099   0.8165644   0.8123351
  0.79130673  0.78627986  0.7760271   0.7712801   0.67897123  0.67623216
  0.63422316  0.6214588   0.5708436   0.55940896  0.5508149   0.5481038
  0.5290437   0.51929474  0.51284397  0.499809    0.49490073  0.4941866
  0.4624055   0.4075253   0.40286404  0.3708031   0.2912479   0.20085679
  0.18435274  0.14604723  0.11939529  0.08913606  0.07761946  0.06057579
  0.04945517  0.01623427 -0.02214537 -0.03148035 -0.10330376 -0.13387188
 -0.15860778 -0.19949897 -0.20317249 -0.21576399 -0.22629242 -0.23933867
 -0.31316942 -0.3879348  -0.40465316 -0.40650493 -0.42091653 -0.42663807
 -0.4543943  -0.4968989  -0.5352094  -0.5382139  -0.5530602  -0.5545728
 -0.5803695  -0.6315277  -0.7195408  -0.745757   -0.7580914  -0.764634
 -0.7673222  -0.7726854  -0.8232478  -0.8238732  -0.83251333 -0.86819965
 -0.9049901  -0.9107827  -0.9221875  -0.94145155 -0.95869094 -0.9615762
 -0.9779055  -1.0027363  -1.0040817  -1.0072333  -1.0077853  -1.0158358
 -1.0232908  -1.0233307  -1.0615138  -1.110003   -1.1102717  -1.1903667
 -1.190623   -1.1972017  -1.2084844  -1.2146547  -1.2257986  -1.2297556
 -1.2314054  -1.2336916  -1.2447169  -1.2503073  -1.2664127  -1.2828667
 -1.292992   -1.3070306  -1.308954   -1.3154624  -1.3300472  -1.336197
 -1.3369542  -1.3646538  -1.3979776  -1.4145364  -1.4271544  -1.4419494
 -1.466616   -1.4730729  -1.4765121  -1.4949611  -1.4968749  -1.5602901
 -1.5651729  -1.5905414  -1.5908349  -1.5958837  -1.6108109  -1.633516
 -1.6398958  -1.7049516  -1.7079626  -1.7175311  -1.7249836  -1.7291895
 -1.7857368  -1.8503705  -1.8594968  -1.8882743  -1.907401   -1.9102588
 -1.9164678  -1.9690943  -1.982821   -2.0070736  -2.0104327  -2.0397213
 -2.0507507  -2.060909   -2.0742943  -2.1259882  -2.1421275  -2.2030056
 -2.2085962  -2.211867   -2.2152984  -2.2228024  -2.226285   -2.2410092
 -2.244972   -2.269996   -2.2835605  -2.3239858  -2.3297288  -2.383174
 -2.3891077  -2.4050033  -2.409574   -2.4562736  -2.461713   -2.4789765
 -2.4910572  -2.504249   -2.5172598  -2.5726929  -2.5780163  -2.6192036
 -2.6219468  -2.6455634  -2.6483624  -2.649203   -2.6565828  -2.7487237
 -2.753571   -2.8249323  -2.8318367  -2.8435426  -2.8555012  -2.864165
 -2.8650882  -2.8678842  -2.8723104  -2.876838   -2.889892   -2.9223409
 -2.9379237  -2.9391065  -2.9431012  -2.9494958  -2.970527   -3.0007997
 -3.0010848  -3.0413144  -3.069962   -3.0897787  -3.0921648  -3.126844
 -3.127191   -3.13869    -3.1465156  -3.1490307  -3.154746   -3.2227273
 -3.2299087  -3.2337239  -3.2439308  -3.250724   -3.2520664  -3.2694285
 -3.2712398  -3.2969046  -3.2996173  -3.3073509  -3.3378692  -3.3685687
 -3.4146187  -3.4155815  -3.4164488  -3.440691   -3.4610813  -3.49112
 -3.5090687  -3.5130365  -3.5269985  -3.5609157  -3.5770469  -3.618057
 -3.6277113  -3.6331031  -3.6336136  -3.7022457  -3.7259104  -3.7462943
 -3.7606711  -3.8201537  -3.886981   -3.898378   -3.9124386  -3.948038
 -3.9525576  -4.074633   -4.082267   -4.115808   -4.1257663  -4.13018
 -4.165843   -4.1942687  -4.1951156  -4.2241626  -4.2331076  -4.2392716
 -4.2429833  -4.3101664  -4.315681   -4.327686   -4.330123   -4.339096
 -4.3499928  -4.386558   -4.3912582  -4.3970113  -4.41098    -4.518733
 -4.5211687  -4.5822544  -4.5875454  -4.60385    -4.604983   -4.632798
 -4.63686    -4.6379085  -4.649548   -4.7105703  -4.710635   -4.717207  ]
Test metrics at specific given threshold:
accuracy: 0.791106
precision: 0.8133578287721727
recall: 0.7562143402620206
f1_score: 0.7835792893189303
fp_rate: 0.17394231384500342
tp_rate: 0.7562143402620206
std_accuracy: 0.01262872772689316
std_precision: 0.0178480274542692
std_recall: 0.018966539732319165
std_f1_score: 0.014570339659935358
std_fp_rate: 0.01651625243894565
std_tp_rate: 0.018966539732319165
TP: 412.513
TN: 378.593
FP: 122.038
FN: 86.856
