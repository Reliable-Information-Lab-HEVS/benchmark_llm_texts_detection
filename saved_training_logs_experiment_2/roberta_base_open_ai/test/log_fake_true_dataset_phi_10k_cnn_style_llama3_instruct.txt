Flipping labels for the dataset
Evaluating the best model on the test set of dataset fake_true_datasets/modified_datasets/fake_true_dataset_phi_10k_cnn_style_llama3_instruct...
Test metrics:
accuracy: 0.545914
precision: 0.6651653579268612
recall: 0.18251087093758592
f1_score: 0.2861014530416545
fp_rate: 0.09163496609707365
tp_rate: 0.18251087093758592
std_accuracy: 0.0159844488175226
std_precision: 0.04083718562693537
std_recall: 0.017219329602461263
std_f1_score: 0.0233238467751357
std_fp_rate: 0.013007601530184995
std_tp_rate: 0.017219329602461263
TP: 454.794
TN: 91.12
FP: 408.199
FN: 45.887
roc_auc: 0.446992
fpr: [0.    0.    0.    0.002 0.002 0.004 0.004 0.006 0.006 0.008 0.008 0.01
 0.01  0.012 0.012 0.014 0.014 0.016 0.016 0.018 0.018 0.022 0.022 0.024
 0.024 0.026 0.026 0.03  0.03  0.032 0.032 0.034 0.034 0.042 0.042 0.044
 0.044 0.048 0.048 0.05  0.05  0.054 0.054 0.056 0.056 0.058 0.058 0.068
 0.068 0.07  0.07  0.072 0.072 0.078 0.078 0.08  0.08  0.082 0.082 0.086
 0.086 0.088 0.088 0.092 0.092 0.096 0.096 0.102 0.102 0.104 0.104 0.106
 0.106 0.108 0.108 0.11  0.11  0.116 0.116 0.122 0.122 0.13  0.13  0.136
 0.136 0.138 0.138 0.142 0.142 0.154 0.154 0.156 0.156 0.162 0.162 0.168
 0.168 0.17  0.17  0.174 0.174 0.184 0.184 0.186 0.186 0.19  0.19  0.196
 0.196 0.2   0.2   0.202 0.202 0.204 0.204 0.218 0.218 0.23  0.23  0.234
 0.234 0.238 0.238 0.248 0.248 0.256 0.256 0.26  0.26  0.288 0.288 0.306
 0.306 0.308 0.308 0.312 0.312 0.32  0.32  0.322 0.322 0.328 0.328 0.332
 0.332 0.334 0.334 0.336 0.336 0.36  0.36  0.37  0.37  0.374 0.374 0.378
 0.378 0.398 0.398 0.424 0.424 0.432 0.432 0.438 0.438 0.446 0.446 0.448
 0.448 0.45  0.45  0.456 0.456 0.46  0.46  0.468 0.468 0.47  0.47  0.472
 0.472 0.476 0.476 0.488 0.488 0.492 0.492 0.496 0.496 0.506 0.506 0.512
 0.512 0.518 0.518 0.52  0.52  0.526 0.526 0.528 0.528 0.532 0.532 0.534
 0.534 0.538 0.538 0.54  0.54  0.548 0.548 0.554 0.554 0.558 0.558 0.56
 0.56  0.57  0.57  0.582 0.582 0.584 0.584 0.592 0.592 0.598 0.598 0.602
 0.602 0.606 0.606 0.608 0.608 0.62  0.62  0.624 0.624 0.626 0.626 0.632
 0.632 0.646 0.646 0.648 0.648 0.654 0.654 0.668 0.668 0.678 0.678 0.688
 0.688 0.692 0.692 0.696 0.696 0.702 0.702 0.708 0.708 0.716 0.716 0.73
 0.73  0.732 0.732 0.738 0.738 0.742 0.742 0.748 0.748 0.75  0.75  0.752
 0.752 0.754 0.754 0.764 0.764 0.766 0.766 0.768 0.768 0.77  0.77  0.78
 0.78  0.786 0.786 0.788 0.788 0.79  0.79  0.792 0.792 0.796 0.796 0.8
 0.8   0.804 0.804 0.81  0.81  0.814 0.814 0.816 0.816 0.826 0.826 0.828
 0.828 0.83  0.83  0.834 0.834 0.836 0.836 0.838 0.838 0.842 0.842 0.844
 0.844 0.846 0.846 0.854 0.854 0.856 0.856 0.862 0.862 0.864 0.864 0.866
 0.866 0.87  0.87  0.872 0.872 0.874 0.874 0.876 0.876 0.878 0.878 0.88
 0.88  0.884 0.884 0.886 0.886 0.888 0.888 0.89  0.89  0.896 0.896 0.898
 0.898 0.906 0.906 0.908 0.908 0.912 0.912 0.916 0.916 0.918 0.918 0.92
 0.92  0.924 0.924 0.928 0.928 0.93  0.93  0.932 0.932 0.934 0.934 0.936
 0.936 0.938 0.938 0.94  0.94  0.942 0.942 0.946 0.946 0.948 0.948 0.952
 0.952 0.954 0.954 0.956 0.956 0.962 0.962 0.964 0.964 0.966 0.966 0.97
 0.97  0.972 0.972 0.974 0.974 0.978 0.978 0.982 0.982 0.984 0.984 0.988
 0.988 0.99  0.99  0.992 0.992 0.994 0.994 0.996 0.996 0.998 0.998 1.
 1.   ]
tpr: [0.    0.002 0.006 0.006 0.016 0.016 0.036 0.036 0.038 0.038 0.04  0.04
 0.06  0.06  0.08  0.08  0.084 0.084 0.09  0.09  0.098 0.098 0.1   0.1
 0.106 0.106 0.11  0.11  0.112 0.112 0.12  0.12  0.124 0.124 0.126 0.126
 0.132 0.132 0.134 0.134 0.136 0.136 0.14  0.14  0.144 0.144 0.148 0.148
 0.154 0.154 0.164 0.164 0.166 0.166 0.17  0.17  0.172 0.172 0.174 0.174
 0.176 0.176 0.178 0.178 0.192 0.192 0.198 0.198 0.202 0.202 0.214 0.214
 0.216 0.216 0.22  0.22  0.224 0.224 0.226 0.226 0.23  0.23  0.244 0.244
 0.256 0.256 0.258 0.258 0.262 0.262 0.266 0.266 0.268 0.268 0.27  0.27
 0.274 0.274 0.276 0.276 0.28  0.28  0.284 0.284 0.286 0.286 0.288 0.288
 0.29  0.29  0.294 0.294 0.296 0.296 0.298 0.298 0.302 0.302 0.304 0.304
 0.306 0.306 0.308 0.308 0.312 0.312 0.314 0.314 0.322 0.322 0.328 0.328
 0.33  0.33  0.334 0.334 0.336 0.336 0.346 0.346 0.354 0.354 0.358 0.358
 0.362 0.362 0.364 0.364 0.366 0.366 0.368 0.368 0.376 0.376 0.38  0.38
 0.382 0.382 0.384 0.384 0.386 0.386 0.39  0.39  0.392 0.392 0.394 0.394
 0.396 0.396 0.398 0.398 0.402 0.402 0.404 0.404 0.406 0.406 0.41  0.41
 0.414 0.414 0.416 0.416 0.418 0.418 0.422 0.422 0.424 0.424 0.428 0.428
 0.43  0.43  0.434 0.434 0.436 0.436 0.438 0.438 0.44  0.44  0.442 0.442
 0.444 0.444 0.446 0.446 0.448 0.448 0.45  0.45  0.452 0.452 0.454 0.454
 0.458 0.458 0.46  0.46  0.462 0.462 0.466 0.466 0.47  0.47  0.476 0.476
 0.482 0.482 0.486 0.486 0.49  0.49  0.496 0.496 0.498 0.498 0.5   0.5
 0.502 0.502 0.506 0.506 0.508 0.508 0.51  0.51  0.512 0.512 0.514 0.514
 0.516 0.516 0.518 0.518 0.534 0.534 0.538 0.538 0.54  0.54  0.542 0.542
 0.544 0.544 0.548 0.548 0.55  0.55  0.552 0.552 0.554 0.554 0.556 0.556
 0.558 0.558 0.56  0.56  0.562 0.562 0.564 0.564 0.566 0.566 0.57  0.57
 0.574 0.574 0.576 0.576 0.58  0.58  0.582 0.582 0.584 0.584 0.586 0.586
 0.588 0.588 0.592 0.592 0.594 0.594 0.598 0.598 0.602 0.602 0.612 0.612
 0.614 0.614 0.618 0.618 0.62  0.62  0.626 0.626 0.632 0.632 0.638 0.638
 0.64  0.64  0.644 0.644 0.646 0.646 0.654 0.654 0.66  0.66  0.664 0.664
 0.666 0.666 0.668 0.668 0.672 0.672 0.676 0.676 0.688 0.688 0.69  0.69
 0.694 0.694 0.704 0.704 0.706 0.706 0.71  0.71  0.714 0.714 0.72  0.72
 0.732 0.732 0.742 0.742 0.744 0.744 0.748 0.748 0.756 0.756 0.758 0.758
 0.76  0.76  0.764 0.764 0.776 0.776 0.784 0.784 0.792 0.792 0.804 0.804
 0.812 0.812 0.816 0.816 0.832 0.832 0.84  0.84  0.85  0.85  0.858 0.858
 0.88  0.88  0.882 0.882 0.892 0.892 0.902 0.902 0.904 0.904 0.906 0.906
 0.914 0.914 0.928 0.928 0.934 0.934 0.94  0.94  0.948 0.948 0.95  0.95
 0.96  0.96  0.962 0.962 0.972 0.972 0.982 0.982 0.99  0.99  0.994 0.994
 1.   ]
thresholds: [        inf  4.703483    4.4435544   4.420733    4.2678504   4.161752
  3.7164948   3.3804214   3.1958425   3.176591    3.0741646   3.0619423
  2.6220548   2.5971656   2.2718875   2.2664266   2.157667    2.1478696
  2.033175    1.9928658   1.9418043   1.822807    1.765764    1.725924
  1.6230739   1.6118169   1.4859692   1.4257184   1.3482509   1.30307
  1.2722251   1.2673293   1.2327847   1.1113334   1.1008989   1.0877966
  0.95987266  0.9044099   0.8139295   0.8123351   0.792151    0.7712801
  0.695912    0.67623216  0.66053045  0.6214588   0.57046735  0.4941866
  0.41013476  0.4075253   0.3731549   0.3708031   0.35117826  0.20085679
  0.17374046  0.14604723  0.13601801  0.08913606  0.08535366  0.03955255
  0.02981421  0.01623427 -0.021055   -0.03148035 -0.12459976 -0.13387188
 -0.18631424 -0.21576399 -0.23351082 -0.23933867 -0.33853513 -0.3879348
 -0.40298945 -0.40650493 -0.4161761  -0.42663807 -0.45533687 -0.4968989
 -0.50452054 -0.5545728  -0.60048896 -0.6315277  -0.739509   -0.7726854
 -0.8203366  -0.8238732  -0.8344542  -0.86819965 -0.9031953  -0.94145155
 -0.9615328  -0.9615762  -0.98454165 -1.0072333  -1.0113561  -1.0233307
 -1.0508436  -1.1023262  -1.1052853  -1.110003   -1.1315616  -1.1800573
 -1.1875011  -1.1903667  -1.1972002  -1.2146547  -1.2157298  -1.2336916
 -1.2341796  -1.2503073  -1.2642099  -1.2670939  -1.28206    -1.2828667
 -1.2858357  -1.3646538  -1.3862941  -1.4730729  -1.4761084  -1.4949611
 -1.4964389  -1.4994833  -1.5024321  -1.5280339  -1.5464389  -1.5728276
 -1.5837903  -1.5958837  -1.6193609  -1.7291895  -1.7602891  -1.8405629
 -1.8432091  -1.8503705  -1.8654737  -1.8677078  -1.8719405  -1.9365232
 -1.9676087  -1.9690943  -1.9955425  -2.0070736  -2.0159569  -2.0219631
 -2.0393064  -2.0397213  -2.043082   -2.060909   -2.0707905  -2.1591706
 -2.1617625  -2.211867   -2.2206206  -2.2228024  -2.2348135  -2.2456226
 -2.2519832  -2.3635345  -2.3752534  -2.463528   -2.473279   -2.504249
 -2.5273292  -2.5433807  -2.5443134  -2.5726929  -2.575186   -2.5809124
 -2.6094017  -2.6192036  -2.6226377  -2.6598241  -2.6764312  -2.685264
 -2.6879427  -2.7052479  -2.7062411  -2.7084546  -2.7174258  -2.7303817
 -2.7411811  -2.76118    -2.7769353  -2.8096414  -2.81997    -2.8326411
 -2.8366628  -2.8576522  -2.8585117  -2.876838   -2.9203825  -2.9494958
 -2.9782393  -3.0007997  -3.0106788  -3.01317    -3.0191019  -3.0383148
 -3.0403318  -3.0413144  -3.0639699  -3.0800667  -3.0801413  -3.0829124
 -3.0854003  -3.0897787  -3.090555   -3.0940223  -3.0996728  -3.1228626
 -3.1254275  -3.130953   -3.1313834  -3.13869    -3.1406474  -3.1490307
 -3.1612513  -3.2038414  -3.207786   -3.250724   -3.254925   -3.2634397
 -3.2660577  -3.2759662  -3.2870133  -3.3073509  -3.3374727  -3.3427925
 -3.3531284  -3.3685687  -3.391569   -3.4155815  -3.4172342  -3.49112
 -3.501567   -3.5285285  -3.5365548  -3.545138   -3.5553858  -3.582015
 -3.586229   -3.6112232  -3.6175454  -3.618057   -3.620097   -3.6389368
 -3.6455684  -3.6834986  -3.6885958  -3.7022457  -3.7052252  -3.7942812
 -3.795009   -3.802414   -3.808212   -3.8201537  -3.8915935  -3.898378
 -3.9104748  -3.9349062  -3.9375174  -3.9617903  -3.966798   -3.987992
 -3.9983902  -4.004746   -4.020572   -4.0229573  -4.0239344  -4.030545
 -4.035729   -4.045714   -4.0520587  -4.054068   -4.0580206  -4.0624332
 -4.068954   -4.074633   -4.0865026  -4.115808   -4.1167517  -4.13018
 -4.164514   -4.1708517  -4.172478   -4.1733494  -4.1788716  -4.1942687
 -4.2029433  -4.211      -4.2160654  -4.2241626  -4.2326326  -4.2392716
 -4.261284   -4.2681203  -4.277302   -4.2856283  -4.2871213  -4.2906737
 -4.3020816  -4.308804   -4.309773   -4.3229756  -4.3250065  -4.327686
 -4.337677   -4.339096   -4.3519754  -4.3587275  -4.3708816  -4.371757
 -4.3719516  -4.3742723  -4.3752375  -4.386558   -4.392389   -4.3970113
 -4.418136   -4.418841   -4.428379   -4.4332495  -4.4387     -4.440411
 -4.441541   -4.441898   -4.4468765  -4.453701   -4.457605   -4.4578447
 -4.4653325  -4.4701405  -4.4743123  -4.479177   -4.484283   -4.484822
 -4.4850354  -4.4975486  -4.498397   -4.5031     -4.5114913  -4.512041
 -4.518495   -4.518733   -4.5303755  -4.5316033  -4.5325203  -4.5325484
 -4.5368924  -4.539078   -4.543106   -4.5439725  -4.549198   -4.5494065
 -4.55073    -4.5549083  -4.559068   -4.5643444  -4.5670753  -4.5708175
 -4.577312   -4.5822544  -4.5923076  -4.593147   -4.5955343  -4.596492
 -4.5977054  -4.598044   -4.602343   -4.60385    -4.604323   -4.606218
 -4.6072216  -4.6141143  -4.6178055  -4.6192393  -4.6258354  -4.626359
 -4.6306286  -4.632798   -4.635886   -4.6379085  -4.649033   -4.6504107
 -4.652719   -4.653709   -4.6558022  -4.6564345  -4.666221   -4.6664844
 -4.6692615  -4.671519   -4.673804   -4.673953   -4.6777897  -4.6811285
 -4.6853256  -4.687511   -4.688642   -4.68918    -4.6924677  -4.6941996
 -4.695619   -4.6957808  -4.69647    -4.696826   -4.696844   -4.6973104
 -4.6996613  -4.6999807  -4.7054124  -4.705861   -4.7061443  -4.7074213
 -4.7095037  -4.7099476  -4.710548   -4.7105703  -4.7105803  -4.7109365
 -4.7112145  -4.711402   -4.711777   -4.711796   -4.712452   -4.7131248
 -4.7140336  -4.714069   -4.7153883  -4.715895   -4.7171617  -4.717207
 -4.7185316 ]
Test metrics at specific given threshold:
accuracy: 0.54952
precision: 0.6090639964795798
recall: 0.2796736238918721
f1_score: 0.38302077427009795
fp_rate: 0.17995666489409234
tp_rate: 0.2796736238918721
std_accuracy: 0.015965951271377454
std_precision: 0.03203937934655325
std_recall: 0.019644653357394327
std_f1_score: 0.02249424023663415
std_fp_rate: 0.01686231182694403
std_tp_rate: 0.019644653357394327
TP: 409.509
TN: 140.011
FP: 360.62
FN: 89.86
