Flipping labels for the dataset
Evaluating the best model on the test set of dataset fake_true_datasets/modified_datasets/fake_true_dataset_phi_10k_repetition_penalty_1.2_zephyr...
Test metrics:
accuracy: 0.52886
precision: 0.617557023008562
recall: 0.14833301066712257
f1_score: 0.23889875373994385
fp_rate: 0.09163496609707365
tp_rate: 0.14833301066712257
std_accuracy: 0.015577817562161917
std_precision: 0.04404774431209373
std_recall: 0.015858979687846744
std_f1_score: 0.022588884964280274
std_fp_rate: 0.013007601530184995
std_tp_rate: 0.015858979687846744
TP: 454.794
TN: 74.066
FP: 425.253
FN: 45.887
roc_auc: 0.537268
fpr: [0.    0.    0.004 0.004 0.006 0.006 0.008 0.008 0.01  0.01  0.012 0.012
 0.014 0.014 0.016 0.016 0.018 0.018 0.022 0.022 0.024 0.024 0.026 0.026
 0.028 0.028 0.03  0.03  0.032 0.032 0.036 0.036 0.04  0.04  0.042 0.042
 0.044 0.044 0.046 0.046 0.048 0.048 0.05  0.05  0.052 0.052 0.054 0.054
 0.058 0.058 0.068 0.068 0.07  0.07  0.072 0.072 0.074 0.074 0.078 0.078
 0.08  0.08  0.082 0.082 0.088 0.088 0.092 0.092 0.096 0.096 0.098 0.098
 0.102 0.102 0.104 0.104 0.106 0.106 0.108 0.108 0.11  0.11  0.112 0.112
 0.116 0.116 0.122 0.122 0.124 0.124 0.128 0.128 0.13  0.13  0.132 0.132
 0.136 0.136 0.138 0.138 0.14  0.14  0.142 0.142 0.146 0.146 0.148 0.148
 0.154 0.154 0.156 0.156 0.158 0.158 0.168 0.168 0.17  0.17  0.174 0.174
 0.176 0.176 0.18  0.18  0.184 0.184 0.188 0.188 0.19  0.19  0.202 0.202
 0.204 0.204 0.21  0.21  0.212 0.212 0.214 0.214 0.216 0.216 0.218 0.218
 0.222 0.222 0.224 0.224 0.228 0.228 0.23  0.23  0.232 0.232 0.238 0.238
 0.24  0.24  0.242 0.242 0.248 0.248 0.25  0.25  0.254 0.254 0.256 0.256
 0.26  0.26  0.266 0.266 0.27  0.27  0.274 0.274 0.276 0.276 0.278 0.278
 0.288 0.288 0.296 0.296 0.3   0.3   0.312 0.312 0.314 0.314 0.316 0.316
 0.32  0.32  0.322 0.322 0.334 0.334 0.336 0.336 0.346 0.346 0.35  0.35
 0.354 0.354 0.366 0.366 0.374 0.374 0.376 0.376 0.384 0.384 0.388 0.388
 0.392 0.392 0.396 0.396 0.398 0.398 0.402 0.402 0.408 0.408 0.418 0.418
 0.422 0.422 0.424 0.424 0.426 0.426 0.432 0.432 0.442 0.442 0.444 0.444
 0.448 0.448 0.45  0.45  0.454 0.454 0.456 0.456 0.462 0.462 0.47  0.47
 0.472 0.472 0.474 0.474 0.476 0.476 0.48  0.48  0.484 0.484 0.488 0.488
 0.49  0.49  0.492 0.492 0.494 0.494 0.506 0.506 0.508 0.508 0.512 0.512
 0.514 0.514 0.516 0.516 0.518 0.518 0.522 0.522 0.528 0.528 0.54  0.54
 0.542 0.542 0.554 0.554 0.558 0.558 0.56  0.56  0.562 0.562 0.572 0.572
 0.582 0.582 0.586 0.586 0.592 0.592 0.598 0.598 0.602 0.602 0.604 0.604
 0.606 0.606 0.61  0.61  0.614 0.614 0.616 0.616 0.62  0.62  0.624 0.624
 0.626 0.626 0.63  0.63  0.638 0.638 0.644 0.644 0.646 0.646 0.648 0.648
 0.656 0.656 0.66  0.66  0.684 0.684 0.686 0.686 0.692 0.692 0.694 0.694
 0.696 0.696 0.702 0.702 0.704 0.704 0.714 0.714 0.716 0.716 0.72  0.72
 0.722 0.722 0.732 0.732 0.742 0.742 0.748 0.748 0.75  0.75  0.756 0.756
 0.76  0.76  0.764 0.764 0.766 0.766 0.77  0.77  0.778 0.778 0.786 0.786
 0.788 0.788 0.79  0.79  0.792 0.792 0.796 0.796 0.8   0.8   0.806 0.806
 0.812 0.812 0.814 0.814 0.816 0.816 0.818 0.818 0.826 0.826 0.832 0.832
 0.834 0.834 0.836 0.836 0.838 0.838 0.84  0.84  0.846 0.846 0.854 0.854
 0.856 0.856 0.868 0.868 0.874 0.874 0.876 0.876 0.88  0.88  0.884 0.884
 0.886 0.886 0.888 0.888 0.894 0.894 0.898 0.898 0.906 0.906 0.916 0.916
 0.92  0.92  0.924 0.924 0.928 0.928 0.932 0.932 0.934 0.934 0.936 0.936
 0.938 0.938 0.94  0.94  0.942 0.942 0.948 0.948 0.95  0.95  0.952 0.952
 0.956 0.956 0.964 0.964 0.972 0.972 0.982 0.982 0.996 0.996 1.   ]
tpr: [0.    0.002 0.002 0.008 0.008 0.01  0.01  0.012 0.012 0.014 0.014 0.02
 0.02  0.022 0.022 0.026 0.026 0.028 0.028 0.034 0.034 0.038 0.038 0.046
 0.046 0.05  0.05  0.052 0.052 0.054 0.054 0.062 0.062 0.064 0.064 0.066
 0.066 0.074 0.074 0.076 0.076 0.088 0.088 0.09  0.09  0.092 0.092 0.1
 0.1   0.104 0.104 0.11  0.11  0.112 0.112 0.116 0.116 0.122 0.122 0.124
 0.124 0.134 0.134 0.136 0.136 0.14  0.14  0.154 0.154 0.156 0.156 0.158
 0.158 0.16  0.16  0.17  0.17  0.172 0.172 0.174 0.174 0.178 0.178 0.18
 0.18  0.188 0.188 0.194 0.194 0.196 0.196 0.198 0.198 0.202 0.202 0.206
 0.206 0.214 0.214 0.218 0.218 0.22  0.22  0.222 0.222 0.224 0.224 0.226
 0.226 0.228 0.228 0.232 0.232 0.236 0.236 0.24  0.24  0.242 0.242 0.246
 0.246 0.25  0.25  0.252 0.252 0.254 0.254 0.258 0.258 0.26  0.26  0.264
 0.264 0.27  0.27  0.272 0.272 0.274 0.274 0.276 0.276 0.278 0.278 0.282
 0.282 0.284 0.284 0.288 0.288 0.292 0.292 0.296 0.296 0.3   0.3   0.304
 0.304 0.308 0.308 0.31  0.31  0.322 0.322 0.324 0.324 0.328 0.328 0.334
 0.334 0.34  0.34  0.342 0.342 0.348 0.348 0.35  0.35  0.356 0.356 0.358
 0.358 0.364 0.364 0.368 0.368 0.372 0.372 0.374 0.374 0.38  0.38  0.388
 0.388 0.396 0.396 0.398 0.398 0.4   0.4   0.402 0.402 0.406 0.406 0.408
 0.408 0.412 0.412 0.414 0.414 0.418 0.418 0.42  0.42  0.424 0.424 0.428
 0.428 0.434 0.434 0.442 0.442 0.444 0.444 0.448 0.448 0.45  0.45  0.452
 0.452 0.454 0.454 0.456 0.456 0.462 0.462 0.468 0.468 0.47  0.47  0.474
 0.474 0.482 0.482 0.488 0.488 0.49  0.49  0.494 0.494 0.5   0.5   0.508
 0.508 0.518 0.518 0.524 0.524 0.528 0.528 0.53  0.53  0.532 0.532 0.538
 0.538 0.54  0.54  0.542 0.542 0.546 0.546 0.55  0.55  0.552 0.552 0.554
 0.554 0.558 0.558 0.566 0.566 0.568 0.568 0.572 0.572 0.576 0.576 0.578
 0.578 0.582 0.582 0.584 0.584 0.586 0.586 0.588 0.588 0.596 0.596 0.598
 0.598 0.602 0.602 0.604 0.604 0.608 0.608 0.614 0.614 0.618 0.618 0.622
 0.622 0.634 0.634 0.636 0.636 0.638 0.638 0.642 0.642 0.654 0.654 0.66
 0.66  0.664 0.664 0.672 0.672 0.674 0.674 0.678 0.678 0.684 0.684 0.69
 0.69  0.694 0.694 0.696 0.696 0.708 0.708 0.712 0.712 0.714 0.714 0.718
 0.718 0.73  0.73  0.732 0.732 0.734 0.734 0.736 0.736 0.74  0.74  0.746
 0.746 0.748 0.748 0.75  0.75  0.752 0.752 0.754 0.754 0.756 0.756 0.76
 0.76  0.766 0.766 0.768 0.768 0.778 0.778 0.784 0.784 0.786 0.786 0.79
 0.79  0.794 0.794 0.808 0.808 0.812 0.812 0.814 0.814 0.826 0.826 0.83
 0.83  0.832 0.832 0.836 0.836 0.842 0.842 0.846 0.846 0.848 0.848 0.85
 0.85  0.852 0.852 0.868 0.868 0.87  0.87  0.872 0.872 0.874 0.874 0.88
 0.88  0.884 0.884 0.886 0.886 0.89  0.89  0.9   0.9   0.902 0.902 0.904
 0.904 0.91  0.91  0.914 0.914 0.918 0.918 0.922 0.922 0.924 0.924 0.928
 0.928 0.93  0.93  0.934 0.934 0.938 0.938 0.94  0.94  0.946 0.946 0.95
 0.95  0.954 0.954 0.96  0.96  0.962 0.962 0.966 0.966 0.968 0.968 0.972
 0.972 0.98  0.98  0.982 0.982 0.994 0.994 0.996 0.996 1.    1.   ]
thresholds: [        inf  4.6011744   4.161752    3.6452196   3.3804214   3.375598
  3.176591    3.1083598   3.0619423   3.04865     2.5971656   2.505922
  2.2664266   2.2057836   2.1478696   1.999851    1.9928658   1.908596
  1.822807    1.7337325   1.725924    1.6140645   1.6118169   1.4772727
  1.4614749   1.4305505   1.4257184   1.3854533   1.30307     1.2929758
  1.2211485   1.174337    1.152836    1.1474897   1.1113334   1.0978761
  1.0877966   0.94671327  0.93790907  0.90663874  0.9044099   0.8191446
  0.8123351   0.8006816   0.78627986  0.78377444  0.7712801   0.7068308
  0.6214588   0.6074354   0.4941866   0.4217761   0.4075253   0.37684724
  0.3708031   0.29968444  0.26702356  0.22651513  0.20085679  0.19860294
  0.14604723  0.1087376   0.08913606  0.07918201  0.01623427 -0.01973287
 -0.03148035 -0.1115229  -0.13387188 -0.18087646 -0.19949897 -0.20550561
 -0.21576399 -0.21870896 -0.23933867 -0.35086188 -0.3879348  -0.39616057
 -0.40650493 -0.42611608 -0.42663807 -0.4468043  -0.46354952 -0.4675187
 -0.4968989  -0.53373754 -0.5545728  -0.5827717  -0.6073186  -0.6080961
 -0.6139102  -0.6239484  -0.6315277  -0.6584261  -0.745757   -0.7490175
 -0.7726854  -0.8183527  -0.8238732  -0.83670956 -0.85072464 -0.8589574
 -0.86819965 -0.8815429  -0.9107827  -0.922178   -0.9249241  -0.92597705
 -0.94145155 -0.94179034 -0.9615762  -0.9867488  -0.99332595 -1.0005859
 -1.0233307  -1.0957693  -1.1023262  -1.1025579  -1.110003   -1.1545023
 -1.1659017  -1.170815   -1.1745553  -1.1760159  -1.1800573  -1.1801813
 -1.1972017  -1.2028048  -1.2146547  -1.2150469  -1.2670939  -1.2767594
 -1.2828667  -1.2996219  -1.3108587  -1.3142581  -1.3154624  -1.3298641
 -1.336197   -1.3575072  -1.3635353  -1.3639054  -1.3646538  -1.3841532
 -1.4145364  -1.4159192  -1.4334472  -1.4385293  -1.4419494  -1.4705904
 -1.4730729  -1.4774468  -1.4831809  -1.4851881  -1.4994833  -1.5006378
 -1.5051519  -1.509589   -1.5101091  -1.5111458  -1.5280339  -1.5513452
 -1.5525895  -1.5540358  -1.5602901  -1.5670063  -1.5728276  -1.5864089
 -1.5958837  -1.6206912  -1.633516   -1.6362197  -1.64407    -1.6519634
 -1.6643306  -1.6653501  -1.6768757  -1.6876307  -1.7049516  -1.7071993
 -1.7291895  -1.7697854  -1.7951006  -1.8041421  -1.8142202  -1.8185498
 -1.8677078  -1.8714622  -1.8882743  -1.9084095  -1.9102588  -1.9211525
 -1.9365232  -1.9650966  -1.9690943  -1.9978684  -2.0397213  -2.052397
 -2.060909   -2.0750105  -2.0905676  -2.100192   -2.112591   -2.1144373
 -2.1259882  -2.1445475  -2.1737587  -2.1901102  -2.2228024  -2.237811
 -2.2410092  -2.243765   -2.269996   -2.290336   -2.295716   -2.2993634
 -2.3239858  -2.3364985  -2.3456302  -2.3627582  -2.3635345  -2.376545
 -2.383174   -2.390328   -2.4050033  -2.4094894  -2.4306004  -2.4394462
 -2.4562736  -2.456793   -2.463528   -2.4635575  -2.4789765  -2.4941273
 -2.504249   -2.5352108  -2.549403   -2.5545166  -2.5602996  -2.5619822
 -2.5809124  -2.609503   -2.6192036  -2.6283123  -2.649203   -2.6549335
 -2.6598241  -2.6749475  -2.6910765  -2.6943743  -2.7084546  -2.7205417
 -2.7303817  -2.7440386  -2.7487237  -2.7582386  -2.76118    -2.773805
 -2.7813532  -2.7900565  -2.8057516  -2.8068748  -2.8096414  -2.8223538
 -2.8249323  -2.8278525  -2.8326411  -2.8389485  -2.8435426  -2.8501737
 -2.876838   -2.921986   -2.9223409  -2.9328427  -2.9494958  -2.951788
 -2.9785662  -2.981613   -2.9864726  -2.9987695  -3.0007997  -3.0095503
 -3.0202544  -3.0346205  -3.0413144  -3.0711925  -3.0940223  -3.0986438
 -3.1021194  -3.1114833  -3.130953   -3.131811   -3.13869    -3.146552
 -3.1490307  -3.1530704  -3.1775203  -3.195148   -3.2158484  -3.2165213
 -3.250724   -3.2617807  -3.2694285  -3.2697508  -3.2759662  -3.2856824
 -3.3073509  -3.3212411  -3.3427925  -3.3526714  -3.354736   -3.356494
 -3.3685687  -3.4135647  -3.4198494  -3.4263868  -3.440691   -3.451726
 -3.4667895  -3.4788992  -3.49112    -3.512047   -3.5285285  -3.54371
 -3.545138   -3.5540788  -3.5609157  -3.5792909  -3.5960786  -3.5972695
 -3.6022494  -3.610721   -3.6112232  -3.614532   -3.618057   -3.625759
 -3.6474168  -3.6523757  -3.6625557  -3.6632514  -3.7462943  -3.7595296
 -3.7664027  -3.790837   -3.802414   -3.8090115  -3.8097246  -3.8137264
 -3.8201537  -3.8837276  -3.898378   -3.9127524  -3.9163315  -3.9173129
 -3.9529555  -3.9567595  -3.9617903  -3.965556   -3.9692364  -3.9745095
 -3.9745982  -3.9751484  -4.004746   -4.0135164  -4.030545   -4.0318775
 -4.045714   -4.0506725  -4.054068   -4.0596786  -4.0870357  -4.0887375
 -4.097784   -4.1112266  -4.115808   -4.12124    -4.13018    -4.1614256
 -4.1733494  -4.1817946  -4.1882777  -4.189859   -4.211      -4.2218294
 -4.2241626  -4.227906   -4.2392716  -4.266835   -4.2681203  -4.278662
 -4.2856283  -4.286159   -4.2906737  -4.307416   -4.3101664  -4.317791
 -4.325387   -4.326158   -4.327686   -4.332739   -4.339096   -4.342695
 -4.3529162  -4.355174   -4.3587275  -4.3704104  -4.3781643  -4.3857136
 -4.386558   -4.3965044  -4.3970113  -4.41793    -4.418841   -4.4246516
 -4.4311533  -4.4324646  -4.441898   -4.442946   -4.453701   -4.4575505
 -4.4578447  -4.4609404  -4.4867406  -4.487128   -4.512041   -4.51757
 -4.518733   -4.529449   -4.5325484  -4.5336237  -4.539078   -4.5438957
 -4.5439725  -4.5473523  -4.5494065  -4.5531073  -4.560483   -4.5639524
 -4.5708175  -4.5793567  -4.5822544  -4.582546   -4.598044   -4.603692
 -4.606218   -4.607313   -4.6141143  -4.6154695  -4.6192393  -4.6238637
 -4.632798   -4.6378345  -4.6379085  -4.6499996  -4.6504107  -4.651964
 -4.653709   -4.6552854  -4.6564345  -4.6619735  -4.6664844  -4.6684046
 -4.673953   -4.675352   -4.678785   -4.6788435  -4.6811285  -4.6845336
 -4.68918    -4.6926236  -4.6957808  -4.6960278  -4.6999807  -4.7048965
 -4.7099476  -4.710078   -4.714069   -4.7147284  -4.717207  ]
Test metrics at specific given threshold:
accuracy: 0.534613
precision: 0.5784141504780731
recall: 0.25972333203353104
f1_score: 0.3581493064380245
fp_rate: 0.18976663778398778
tp_rate: 0.25972333203353104
std_accuracy: 0.01626134161131855
std_precision: 0.03185534693194592
std_recall: 0.019575247373249702
std_f1_score: 0.022501889502139605
std_fp_rate: 0.017218240320230123
std_tp_rate: 0.019575247373249702
TP: 404.611
TN: 130.002
FP: 370.629
FN: 94.758
