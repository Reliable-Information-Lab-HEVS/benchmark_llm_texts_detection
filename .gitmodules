[submodule "lm-evaluation-harness"]
	path = benchmarking_detectors/lm-evaluation-harness
	url = https://github.com/marluxiaboss/lm-evaluation-harness
	branch = main
[submodule "prometheus-eval"]
	path = prometheus-eval
	url = https://github.com/marluxiaboss/prometheus-eval
[submodule "benchmarking_detectors/prometheus-eval"]
	path = benchmarking_detectors/prometheus-eval
	url = https://github.com/marluxiaboss/prometheus-eval
[submodule "human-eval"]
	path = benchmarking_detectors/detector_benchmark/text_quality_evaluation/human-eval
	url = https://github.com/openai/human-eval
[submodule "benchmarking_detectors/bigcode-evaluation-harness"]
	path = benchmarking_detectors/bigcode-evaluation-harness
	url = https://github.com/bigcode-project/bigcode-evaluation-harness
